<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Arnaud Bailly's  Blog</title>
    <link href="http://abailly.github.io/atom.xml" rel="self" />
    <link href="http://abailly.github.io" />
    <id>http://abailly.github.io/atom.xml</id>
    <author>
        <name>Arnaud Bailly</name>
        <email>arnaud@igitur.io</email>
    </author>
    <updated>2017-03-28T00:00:00Z</updated>
    <entry>
    <title>Weekly Review - Week 12</title>
    <link href="http://abailly.github.io/posts/weekly-review-12.html" />
    <id>http://abailly.github.io/posts/weekly-review-12.html</id>
    <published>2017-03-28T00:00:00Z</published>
    <updated>2017-03-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Weekly Review - Week 12</h1>
<div class="info">Posted on March 28, 2017</div>

<p>This post is a summary of my activities related to coding and software in the past week. Its purpose is both to serve as a high-level personal log and as a potential source of interesting (or not so interesting) links. Entries are provided in no particular order with minimal comments…</p>
<dl>
<dt><a href="http://www.grammaticalframework.org/">Grammatical Framework</a></dt>
<dd><p>A fascinating piece of work whose purpose is to provide a way to define unified grammars that can be “linearized” into different languages for the purpose of both parsing and text generation.</p>
</dd>
<dt><a href="https://korewanetadesu.com/emacs-on-os-x.html">Emacs Daemon on Mac OS X</a></dt>
<dd><p>Configuration for running Emacs in server mode which is useful for fast editing of files from the command-line: Run <code>emacsclient foo.txt&amp;</code> and the file’s content is displayed in a buffer in emacs.</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Axel_Honneth">La lutte pour la reconnaissance</a></dt>
<dd><p>Finished reading this book from Axel Honneth, a German philosopher heir to the Frankfurt School. Worthy of some extended blog post…</p>
</dd>
<dt><a href="https://addons.mozilla.org/fr/firefox/addon/org-mode-capture/">Capture org-mode links in Firefox</a></dt>
<dd><p>A nice utility to quickly capture links in Firefox and add them to Emacs’ org-mode</p>
</dd>
<dt><a href="https://github.com/cantino/huginn">Huggin</a></dt>
<dd><p>A tool in Rails to create and manage agents on a personal server, something I have been thinking to setup for a while.</p>
</dd>
<dt><a href="https://syncthing.net/">Syncthing</a></dt>
<dd><p>Open-source system to synchronize several devices</p>
</dd>
<dt><a href="https://vimeo.com/162036084">Types + Properties = Software - Mark Seemann on Vimeo</a></dt>
<dd><p>While working on my talk for <a href="https://www.meetup.com/fr-FR/Crafting-Software/events/238241119/">Crafting Software</a> meetup, I discovered previous work from Mark Seeman in the same vein. There is a whole blog post series on <a href="http://blog.ploeh.dk/2016/02/10/types-properties-software/">Types + Properties = Software</a> which is definitely interesting. Inspired <a href="http://mirrors.link/posts/the-polyglot-approach-to-modeling-state-and-property-tests-in-elm">The Polyglot Approach to Getting Better at Modeling the State and Writing Property Tests in Elm · Exceptional Mirrors</a> written in Elm.</p>
</dd>
<dt><a href="https://www.stackbuilders.com/news/reverse-reverse-theorem-proving-with-idris">Reverse, Reverse: Theorem Proving with Idris</a></dt>
<dd><p>A blog post on how theorem proving works in Elm, detailing the classical vector reversal function’s derivation.</p>
</dd>
<dt><a href="https://www.cs.ox.ac.uk/projects/utgp/school/idris-tutorial.pdf">idris-tutorial.pdf</a></dt>
<dd><p>A short tutorial on Idris by Edwin Brady. Not sure how relevant it is to the newest versions of the language, but provides a compact overview of Idris’ features.</p>
</dd>
<dt><a href="http://www.cse.chalmers.se/~ulfn/papers/afp08/tutorial.pdf">Agda Tutorial</a></dt>
<dd><p>Working on Idris led me to <a href="http://wiki.portal.chalmers.se/agda/pmwiki.php">Agda</a> which is a predecessor of Idris with an emphasis on theorem proving.</p>
</dd>
<dt><a href="http://stackoverflow.com/questions/42974540/how-can-i-express-range-validity-in-idris">How can I express range validity in Idris?</a></dt>
<dd><p>As I was struggling on writing some Idris code for my talk, I posted this question on SO which leads to a Ah!Ah! moment thanks to the answer it received: The slogan is <em>Add more information to your types</em>!</p>
</dd>
<dt><a href="https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/ttfp.pdf">Type Theory and Functional Programming</a></dt>
<dd><p>An out-of-print book by Simon Thompson (author of one of the first Haskell books) that seems to provide a lot of insights on top of Pierce’s classical textbook.</p>
</dd>
<dt><a href="http://oxij.org/note/BrutalDepTypes/">Brutal {Meta}Introduction to Dependent Types in Agda</a></dt>
<dd><p>A page full of resources on dependent types, not only in Agda. Lead me to <a href="http://augustss.blogspot.fr/2007/10/simpler-easier-in-recent-paper-simply.html">this post</a> from Lennart Augustsson which gives an implementation of a depedently-typed lambda calculus in Haskell.</p>
</dd>
<dt><a href="https://medium.com/wardleymaps/finding-a-path-cdb1249078c0#.32oohi27s">Wardley Maps</a></dt>
<dd><p>I have started again to read Simon Wardley’s book-in-progress on how to draw maps for strategic thinking.</p>
</dd>
</dl>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Les Blancs, les Juifs et nous&quot;</title>
    <link href="http://abailly.github.io/posts/bouteldja.html" />
    <id>http://abailly.github.io/posts/bouteldja.html</id>
    <published>2016-06-21T00:00:00Z</published>
    <updated>2016-06-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Les Blancs, les Juifs et nous&quot;</h1>
<div class="info">Posted on June 21, 2016</div>

<p>J’ai lu récemment <a href="http://www.lafabrique.fr/catalogue.php?idArt=952">Les Blancs, les Juifs et nous</a> de <a href="https://fr.wikipedia.org/wiki/Houria_Bouteldja">Houria Bouteldja</a>, fondatrice du Mouvement puis Parti des <a href="http://indigenes-republique.fr/">Indigènes de la République</a>. Les temps que nous vivons sont, comme le dit une fameuse malédiction, intéressants et la question des migrations, des frontières et des nations se repose avec une acuïté renouvellée. Nous croyions les nationalismes et racismes dépassés, au moins en Europe, vestiges d’un ancien monde qui aurait plongé dans l’abyme en 1945, quand ils n’étaient qu’assoupis. Et ces vieux démons nous reviennent en partie sous les mêmes oripeaux - stigmatisation de l’étranger, de l’immigré, peur de l’avenir et du déclassement, exaltation de la grandeur du passé - en partie sous de nouvelles hardes - crise écologique, hyper-technologie, libéralisme dévorant. Essayer de comprendre les alternatives qui s’offrent à nous, les “nouvelles” idéologies qu’il nous faudra fabriquer, diffuser, intégrer pour espérer survivre me semble être un impératif pressant.</p>
<p>Pour ceux qui liraient ces lignes et que ces questions intéresseraient, internet est comme souvent une mine inépuisable de textes, d’information et de désinformation sur ces questions et sur le sujet du <em>décolonialisme</em> dont je n’ai fait qu’égratigner la surface, et qui est le sujet du livre de Houria Bouteldja. Je n’en parlerai donc pas plus et me concentrerai sur ce que j’ai compris de ce livre et ce qu’il m’inspire.</p>
<h2 id="brève-synthèse">Brève synthèse</h2>
<p>Le livre est court, divisé en 6 chapitres traitant respectivement de Sartre et de la génèse du mouvement décolonial, des Blancs et de leur domination sur toutes les autres “races”, des Juifs et de leur soumission aux Blancs, des femmes décolonisées et de leur relation aux hommes décolonisés et aux femmes en général, de tous les décolonisés et enfin de Dieu et plus particulièrement de l’Islam.</p>
<p>Il est aussi très bien écrit. La langue d’Houria Bouteldja est fluide, percutante, poétique parfois, polémique toujours. Elle me rappelle, si ce n’est par le style du moins par le ton et le sens de la formule, certains écrits de Debord, ou bien sûr les textes du <a href="http://www.lafabrique.fr/spip/IMG/pdf_Insurrection.pdf">Comité invisible</a>. Cela n’a rien d’étonnant compte-tenu de la proximité entre toutes les luttes de l’ultra-gauche: le décolonialisme est l’allié “naturel” du féminisme, de l’anti-capitalisme, des luttes trans-genres, de l’écologie radicale…</p>
<p>Allié ou plutôt <em>avant-garde</em> au sens bolchévique, marxiste, révolutionnaire du terme : la pointe la plus avancée de la contestation, le groupe le plus en phase avec le <em>sens de l’histoire</em>, celui sur lequel toutes les autres luttes doivent s’aligner, qui a la responsabilité historique d’être révolutionnaire. C’est d’ailleurs le point essentiel du livre : démontrer en quoi les décolonisés sont la nouvelle <em>classe révolutionnaire</em> et subsument toutes les autres luttes ; autrement dit transformer la dialectique prolétaires/capitalistes en dialectique (dé)colonisés/colonisateurs : les décolonisés sont les nouveaux <em>damnés de la Terre</em>, les ultimes prolétaires.</p>
<p>Et ce pour une bonne raison : le concept de race, la <em>blanchitude</em> et donc la <em>non-blanchitude</em>, est une invention de l’Occident destinée à enfoncer un coin entre le prolétariat “blanc” occidental et les colonisés. Ce sont les dominants Blancs qui ont inventé le racisme pour construire leur hégémonie et s’assurer de la docilité de leurs prolétaires en inventant un sous-prolétaire : le <em>non-blanc</em>, le <em>colonisé</em>. Tactique classique de tous les pouvoirs pour lutter contre les critiques internes : créer de toute pièce un ennemi “extérieur” qui deviendra ennemi commun, puis en appeler à la solidarité de la communauté.</p>
<p>Ce principe, au sens le plus “principiel” d’origine première d’une chose, doit donc informer toutes les luttes “autres”:</p>
<ul>
<li>Les mouvemements ouvriers et de luttes sociales sont invités à se rallier à sa bannière car “l’Arabe est le prolétaire du prolétaire” et leurs luttes convergent ;</li>
<li>les luttes homosexuelles, de genre et plus largement LGBTQ sont considérées comme secondaires et surtout purement blanches : “il n’y a pas d’homosexuels en Iran” dit Ahmadinejjad lors d’un colloque à Columbia ;</li>
<li>le féminisme est lui aussi un produit de la blanchitude et l’auteure en appele à une solidarité communautaire avec les mâles décolonisés dans un délicat équilibre entre des revendications d’émancipation et l’impératif du combat principal contre la colonisation blanche. Le corps de la femme décolonisée, en tout cas celui d’Houria Bouteldja, ne lui appartient pas, il appartient à son clan, sa communauté, sa race, à la révolution qui vient, et la violence machiste des hommes colonisés est une réaction exacerbée par la domination subie, donc <em>in fine</em> une violence d’origine coloniale.</li>
</ul>
<p>Le cas des Juifs est particulier : les Juifs sont des non-blancs, des colonisés, mais en adoptant le sionisme ils se sont blanchis. L’auteure utilise d’ailleurs le terme très percutant et provocant de <em>dhimmis<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> de la République</em>. L’antisémitisme, comme toute forme de racisme, est un pur produit Occidental né de la modernité, une autre forme de la domination coloniale qui a trouvée son point culminant dans la destruction des juifs d’Europe. En universalisant l’antisémitismes, les Blancs réussissent à “faire d’une pierre deux coups : justifier le hold-up de la Palestine et justifier la répression des indigènes en Europe”.</p>
<p>L’Islam, socle culturel authentiquement décolonisé et indigène, est la seule force capable de lutter contre la modernité occidentale incarnée par la figure tutélaire de Descartes, d’où le titre du dernier chapitre du livre : <em>Allahou Akbar</em>. En posant tous les hommes également égaux car soumis à Dieu, l’Islam renverserait la profession de foi occidentalo-centrée en “l’homme maître et possesseur de la Nature”.</p>
<h2 id="quelques-remarques-pêle-mêles">Quelques remarques pêle-mêles</h2>
<p>J’ai aimé ce livre pour sa force provocatrice, son ton radical, son engagement en faveur des exploités et dominés. Il m’a donné des clés pour lire certains événements contemporains, certains prises de position, certaines luttes, par exemple pourquoi le port du voile peut être pensé comme révolutionnaire et libérateur (et ce en dehors de toute question morale). Comme tous les pamphlets bien écrits, il ne peut laisser indifférent et provoque des sentiments mêlés d’admiration, d’enthousiasme, de peur. C’est aussi sa limite.</p>
<p>Comme tous les pamphlets, il est plein d’amalgames, de raccourcis, de formules chocs dont le sens est interprétable à l’infini, d’appels à l’Histoire dans lesquels se télescopent les situations, les époques, les peuples, les civilisations. Plein de mauvaise foi aussi, jugée nécessaire pour les besoins de l’argumentation. Et d’ambiguïtés : citer dans un même livre Sartre, Genet, Césaire, Malcolm X, James Baldwin, Mahmoud Ahmadinejjad et Dieudonné. Et parfois aussi tout simplement d’erreurs et d’omissions, volontaires ou non. Sur le plan historique, les relations entre Occident et Orient me semblent un peu plus complexes que ce qu’en dit l’auteure : l’Islam n’a pas attendu l’invention de la modernité pour être impérial, si ce n’est colonial. Et mettre dans le même plan toutes les colonisations européennes, depuis 1492 jusqu’au vingtième siècle est un court-circuit historique qui me semble abusif<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. Cela n’enlève rien à la responsabilité historique de l’Occident et de l’Europe dans la tragédie coloniale et post-coloniale.</p>
<p>Est-ce que ce livre s’adresse à moi ? Moi, homme blanc, petit-bourgeois, non engagé dans les luttes sociales, rationnel et raisonnable ou tentant de l’être ; moi qui n’ai pas eu des parents ouvriers, qui n’ai jamais vécu dans une cité, qui suit un “souchien” n’ayant pas à souffrir du racisme ? Il parait difficile de le croire mais en tout cas il m’a touché. Et d’une certaine manière, Houria Bouteldja, en glorifiant le particularisme et sa “race” opprimée, atteint à l’universel de la lutte des dominés pour plus de justice sociale.</p>
<p>Nous sentons tous confusément que notre vieux monde se meurt, lentement mais sûrement ; que si l’Occident n’a plus de colonies il détient un part du capital mondial telle qu’il capte à son profit l’essentiel des richesses produites ; que Gaïa est en train de réagir aux mauvais traitements que nous lui infligeons ; que le modèle consumériste et la logique d’accumulation qui le sous-tend sont à bout de souffle. La question est, pour paraphraser Lénine : “Que faire ?”</p>
<p>Je n’ai pas de leçons à donner et m’en abstiendrai donc, mais je crois plus aux petits matins qu’aux grands soirs. Même si les seconds sont plus exaltants que les premiers.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Dans l’espace musulman, les dhimmis sont les non-musulmans, Juifs, Chrétiens, Zoroastriens (pas sûr pour ceux-là…) auxquels est accordé un statut spécial. Ils sont tolérés et protégés par le calife ou le sultan, ils ont l’autorisation de pratiquer leurs cultes en contrepartie d’une taxe et, si mes souvenirs sont bons, de l’obligation du port d’un signe distinctif.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Les anciens colonisateurs espagnols et portugais qui ont dominé et même exterminé les peuples indigènes d’Amérique sont devenus eux-mêmes colonisés et solidaires des luttes tiers-mondistes arabes, africaines et asiatiques.<a href="#fnref2">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>The Dungeon Master</title>
    <link href="http://abailly.github.io/posts/dungeon-master.html" />
    <id>http://abailly.github.io/posts/dungeon-master.html</id>
    <published>2016-06-03T00:00:00Z</published>
    <updated>2016-06-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>The Dungeon Master</h1>
<div class="info">Posted on June  3, 2016</div>

<p>This post was triggered by a <a href="https://twitter.com/ziobrando/status/737619202538758145">tweet from Alberto Brandolini</a> on <a href="https://medium.com/@ziobrando/the-rise-and-fall-of-the-dungeon-master-c2d511eed12f#.erkso3y88">The rise and fall of the Dungeon Master</a>. This revived old memories from my youth and the desire to share this part of my story, in the hope that it might shed some light on what a “Dungeon Master” role actually should be and what team work is all about. My life revolved around Role Playing Games between the the age of fifteen to about twenty-eight and this experience shaped my way of thinking probably more than anything else.</p>
<h1 id="kill-maim-mutilate">Kill, Maim, Mutilate!</h1>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/en/3/32/D%26D_Basic_Rules_1981.jpg" class="floating" width="200" />

</div>
<p>In the beginning, there was Dungeons &amp; Dragons, the ancestor of all modern <em>Role Playing Games</em>. I bought a mysterious box containing all kind of booklets, sheets and dices when I was fourteen. I have already been exposed to wargaming thanks to <a href="https://fr.wikipedia.org/wiki/Jeux_et_Strat%C3%A9gie">Jeux et Stratégies</a>, a specialized newspaper that died somewhere in the 90s, and D&amp;D was a kind of logical follow-up to wargames. My proficiency level in English at that time was barely sufficient to allow me to understand what I was reading and the whole concept sounded at first quite alien. It took me several months of frustrating reading and discussions with friends to finally understand what it was all about: Sitting around a table, throwing dices and killing monsters inside a “dungeon” designed by an evil <em>Dungeon Master</em>.</p>
<p>I dived into D&amp;D with the full passion of a shy and sexually frustrated teenager who discovers he can actually <em>be</em> anybody: A fierce warrior dreaded by his ennemies, a cunning wizard, a nimble thief, a wise priest… I wrote programs to generate characters on an old IBM at school, I spent nights writing “scenarios”, mapping dungeons on 5mm x 5mm grid paper, inventing new monsters, reading hundreds of pages of arcane rules, reading sci-fi and fantasy books to get inspiration from and of course playing, playing, playing…</p>
<p>At that time, the Dungeon Master looked quite like the one portrayed by Alberto Brandolini: The overlord of the game, hidden behind his <em>DM screen</em> from where he would throw at the poor players traps and monsters, and under the cover of which he could <em>cheat on the dices</em>! It was a major breach to look behind the screen and try to have a sneak peek at the DM’s plans and scenario, something which would invariably bring upon your head a major disaster like a <em>red dragon</em> or worse, the DM leaving the game.</p>
<p>As a player, my goal was pretty much guided by <em>numbers</em>: Getting to 18/100 in <em>strength</em>, accumulating enough <em>experience points</em> to get to the next level where new spells, weapons, tricks, skills were available. And the only way to get those XPs was to <em>kill monsters</em> and <em>hoard treasures</em>! I, like other players in my team, played by the rules and kept on pursuing those goals in a never-ending cycle of more powers, more dangerours monsters, more treasures, more intricate dungeons… I moved on quickly from D&amp;D to <em>Advanced D&amp;D</em> as the latter offered to go beyond the first ten levels, more character classes, more spells, more weapons, more tricks. I bought more books, like the infamous <a href="https://en.wikipedia.org/wiki/Deities_%26_Demigods#2nd_Edition_Advanced_Dungeons_.26_Dragons">Deities and Demi-gods</a> which detailed the characteristics of numerous figures from real or fictional religions, or the <a href="https://en.wikipedia.org/wiki/Fiend_Folio">Fiend Folio</a> which detailed more dreadful monsters.</p>
<h1 id="growing">Growing</h1>
<p>At some point, we grew wary of AD&amp;D and longed for new experiences. We discovered games like <a href="https://en.wikipedia.org/wiki/Call_of_Cthulhu_%28role-playing_game%29">Call of Cthulhu</a> or <a href="https://en.wikipedia.org/wiki/RuneQuest">RuneQuest</a>. Those games offered more complex settings and characters, with subtler goals like not losing all your <em>sanity</em>. But those games were still based on the principle of <em>accumulation</em>: Characters would <em>grow</em> and become more powerful, knowledgeable, skillfull. I vividly remember that the <em>GameMaster</em> (there were no more <em>dungeons</em>) was quite upset when, during one of our Cthulhu game, in some scene that was supposed to be one of the climax of the <a href="https://index.rpg.net/display-entry.phtml?mainid=829&amp;editionid=1045">Masks of Nyarlathotep</a> campaign and following a lengthy and supposedly terrifying description of some fierce beast whiche we were fighting, I said “Oh, a Hunting Horror !” in a definitely <em>not</em> terrified voice…</p>
<p>Then I became officially adult, and then came <a href="https://en.wikipedia.org/wiki/Vampire:_The_Masquerade">Vampire</a>. This game, and other similar games we played at that time like <a href="https://en.wikipedia.org/wiki/Pendragon_%28role-playing_game%29">Pendragon</a>, <a href="https://en.wikipedia.org/wiki/Bushido_%28role-playing_game%29">Bushido</a>, <a href="https://en.wikipedia.org/wiki/Mal%C3%A9fices">Maléfices</a> or <a href="https://en.wikipedia.org/wiki/Ars_Magica">Ars Magica</a>, developed the concept of <em>campaign</em> not as a sequence of battles to gain more XP, but as long story depicting the life (and sometimes death) of the player characters.</p>
<p>All of sudden, or so it seems in retrospect, the goal of the game shifted from <em>accumulating things</em> to <em>telling a good story</em>. What became important was not whether your character was the most powerful vampire of the universe, the cunniest wizard of the Covenant or the noblest knight around the table ; but whether or not your character had been through interesting, intriguing, funny, frightful and more importantly memorable experiences. Your character could grow in power: This was not for power’s sake but to enable him or her to live new and interesting things, to be involved in more complex intrigues at the Kings’s court or the local vampire overlord’s den. One of our Bushido’s campaign ended up with one of the player’s character committing <a href="https://en.wikipedia.org/wiki/Seppuku">seppuku</a> upon request from the Shôgun on the charge of treason and this was a really a moving experience. We played some Maléfices scenarios in a candle-lit chilly cave and those were the most frightening games we are went through.</p>
<p>The role of the Game Master obviously changed, so much so that it became a <em>Storyteller</em> in Vampire. He became more a different kind of player, a referee, a source of inspiration than a traps-dealer or a dungeon designer. He would be responsible for setting the stage, starting the story or crafting some new plot in case the original one dwindled and the game dragged along, surprising the players with interesting twists, embodying <em>non player characters</em> which the player would encounter or suggest… In other words, he stopped being an omnipotent <em>dictator</em> to become a <em>facilitator</em>, a <em>master of ceremony</em>: But having fun was a shared responsibility!</p>
<p>Within this frame, it was possible to be very directive, like an author whose skill takes you off and whom you would follow anywhere. Those kind of game masters would write complex stories, intricate plots, subtle NPCs and dramatic scenes and we would follow them because we knew they were good storytellers. I was more of the other kind of gamemasters, those who could improvise a game on the spur of the moment, counting on the other players to fuel the story and their own imagination to adapt to it as it unfolded in surprising ways. My scenarios were written on a napkin but I was good at recycling the numerous books I read, combining them, taking the plot of one book and mixing it with the background of another one.</p>
<div class="figure">
<img src="http://www.legrog.org/visuels/gammes/288.jpg" class="floating-right" />

</div>
<p>At some point, role-playing games became so prominent in my life we started <a href="https://rpggeek.com/rpgpublisher/11284/sarl-sans-peur-et-sans-reproche">a company</a> to publish our own games. The first, and most successful, game we published was <a href="https://fr.wikipedia.org/wiki/Miles_Christi">Miles Christi</a>, a game set in the Middle East during the early crusades era, in which the players’ characters were exclusively <em>templars</em>. This game was the embodiment of the evolution I sketched above: The scenarios were devised to put players into conflicting situations which forced to choose between their loyalty to the cause they were supposed to defend and their loyalty to the christian ideal of universal love and forgiving God. And each game ended with a <em>confession</em> scene during which the players were supposed to confess the, usually numerous, sins they would have committed during the game and were rewarded or punished accordingly.</p>
<h1 id="discussion">Discussion</h1>
<blockquote>
<p>The purpose of Life is living.</p>
</blockquote>
<p>Those recollections are probably of low interest to the reader and might sound like nostalgic rambles from an aging man. But if I try to relate that experience with the aforementioned blog post, it seems to me it highlights something important about the way we work, and especially the way we work in teams while we develop software, and the role of so-called <em>managers</em> within a team.</p>
<p>Most organizations, and teams within those organizations, and people making up those teams, are playing D&amp;D. Just like a D&amp;D player wants to get more XPs, more gold, kill more monsters ; and D&amp;D GM wants to devise more complex dungeons, more traps, more powerful monsters to throw at playsers ; those groups and people want <em>more</em> of something: Money, power, knowledge, tools, lines of code… They have a <em>goal</em>, they are <em>mission driven</em>, they <em>achieve</em>. And when they reach those goals, they find new ones, because it is never-ending, there is always more money, more knowlege, more power to grab. This is what give rise to the kind of <em>Dungeon Masters</em> Alberto Brandolini writes about, and this is fueled by the logic of <em>accumulation</em> and <em>competition</em> bred by material goals and achievements we often crave for.</p>
<p>Those days, I personally tend to favor the other approach. As a team member, whatever my precise role may be, I find it important to have clear, tangible goals. But what I have found to be more important is what happens within the team, the relationship I have with the people, the way we work together: The journey has become more important than the destination, the <em>how?</em> (and the <em>why?</em>) more important than the <em>what?</em>. As a <em>Dungeon Master</em>, or as an experienced person or the historical developer of some piece of software, what becomes important is to ensure <em>we</em> are telling ourselves a good story. And this is a collaborative process in which everybody has its role to play, and which requires a lot of effort from everybody.</p>
<p>To conclude on a philosophical note, let me quote my favourite philosopher:</p>
<blockquote>
<p>Therefore, to man there is nothing more useful than man–nothing, I repeat, more excellent for preserving their being can be wished for by men, than that all should so in all points agree, that the minds and bodies of all should form, as it were, one single mind and one single body, and that all should, with one consent, as far as they are able, endeavour to preserve their being, and all with one consent seek what is useful to them all. Hence, men who are governed by reason–that is, who seek what is useful to them in accordance with reason,–desire for themselves nothing, which they do not also desire for the rest of mankind, and, consequently, are just, faithful, and honourable in their conduct.</p>
<p>Spinoza, Ethica IV,18,sc.</p>
</blockquote>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Multi-host Docker Networking</title>
    <link href="http://abailly.github.io/posts/multi-host-docker-net.html" />
    <id>http://abailly.github.io/posts/multi-host-docker-net.html</id>
    <published>2016-05-30T00:00:00Z</published>
    <updated>2016-05-30T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Multi-host Docker Networking</h1>
<div class="info">Posted on May 30, 2016</div>

<p>A while ago I grew the desire to experiment implementing <em>multi-host docker networking</em> to deploy <a href="/posts/cm-infra-2.html">Capital Match system</a>. This system is made of several interlinked containers and <a href="https://docs.docker.com/v1.8/compose/">docker-compose</a> does not (did not?) work across several hosts. It seemed to me the <a href="https://docs.docker.com/engine/userguide/networking/get-started-overlay/">official solution</a> based on <code>docker-machine</code>, <code>swarm</code> and service registry was a bit complicated: Our configuration is mostly static, e.g. number, distribution and relationship between containers in known at deploy time. Hence I looked for a simpler solution, something that would be more <em>networky</em>: I am indebted to <a href="https://fr.wikipedia.org/wiki/Utilisateur:Hashar">hashar</a> for suggesting a GRE-based solution and to the following references for actual technical details:</p>
<ul>
<li><a href="https://goldmann.pl/blog/2014/01/21/connecting-docker-containers-on-multiple-hosts/" class="uri">https://goldmann.pl/blog/2014/01/21/connecting-docker-containers-on-multiple-hosts/</a></li>
<li><a href="https://wiredcraft.com/blog/multi-host-docker-network/" class="uri">https://wiredcraft.com/blog/multi-host-docker-network/</a></li>
</ul>
<p>I did some experiment in shell, jotted down a couple of notes in my journal and moved on to other, more urgent duties. I had a couple of hours left on Friday last week and I stumbled on those notes which were sitting there, on my hard disk, and I decided it was a good time to write a blog post about this experiment.</p>
<p>I started writing this post embedding script fragments but I quickly wanted to check what I wrote actually worked, so I began running those scripts fragment. But then it made this experiment non repeatable which is definitely annoying if you make a mistake, want to restart from scratch, change some parameters… So I decided this stuff would warrant a minor project of its own where I could provide all the needed code to configure multi-host networking in docker based on GRE tunnels. I have done quite a share of system configuration and operations management and have been able to use or create some useful tools to streamline ops in Haskell, so it quickly became obvious I would need to write some Haskell code. So what started as a mundane journal cleanup ended up being a full-blown yak-shaving session whose result can be found in this github <a href="https://github.com/abailly/multi-host-docker">repository</a>.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Haskell-based Infrastructure</title>
    <link href="http://abailly.github.io/posts/cm-infra-2.html" />
    <id>http://abailly.github.io/posts/cm-infra-2.html</id>
    <published>2016-05-24T00:00:00Z</published>
    <updated>2016-05-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Haskell-based Infrastructure</h1>
<div class="info">Posted on May 24, 2016</div>

<p>In my <a href="/posts/cm-infra-1.html">previous post</a> I focused on the build and development tools. This post will conclude my series on Capital Match by focusing on the last stage of the rocket: How we build and manage our development and production infrastructure. As already emphasized in the previous post, I am not a systems engineer by trade, I simply needed to get up and running something while building our startup. Comments and feedback most welcomed!</p>
<h1 id="continuous-integration">Continuous Integration</h1>
<p><a href="http://www.extremeprogramming.org/rules/integrateoften.html">Continuous Integration</a> is a cornerstone of Agile Development practices and something I couldn’t live without. CI is a prerequisite for <em>Continuous Deployment</em> or <a href="http://martinfowler.com/bliki/ContinuousDelivery.html">Continuous Delivery</a>: It should ensure each and every change in code of our system is actually working and did not break anything. CI is traditionally implemented using servers like <a href="https://jenkins.io/">Jenkins</a> or online services like <a href="https://travis-ci.org/">Travis</a> that trigger a build each time code is pushed to a source control repository. But people like <a href="http://blog.javabien.net/2009/12/01/serverless-ci-with-git/">David Gageot</a>, among <a href="http://www.yegor256.com/2014/10/08/continuous-integration-is-dead.html">others</a>, have shown us that doing CI without a server was perfectly possible. The key point is that <em>it should not be possible to deploy something which has not been verified and validated by CI</em>.</p>
<h2 id="ci-server">CI Server</h2>
<p>We settled on using a central git repository and CI server, hosted on a dedicated build machine:</p>
<ul>
<li>Git repository’s master branch is “morally” locked: Although technically it is still possible to push to it, we never do that and instead push to a <code>review</code> branch which is merged to the <code>master</code> only when build passes,</li>
<li>The git repository is configured with a git deploy hook](https://www.digitalocean.com/community/tutorials/how-to-use-git-hooks-to-automate-development-and-deployment-tasks) that triggers a call to the CI server when we push on the <code>review</code> branch,</li>
<li><p>Our CI server is implemented with <a href="https://github.com/ndmitchell/bake">bake</a>, a robust and simple CI engine built - guess what? - in Haskell. Bake has a client/server architecture where the server is responsible for orchestrating builds that are run by registered clients, which are supposed to represent different build environments or configurations. Bake has a very simple web interface that looks like</p>
<div class="figure">
<img src="/images/bake-screenshot.png" />

</div></li>
<li><p>Bake provides the framework for executing “tests”, reporting their results and merging changes to <code>master</code> branch upon successful build, but does not tell you <em>how</em> your software is built: This is something we describe in Haskell as a set of steps (bake calls them all <em>tests</em>) that are linked through dependencies and possibly dependent on the capabilities of the client. Here is a fragment of the code for building Capital Match:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Action</span> <span class="fu">=</span> <span class="dt">Cleanup</span>
            <span class="fu">|</span> <span class="dt">Compile</span>
            <span class="fu">|</span> <span class="dt">Dependencies</span>
            <span class="fu">|</span> <span class="dt">RunDocker</span>
            <span class="fu">|</span> <span class="dt">Deploy</span> <span class="dt">ImageId</span>
            <span class="fu">|</span> <span class="dt">IntegrationTest</span>
            <span class="fu">|</span> <span class="dt">UITest</span>
            <span class="fu">|</span> <span class="dt">EndToEndTest</span>
            <span class="kw">deriving</span> (<span class="dt">Show</span>,<span class="dt">Read</span>)

<span class="ot">allTests ::</span> [<span class="dt">Action</span>]
allTests <span class="fu">=</span> [ <span class="dt">Compile</span>
           , <span class="dt">Dependencies</span>
           , <span class="dt">IntegrationTest</span>
           , <span class="dt">UITest</span>
           , <span class="dt">EndToEndTest</span>
           , <span class="dt">Deploy</span> appImage
           , <span class="dt">RunDocker</span>
           ]

<span class="ot">execute ::</span> <span class="dt">Action</span> <span class="ot">-&gt;</span> <span class="dt">TestInfo</span> <span class="dt">Action</span>
execute <span class="dt">Compile</span> <span class="fu">=</span> depend [<span class="dt">Dependencies</span>] <span class="fu">$</span> run <span class="fu">$</span> <span class="kw">do</span>
  opt <span class="ot">&lt;-</span> addPath [<span class="st">&quot;.&quot;</span>] []
  () <span class="ot">&lt;-</span> cmd opt <span class="st">&quot;./build.sh --report=buildreport.json&quot;</span>
  <span class="dt">Exit</span> _ <span class="ot">&lt;-</span> cmd opt <span class="st">&quot;cat buildreport.json&quot;</span>
  sleep <span class="dv">1</span>
  incrementalDone

execute <span class="dt">IntegrationTest</span> <span class="fu">=</span> depend [<span class="dt">Compile</span>] <span class="fu">$</span> run <span class="fu">$</span> <span class="kw">do</span>
  opt <span class="ot">&lt;-</span> addPath [<span class="st">&quot;.&quot;</span>] []
  () <span class="ot">&lt;-</span> cmd opt <span class="st">&quot;./build.sh test&quot;</span>
  incrementalDone</code></pre></div>
The code is pretty straightforward and relies on the toplevel build script <code>build.sh</code> which is actually a simple wrapper for running our Shake build with various targets.</li>
<li>The output of the CI process, when it succeeds, is made of a bunch of docker containers deployed to Dockerhub, each tagged with the SHA1 of the commit that succeeded,</li>
<li>We extended bake to use <a href="https://git-scm.com/docs/git-notes">git notes</a> to identify successful builds: We attach a simple note saying <code>Build successful</code> to those commits which actually pass all the tests. We also notify outcome of the build in our main <a href="https://slack.com/">Slack</a> channel,</li>
<li>Bake server and client are packaged and deployed as docker containers, which means we can pull and use those containers from any docker-enabled machine in order to reproduce a CI environment or trigger builds through bake’s command-line interface,</li>
<li><p>As the last stage of a successful build we deploy a test environment, using anonymized and redacted sample of production data.</p></li>
</ul>
<h2 id="testing">Testing</h2>
<p>An significant time slice of our build is dedicated to running tests. Unit and server-side integration tests are pretty straightforward as they consist in a single executable built from Haskell source code which is run at <code>IntegrationTest</code> stage of the CI build process. Running UI-side tests is a little bit more involved as it requires an environment with PhantomJS and full ClojureScript stack to run leiningen. But the most interesting tests are the end-to-end ones which run Selenium tests against the full system.</p>
<ul>
<li>The complete ETE tests infrastructure is packaged as - guess what? - a set of containers orchestrated with <code>docker-compose</code> and mimicking production setup:
<ul>
<li>One container per service,</li>
<li>One container for the nginx front-end,</li>
<li>One container for the <a href="https://github.com/SeleniumHQ/docker-selenium">SeleniumHub</a>,</li>
<li>One container for a Firefox node in debug mode (this allows us to use VNC to log into the container and see the Firefox instance executing the tests),</li>
<li>and one container for the test driver itself,</li>
</ul></li>
<li><p>Tests are written in Haskell using <a href="https://github.com/kallisti-dev/hs-webdriver">hs-webdriver</a>, and we try to write them in a high-level yielding something like:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">
it <span class="st">&quot;Investor can withdraw cash given enough balance on account&quot;</span> <span class="fu">$</span> runWithImplicitWait <span class="fu">$</span> <span class="kw">do</span>

  liftIO <span class="fu">$</span> invokeApp appServer <span class="fu">$</span> <span class="kw">do</span>
    iid <span class="ot">&lt;-</span> adminRegistersAndActivateInvestor arnaudEMail
    adjustCashBalance_ (<span class="dt">CashAdjustment</span> iid <span class="dv">100001</span> (<span class="dt">TxInvestorCash</span> iid))

  userLogsInSuccesfully appServer arnaud userPassword
  goToAccountSummary
  cashBalanceIs <span class="st">&quot;S$\n1,000.01&quot;</span>

  investorSuccessfullyWithdraws <span class="st">&quot;500.00&quot;</span>

  cashBalanceIs <span class="st">&quot;S$\n500.01&quot;</span>
  userLogsOut</code></pre></div></li>
<li>Those tests only need a single URL pointing at an arbitrary instance of the system, which makes it “easy” to run them during development outside of docker containers. It’s even possible to run from the REPL which greatly simplifies their development,</li>
<li>Getting the docker-based infrastructure right and reliable in CI was a bit challenging: There are quite a few moving parts and feedback cycle when working with containers is slow. We ran into subtle issues with things like:
<ul>
<li>Differing versions of Firefox between local environment and container leading to different behaviours, like how visibility of DOM elements is handled which may or may not prevent <code>click</code> actions to complete</li>
<li>Timezone differences between various containers yielding different interpretations of the same timestamp (official Selenium docker images are configured to use PST whereas test driver container uses SGT,</li>
<li>Connections and timeouts issues between all the containers depending on open ports and network state,</li>
<li>…</li>
</ul></li>
<li><p>However, once in place and executing reliably, those tests really payoff in terms of how much confidence we have in our system. We don’t aim to provide 100% feature coverage of course and try to keep <a href="http://martinfowler.com/bliki/TestPyramid.html">ETE tests small</a>: The goal is to ensure our system’s main features are still usable after each change.</p></li>
</ul>
<h1 id="deployment">Deployment</h1>
<h2 id="provisioning-infrastructure">Provisioning &amp; Infrastructure</h2>
<p>We are using <a href="https://www.digitalocean.com/">DigitalOcean</a>’s cloud as our infrastructure provided: DO provides a much simpler deployment and billing model than what provides AWS at the expense of some loss of flexibility. They also provide a simple and consistent RESTful API which makes it very easy to automate provisioning and manage VMs.</p>
<ul>
<li>I wrote a Haskell client for DO called <a href="https://github.com/capital-match/hdo">hdo</a> which covers the basics of DO API: CRUD operations on VMs and listing keys,</li>
<li>Provisioning is not automated as we do not need capacity adjustments on the go: When we need a machine we simply run the script with appropriate credentials. Having a simple way to provision VMs however has a nice side-effect: It makes it a no-brainer to fire copy of any environment we use (Dev, Ci or Production) and configure it. This was particularly useful for pairing sessions and staging deployment of sensitive features,</li>
<li>We also use AWS for a couple of services: S3 to backup data and host our static web site and CloudFront to provide HTTPS endpoint to website.</li>
</ul>
<h2 id="configuration-management">Configuration Management</h2>
<p>Configuration of provisioned hosts is managed by <a href="http://propellor.branchable.com/">propellor</a>, a nice and very actively developed Haskell tool. Configuration in propellor are written as Haskell code using a specialized “declarative” embedded DSL describing <em>properties</em> of the target machine. Propellor’s model is the following:</p>
<ul>
<li>Configuration code is tied to a git repository, which may be only local or shared,</li>
<li>When running <code>./propellor some.host</code>, it automatically builds then commits local changes, pushing them to remote repository if one is defined. All commits are expected to be signed,</li>
<li>Then propellor connects through SSH to <code>some.host</code> and tries to clone itself there, either by plain cloning from local code if <code>some.host</code> has never been configured, or by merging missing commits if host has already been configured (this implies there is a copy of git repository containing configuration code on each machine),</li>
<li>In case architectures are different, propellor needs to compile itself on the target host, which might imply installing additional software (e.g. a Haskell compiler and needed libraries…),</li>
<li>Finally, it runs remote binary which triggers verification and enforcement of the various “properties” defined for this host.</li>
</ul>
<p>Propellor manages security, e.g. storing and deploying authentication tokens, passwords, ssh keys…, in a way that seems quite clever to me: It maintains a “store” containing sensitive data <em>inside</em> its git repository, encrypted with the public keys of accredited “users”, alongside a keyring containing those keys. This store can thus be hosted in a public repository, it is decrypted only upon deployment and decryption requires the deployer to provide her key’s password.</p>
<p>Here is an example configuration fragment. Each statement separated by <code>&amp;</code> is a property that propellor will try to validate. In practice this means that some system-level code is run to check if the property is set and if not, to set it.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">ciHost ::</span> <span class="dt">Property</span> <span class="dt">HasInfo</span>
ciHost <span class="fu">=</span> propertyList <span class="st">&quot;creating Continuous Integration server configuration&quot;</span> <span class="fu">$</span> props
              <span class="fu">&amp;</span> setDefaultLocale en_us_UTF_8
              <span class="fu">&amp;</span> ntpWithTimezone <span class="st">&quot;Asia/Singapore&quot;</span>
              <span class="fu">&amp;</span> Git.installed
              <span class="fu">&amp;</span> installLatestDocker
              <span class="fu">&amp;</span> dockerComposeInstalled</code></pre></div>
<p>In practice, we did the following:</p>
<ul>
<li>All known hosts configurations are defined in a configuration file (a simple text file containing a Haskell data structure that can be <code>Read</code>) and tells, for each known IP/hostname, what type of configuration should be deployed there and for production hosts what is the <strong>tag</strong> for containers to be deployed there. As this information is versioned and committed upon each deployment run, we always know which version of the system is deployed on which machine by looking at this configuration,</li>
<li>We also defined a special <em>clone</em> configuration which allows us to deploy some version of the system using cloned data from another system,</li>
<li>We ensure the application is part of the boot of the underlying VM: Early on we had some surprises when our provider decided to reboot the VM and we found our application was not available anymore…</li>
</ul>
<h2 id="deployment-to-production">Deployment to Production</h2>
<p>Given all the components of the application are containerized the main thing we need to configure on production hosts apart from basic user information and firewall rules is docker itself. Apart from docker, we also configure our <a href="http://nginx.org">nginx</a> frontend: The executable itself is a container but the configuration is more dynamic and is part of the hosts deployment. In retrospect, we could probably make use of pre-canned configurations deployed as data-only containers and set the remaining bits as environment variables.</p>
<p>Doing actual deployment of a new version of the system involves the following steps, all part of propellor configuration:</p>
<ul>
<li>We first check or create our data containers: Those are the containers which will be linked with the services containers and will host the persisted event streams (see <a href="/posts/cm-archi.html">post on architecture</a>),</li>
<li>We then do a full backup of the data, just in case something goes wrong…</li>
<li>And finally rely on <a href="https://docs.docker.com/v1.8/compose/">docker-compose</a> to start all the containers. The <code>docker-compose.yml</code> configuration file is actually generated by propellor from some high-level description of the system which is stored in our hosts configuration file: We define for each deployable service the needed version (docker repository <em>tag</em>) and use knowledge of the required topology of services dependencies to generate the needed docker links, ports and names.</li>
</ul>
<p>The net result is the something like the following. The dark boxes represent services/processes while the lighter grayed boxes represent containers:</p>
<div class="figure">
<img src="/images/services-architecture.png" />

</div>
<p>We were lucky enough to be able to start our system with few constraints which means we did not have to go through the complexity of setting up a blue/green or rolling deployment and we can live with deploying everything on a single machine, thus alleviating to use more sophisticated container orchestration tools.</p>
<h3 id="rollbacks">Rollbacks</h3>
<p><a href="/posts/cm-archi.html">Remember</a> our data is a simple persistent stream of events? This has some interesting consequences in case we need to rollback a deployment:</p>
<ul>
<li>If the version number has not been incremented, rollbacking simply means reverting the containers’ tag to previous value and redeploying: Even if some events have been recorded before we are notified of an issue implying rollback is needed, they should be correctly interpreted by the system,</li>
<li>If the version has changed during deployment, then either we cannot rollback because new events have been generated and stored and we must roll-forward ; or we can rollback at the expense of losing data. This is usually not an option but still is possible if stored events are “harmless” business-wise, like authentication events (logins/logouts): A user will simply have to login again.</li>
</ul>
<h2 id="monitoring">Monitoring</h2>
<p>Monitoring is one the few areas in Capital Match system where we cheated on Haskell: I fell in love with <a href="http://riemann.io">riemann</a> and chose to use it to centralize log collections and monitoring of our system.</p>
<ul>
<li>Riemann is packaged as a couple of containers: One for the server and one for the <a href="http://riemann.io/dashboard.html">dashboard</a>, and deployed on a dedicated (small) VM. Both server and dashboard configuration are managed by propellor and versioned,</li>
<li>As part of the deployment of the various VMs, we setup and configure <a href="https://www.stunnel.org/index.html">stunnel</a>s containers which allow encrypted traffic between monitored hosts and monitoring server: On the monitoring host there is a stunnel server that redirects inbound connections to running docker containers, whereas on monitored hosts the stunnel server is referenced by clients and encapsulate traffic to remote monitoring host transparently,</li>
<li>Riemann is fed 2 types of events:
<ul>
<li>System level events which are produced by a <a href="https://collectd.org/">collectd</a> installed on each deployed host,</li>
<li>Applicative level events which are produced by the deployed services as part of our logging system,</li>
</ul></li>
<li>Applicative events are quite simple at the moment, mostly up/down status and a couple of metrics on HTTP requests and disk storage latency and throughput,</li>
<li>There is a simple riemann dashboard that presents those collected events in a synoptic way,</li>
<li>It is very easy to extend riemann with new clients or external connectors: At one point I considered using <a href="http://logmatic.io">LogMatic</a> to host some business-level dashboards and it took me a few hours to build a <a href="https://github.com/capital-match/riemann-logmatic">riemann plugin</a> to send events to Logmatic’s API,</li>
<li>Riemann’s event model is very simple and flexible hence it is an ideal candidate for being a one-stop sink for all your events: Dump all events to riemann using a single connector in the application and configure riemann server to massage the events and feed specialized clients,</li>
<li>There a couple of alerts configured in Riemann that notifies <em>slack</em> when disks fill up or hosts are down.</li>
</ul>
<p>We also have set up external web monitoring of both application and web site using <a href="https://checkmy.ws/fr/">Check My Website</a>.</p>
<h1 id="discussion">Discussion</h1>
<h2 id="some-takeaways">Some takeaways</h2>
<ul>
<li>Docker has its shortcomings, is far from being perfect and is becoming bloated like all enterprise software, but packaging all parts of a system as containers is a good thing. It allowed us to grow a flexible yet consistent system made of a lot of moving parts with diverse technological requirements. Containers are obviously great for <em>development</em>, providing a simple and efficient way of packaging complex tools and environments in an easy to use way. But they are also great for <em>operations</em>: They are more flexible than VMs, they can be as secure if one takes care to trim them down to the bare minimum, and pretty compact, they give you great flexibility in terms of deployment,</li>
<li>I still don’t have much experience, apart from small experiments, on how to deploy docker over multiple machines. However the ecosystem of tools for managing more complex deployments is growing and maturing fast and beside I have a couple ideas on how to do it in a “simple way” using <a href="https://github.com/openvswitch/ovs/">OpenVSwitch</a>,</li>
<li>Docker containers should do one and only one thing and they should be kept minimal: Don’t use default fat images and try to trim them down to the bare minimum (e.g. executable + support libraries + configuration files),</li>
<li>I did not pay enough attention to build time, or more precisely I did not pay attention often enough,</li>
<li>Automating as much as possible of the whole system is an investment: If you are going to throw it away in a few months, don’t do it ; but if you are going to live with it for years, do it <strong>now</strong> because later it will be too late to really payoff,</li>
<li>Having automated ETE tests is a great thing but they should be kept to a minimum: Always consider the relative size of the layers in the pyramid and do not try to cover bugs or “deviant” behaviour at the level of ETE tests,</li>
<li>Monitoring must be baked into the system from the onset, even if with simple solutions and basic alerts. It is then easy to extend when business starts to understand they could leverage this information,</li>
<li>propellor is a great tool for provisioning. I tried things like Chef or Puppet before and the comfort of working in Haskell and not having to delve into the intricacies of complex “recipes” or custom DSL is invaluable. Propellor is simple and suits my requirements pretty well, however there are a couple of pain points I would like to find some time to alleviate:
<ul>
<li>Tying deployment runs to git commits is really a good thing but this should be more customizable: I would like to keep deployment code in the same repository than production code but this currently would yield a lot of identically named commits and pollute the log of the repository,</li>
<li>Propellor needs to be built on the target machine as it is an executable: It can upload itself when architecture matches hence it would be better to run deployment inside a dedicated container that match the target OS in order to remove the need to install GHC toolchain,</li>
<li>It is hard to write and maintain <em>idempotent properties</em>: It would be simpler to be able to run propellor only once on a machine, forcing immutable infrastructure.</li>
</ul></li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Growing such a system was (and still is) a time-consuming and complex task, especially given our choice of technology which is not exactly mainstream. One might get the feeling we kept reinventing wheels and discovering problems that were already solved: After all, had we chosen to develop our system using PHP, Rails, Node.js or even Java we could have benefited from a huge ecosystem of tools and services to build, deploy and manage it. Here are some benefits I see from this “full-stack” approach:</p>
<ul>
<li>We <strong>know</strong> how our system works down to the system level, which allows us to take informed decisions on every part of it while understanding the global picture. The knowledge gained in the process of growing this system has a value in and of itself but is also an asset for the future: The better we know how the system works, the faster we can adpat it to changing requirements and constantly evolving environment,</li>
<li>It has been definitely frustrating at time but immensely fun to experiment, learn, tweak, fail or succeed, with all those moving parts,</li>
<li>It forces us to really think in terms of a single unified <strong>system</strong>: Being in charge of the whole lifecycle of your code, from writing the first line to deployment to production to retirement yields a sense of responsibility one does not gain from working in silos and throwing some bunch of code over the wall to ops team. This is truly <a href="http://www.jedi.be/blog/2010/02/12/what-is-this-devops-thing-anyway/">DevOps</a> in the way Patrick Debois initially coined the term, as a kind of system-thinking process and genuinely drives you to the <a href="http://queue.acm.org/detail.cfm?id=1142065">You build it, you run it</a> culture,</li>
<li>Managing operations, even at a small scale, is demanding, hence the need to think about automation, monitoring and short deployment cycles as early as possible in order to minimize the need for manual interventions.</li>
</ul>
<p>This completes a series of post I have written over the past few months, describing my experience building Capital Match platform:</p>
<ul>
<li><a href="/posts/cm-arch-design.html">Anatomy of a Haskell-based Application</a> described the overall design and architecture of the application,</li>
<li><a href="/posts/agile-startup.html">Using agile in a startup</a> detailed our development process,</li>
<li><a href="/posts/cm-infra-1.html">Haskell-based Development Environment</a> focused on the build system and development environment.</li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Haskell-based Development Environment</title>
    <link href="http://abailly.github.io/posts/cm-infra-1.html" />
    <id>http://abailly.github.io/posts/cm-infra-1.html</id>
    <published>2016-05-23T00:00:00Z</published>
    <updated>2016-05-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Haskell-based Development Environment</h1>
<div class="info">Posted on May 23, 2016</div>

<p>In a <a href="/posts/cm-arch-design.html">previous post</a> I described the overall design and architecture of Capital Match’s core system. I now turn to providing more details on our development and operations environment which uses mostly Haskell tools and code. As there are quite a lot of moving parts, this large topic will be covered in two posts: The present one will focus on basic principles, build tools and development environment ; it shall be followed by another post on configuration management, deployment and monitoring. I consider both development and production environments as a single integrated system as, obviously, there is a porous membrane between the two especially in a small company with 4 developers. Although I have been interested in that topic since my first systems programming course in university, some 18 years ago, I do not consider myself a genuine systems administrator and I made a lot of mistakes while building Capital Match platform. But I do believe in the <em>“you build it, you run it”</em> motto and this is all the more true for a small startup team. Hence I have tried to pay attention to building a flexible yet robust system.</p>
<h1 id="principles">Principles</h1>
<p>When we started to setup this environment, we were guided by a few principles:</p>
<ul>
<li>Automate, automate, automate: As much setup as possible should be automated,</li>
<li>Every system-level part should be containerized,</li>
<li>There should be a single versioned source of authority for configuration,</li>
<li>Use as much Haskell as possible.</li>
</ul>
<h2 id="automate">Automate</h2>
<blockquote>
<p>Automate all the things!</p>
</blockquote>
<p>Deployment to production should be as much automated as possible, involving as few manual steps as possible. The end goal is to reach a state of continuous deployment where pushed changes are built, verified and deployed continuously over the day. This implies all the steps involved in getting some feature delivered to end-users should be identified and linked into a coherent process that is implemented in code, apart from the actual coding of the feature itself. There should be no fiddling with SSHing on production machine to fix some configuration script, no manual migration process when upgrading data schema, no copying of binaries from development environment to production…</p>
<h2 id="everything-docker">Everything Docker</h2>
<blockquote>
<p>Containerize all the things!</p>
</blockquote>
<p><a href="http://docker.io">docker</a> is still a controversial technology, esp. among system and cloud specialists, and the topic of hot debates which is a sure sign it is a game changer. And back in 2014 when we started developing Capital Match’s platform, docker was in its infancy. I have had some experience in the past working with <a href="http://linux-vserver.org/Welcome_to_Linux-VServer.org">VServer</a> and <a href="https://linuxcontainers.org/">LXC</a> and containers are definitely great as a way to package (parts of) a system. Using docker allows us to:</p>
<ul>
<li>Provide seamless integration of development and production environments: The exact same software can be produced anywhere and used anywhere, whatever OS or configuration the actual developer is using, and the production configuration can be reproduced easily for testing or staging purposes,</li>
<li>Encapsulate components in immutable “packages” that require minimal system-level configuration, e.g. no more fiddling with ports, machine names, environment variables… docker-compose takes care of running everything, and we can make services dependent to stable names,</li>
<li>Simplify “hardware” configuration: All we need is something that is running docker (and a compatible kernel of course…) which means machines provisioning becomes a no-brainer,</li>
<li>Isolate build and run components from system-level dependencies conflicts,</li>
<li>Provide some level of reuse across containers and components thanks to layered FS.</li>
</ul>
<p>Note that we stuck to the initial docker “philosophy” of <em>one process per container</em>, except for some very specific needs (e.g. Selenium testing): It is not possible to ssh into our applicative containers.</p>
<h2 id="single-source-of-authority">Single Source of Authority</h2>
<blockquote>
<p>Version all the things!</p>
</blockquote>
<p>This means we should of course version our application’s code, but also the system’s configuration and as much dependencies as possible. Ideally, we should be able to reconstruct the whole system from a handful commands:</p>
<ul>
<li><code>git clone &lt;the repo&gt; cm</code></li>
<li><code>cd cm; ./build ; ./deploy</code></li>
</ul>
<p>In practice this is quite a bit more complicated as there are some glue parts missing to ensure the whole system can be rebuilt from scratch, but still we came quite close to that ideal. We are using 2 different repositories, one for the application code and one for the environment, mostly for technical reasons related to how our configuration management software works. The only unversioned part is the description of the “hardware” and the provisioning part which is still done “manually”.</p>
<h2 id="everything-haskell">Everything Haskell</h2>
<blockquote>
<p>Typecheck all the things!</p>
</blockquote>
<p>There is not a dearth of tools when it comes to configuration management, systems provisioning and deployment, build tools… When starting small you usually don’t want to invest a lot of time in learning new tools hence a common choice is simply to start small with shell scripts. But tools usually exist for a reason: Scripts quickly become a tangled maze of scattered knowledge. Yet we have at our disposal a powerful tool: Haskell itself, the language and its ecosystem, hence we decided to try as much as possible to stick to using Haskell-based tools. Beside the obvious simplification this brings us (one compiler, one toolchain, one language…), the advantages Haskell provides over other languages (type safety, lazy evaluation, immutable data structures) seemed to be equally valuable at the applicative level than at the system level.</p>
<h1 id="overview">Overview</h1>
<div class="figure">
<img src="/images/system-architecture.png" width="900" />

</div>
<p>The above figure gives a high-level overview of the system:</p>
<ul>
<li>Developers work on local machines (or <em>dev boxes</em>, see below), pushing changes to <a href="http://git-scm.com">git</a>,</li>
<li>Pushing to remote repository triggers build on <em>continuous integration</em> server <a href="https://github.com/ndmitchell/bake">bake</a>,</li>
<li>The final output of CI is a bunch of containers which are deployed to a private repositories on <a href="https://hub.docker.com/">docker hub</a>,</li>
<li>When we are ready to deploy, we update the system configuration in another git repository then run <a href="http://propellor.branchable.com/">propellor</a>,</li>
<li>This triggers configuration of <em>run</em> system which usually entails downloading correct container from repository and running it,</li>
<li>Data (also stored in a container) is regularly backed-up on S3,</li>
<li>Various components of the system feed events to <a href="http://riemann.io">riemann</a> monitoring system.</li>
</ul>
<h1 id="build-toolchain">Build &amp; Toolchain</h1>
<h2 id="build">Build</h2>
<h3 id="cabal">Cabal</h3>
<p>For building the Haskell part, we started obviously with <a href="https://www.haskell.org/cabal/">Cabal</a> which is the defacto build system/package manager in Haskell. The structure of GHC+Cabal packages system makes it quite hard to create insulated and <strong>reproducible</strong> build environments as there are various interactions between what’s installed globally (with GHC) and what’s installed per user and per project. There was no <a href="http://docs.haskellstack.org">stack</a> two years ago so we had to roll our own. Here are some key features of our cabal-based build:</p>
<ul>
<li>We used cabal snapshots with pinned down versions of all dependencies through <code>cabal freeze</code></li>
<li>Build became more complex when we started to add subpackages and sharing dependencies (&gt;100) seemed like a good idea. We shared a single sandbox by setting <code>CABAL_SANDBOX_CONFIG</code> to point to toplevel directory sandbox configuration file for all packages, then <code>add-source</code> sub-packages. This make it easier to simultaneously:
<ul>
<li>Build everything in one go,</li>
<li>Work in a sub-package,</li>
<li>Work in main (top-level) package,</li>
</ul></li>
<li>This does not prevent rebuilds when moving across packages as the build directory used by cabal is still located within each package,</li>
<li>We are still dependent on a globally available GHC. When upgrading GHC versions, you need to change globally installed GHC before rebuilding,</li>
<li>Several concurrent versions can coexist and be used in the same directory as GHC maintains version/OS dependent packages database, but care need to be taken with <code>PATH</code>s as the cabal version is likely different too…</li>
</ul>
<h3 id="stack">Stack</h3>
<p><a href="https://github.com/commercialhaskell/stack/">stack</a> represented a huge improvement for managing our build but it took us a few months to ensure it built consistently.</p>
<ul>
<li>Stack provides truly repeatable builds and segregate build environments tightly, including the tooling (compiler, lexer, parser…), managing downloads, setting package databases paths…</li>
<li>There is a single executable to install which makes creating build containers much easier: install stack, run setup and you have a fully configured container at required version. It is also very easy to upgrade,</li>
<li>Stack manages dependencies through <a href="https://www.stackage.org/">stackage</a> meaning you only have to provide a single version number and you are guaranteed to have compatible versions of libraries. This might be sometimes problematic if you require some specific version of a library that is not part of the dependency package, but it is still possible to provide custom versions,</li>
<li>I was sometimes surprised by stack not reusing some previous build result, although I could make it work manually,</li>
<li>The biggest hurdle we had to overcome to make stack work for us were the tests. Some tests relied on specific files to be present which means we had to manage relative paths: depending on whether or not tests are run from toplevel (which is the case in CI for example) or from local package directory (which is the case when using stack to build a tree of packages), relative directory may not be correctly set. Moreover stack runs tests in parallel, which is a good thing to force you to implement parallelizable tests but failed for us as we relied on starting server on some port for integration tests. We should get rid of hardwired port and allow the server to use some randomly allocated one but we chosed the simplest path and configured stack to run tests sequentially.</li>
<li>A minor annoyance is (was?) that stack maintains a build directory in each sub package, even when run from the toplevel, which is not the case when using cabal sandbox. This implies that reusing previous builds is a bit more cumbersome as one needs to save each <code>.stack-work</code> directory.</li>
</ul>
<h3 id="leiningen">Leiningen</h3>
<p><a href="http://leiningen.org/">leiningen</a> is (was?) the prominent build tool for clojure and clojurescript. We chose Clojurescript for the UI mostly because this allowed us to develop it using the excellent <a href="https://github.com/omcljs/om/">Om</a> wrapper over React. It took us quite a lot of time to get our project build comfortable and it did not evolve as quickly as the Haskell one.</p>
<ul>
<li>When to distinguish various build targets: Development mode where we want some interactive reload within the browser, test mode to run unit tests (automatically or in batch) and production mode which needs to be optimiszed,</li>
<li>Getting the tests to run correctly proved difficult and is still dependent on some manual configuration: To run clojurescript tests, we need to install <a href="http://phantomjs.org/">phantomjs</a> and configure correctly <a href="https://github.com/cljsjs/packages/wiki/Creating-Externs">externs</a> for the few javascript libraries we use and compile both code and tess <strong>with only whitespace</strong> optimizations (tests don’t run in fully optimized mode),</li>
<li>This actually means code is compiled as much as 3 times, which takes some time…</li>
<li>The CSS part of the UI is written using <a href="https://github.com/noprompt/garden">garden</a>, which means we have to compile it to proper CSS then pack and compress all CSS files together to improve load time. In retrospect, this was probably a mistake: We don’t use clojure’s power to write our CSS and it is still a mess, so we would have been better off using some standard CSS language like Less or Sass (although this adds the burden of running some thirdparty tool as part of the build…).</li>
</ul>
<h3 id="javascript">Javascript</h3>
<p>When we introduced the mobile UI for Capital Match, we had to integrate its build inside our process. This caused some headache as this part of the system is developed in pure Javascript using <a href="http://emberjs.com/">Emberjs</a> and relies on various tools in the JS ecosystem I was not familiar with. It also used <a href="http://sass-lang.com/">sass</a> to write CSS which means we needed ruby to run the compiler.</p>
<ul>
<li>We packaged all system-level dependencies into a single docker container. Note that official distribution’s package for node and npm were outdated hence we had to install them “by hand” in the container which is apparently the right way anyway,</li>
<li>There is a single top-level script which builds everything and is ran from the container.</li>
</ul>
<h3 id="shake">Shake</h3>
<p>Given the diversity of tools and components we are building, we needed a way to orchestrate build of the full solution which could be easily run as part of <em>Continuous integration</em>. We settled on <a href="http://shakebuild.com">shake</a> which is a Haskell-based tool similar to <em>make</em>.</p>
<ul>
<li>Rules are written in Haskell and shake provides support for all system-level tasks one would need to do in a build, including running arbitrary processes, manipulating their output, manipulating files… Using this embedded DSL makes it possible to track dependencies more easily. Shake maintains a database of dependencies that can be populated with arbitrary data,</li>
<li>The default target of our build is a list of docker containers, one for each service of the system plus the nginx container,</li>
<li>At the root of the dependency graph lies our build containers: one for <em>ghc + clojurescript</em> and one for building <em>javascript</em> code. Those containers are only expected to change (and be built) when we upgrade our toolchain. They are somewhat expensive to build as they need to provide all the needed tools to build (and run) our system,</li>
<li>On the server side, we use the <code>ghc-clojure</code> container to run a top-level build script that builds all services and the web UI. Given it takes ages to download and build all dependencies, then build all the various parts of the system, we tried to maximize reuse across builds: The build artifacts are exported as data containers and we link to the <span class="math inline"><em>n</em> − 1</span> build container in the <span class="math inline"><em>n</em></span> build run,</li>
<li>In order to minimize the size of our containers, we extract each service’s executable from the full build container and repack it into another container which contains a minimal runtime environment. We initially tried to do something like <a href="https://github.com/fpco/haskell-scratch/">haskell-scratch</a> but this did not work when our code needed to issue client-side HTTPS request: For some network and SSL reason the service fails to initialize properly. We resorted to use the standard busybox image, to which we add some prepackaged runtime libraries. This allows us to deploy containers with a “small” size: Our main application container weighs in at about 27MB and a typical service weighs 10MB. Note this has the additional benefit of drastically limiting the attack surface of the containers as they only contain the bare minimum to run our services and nothing else,</li>
<li>Shake build also contains rules to run different class of tests: Unit/integration server-side tests, UI tests and end-to-end-tests (see below), and rules to clean build artifacts and docker containers.</li>
</ul>
<h2 id="development-environment">Development Environment</h2>
<h3 id="haskell">Haskell</h3>
<p>There has been various attempts at providing an IDE for Haskell: * <a href="http://leksah.org/">leksah</a> is an Eclipse-based Haskell IDE, * <a href="http://haskellformac.com/">Haskell for Mac</a>, * FPComplete used to provide some web-based environment.</p>
<p>Having used emacs for years, I feel comfortable with and besides there are actually benefits using a plain-text tool for coding when you are part of a distributed team: It allows you to easily setup a distributed pairing environment with minimal latency. Yet configuring a proper Haskell development environment in Emacs can be a challenging task, and it seems this is a moving target.</p>
<ul>
<li>Starting from <a href="https://github.com/haskell/haskell-mode/">Haskell-mode</a> page is good idea as it is the base upon which one builds her own Emacs Haskell experience.</li>
<li><a href="https://github.com/serras/emacs-haskell-tutorial/blob/master/tutorial.md">Emacs haskell tutorial</a> provides some more details on how to set things up,</li>
<li><a href="https://github.com/chrisdone/emacs-haskell-config">Chris Done’s Haskell config</a> provides an easy to use full-blown configuration,</li>
<li>I tried <a href="https://github.com/chrisdone/structured-haskell-mode">SHM</a> a couple of times but could not get used to it, or could not make it work properly, or both… Might want to retry at some point in the future,</li>
<li><a href="http://tim.dysinger.net/posts/2014-02-18-haskell-with-emacs.html">this blog post</a> is a bit older but I remember having gone through it and try to reproduce some of the proposed features</li>
<li><a href="http://blog.hoersten.co/post/110096363794/modern-emacs-haskell-mode">This other post</a></li>
<li><a href="http://www.mew.org/~kazu/proj/ghc-mod/en/">ghc-mod</a> is useful but With cabal sandboxes and multiple projects it seems to be pretty unusable. I am also having a hard time making it work properly for test code: This requires different configurations and package dependencies are not properly picked up by ghc-mod. I need to investigate a bit more as I found this extension quite interesting,</li>
<li>Some people at Capital Match have started to use <a href="http://spacemacs.org/">spacemacs</a> which seems to come with a correctly configured Haskell environment out of the box.</li>
</ul>
<p>Here is my current .emacs content:</p>
<div class="sourceCode"><pre class="sourceCode scheme"><code class="sourceCode scheme">(eval-after-load <span class="st">&quot;haskell-mode&quot;</span>
  &#39;(progn
     (setq haskell-stylish-on-save t)
     (setq haskell-tags-on-save t)

     (setq haskell-process-type &#39;stack-ghci)
     (setq haskell-process-args-stack-ghci &#39;(<span class="st">&quot;--test&quot;</span>))
     
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-,&quot;</span>) &#39;haskell-move-nested-left)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-.&quot;</span>) &#39;haskell-move-nested-right)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c v c&quot;</span>) &#39;haskell-cabal-visit-file)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c v c&quot;</span>) &#39;haskell-cabal-visit-file)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c C-t&quot;</span>) &#39;ghc-show-type)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-x C-d&quot;</span>) nil)
     (setq haskell-font-lock-symbols t)

     <span class="co">;; Do this to get a variable in scope</span>
     (auto-complete-mode)

     <span class="co">;; from http://pastebin.com/tJyyEBAS</span>
     (ac-define-source ghc-mod
       &#39;((depends ghc)
         (candidates . (ghc-select-completion-symbol))
         (symbol . <span class="st">&quot;s&quot;</span>)
         (cache)))
     
     (defun my-ac-haskell-mode ()
       (setq ac-sources &#39;(ac-source-words-in-same-mode-buffers
                          ac-source-dictionary
                          ac-source-ghc-mod)))
     (add-hook &#39;haskell-mode-hook &#39;my-ac-haskell-mode)
     
  
     (defun my-haskell-ac-init ()
       (when (<span class="kw">member</span> (file-name-extension buffer-file-name) &#39;(<span class="st">&quot;hs&quot;</span> <span class="st">&quot;lhs&quot;</span>))
         (auto-complete-mode t)
         (setq ac-sources &#39;(ac-source-words-in-same-mode-buffers
                            ac-source-dictionary
                            ac-source-ghc-mod))))
     (add-hook &#39;find-file-hook &#39;my-haskell-ac-init)))

(add-hook &#39;haskell-mode-hook &#39;turn-on-haskell-decl-scan)
(add-hook &#39;haskell-mode-hook &#39;turn-on-haskell-indentation)
(add-hook &#39;haskell-mode-hook &#39;interactive-haskell-mode)

(add-hook &#39;haskell-interactive-mode-hook &#39;turn-on-comint-history)

(eval-after-load <span class="st">&quot;which-func&quot;</span>
  &#39;(add-to-list &#39;which-func-modes &#39;haskell-mode))

(eval-after-load <span class="st">&quot;haskell-cabal&quot;</span>
    &#39;(define-key haskell-cabal-mode-map (kbd <span class="st">&quot;C-c C-c&quot;</span>) &#39;haskell-compile))</code></pre></div>
<p>Thanks to discussions with <a href="https://twitter.com/solirc_">Simon</a> and <a href="https://twitter.com/amarpotghan">Amar</a> I am now using the REPL much more than I used to. My current workflow when working on Haskell code looks like:</p>
<ul>
<li>Load currently worked on file in interpreter using <code>C-c C-l</code>: This starts an inferior-haskell which is configured to use <code>stack ghci --test</code> under the hood, meaning all files including tests are in scope,</li>
<li>Code till it compiles properly and I can run a test,</li>
<li>Make test pass in the REPL,</li>
<li>When it’s OK, run full build, e.g. <code>stack test</code> in the console. This might trigger some more changes downstream which I need to fix,</li>
<li>When all unit tests pass, commit and push to CI.</li>
</ul>
<h3 id="clojurescript">Clojurescript</h3>
<p>The nice thing when using non-modern languages like Haskell and Clojure is that you only need to be able to edit text files to develop software, hence the choice of Emacs to develop both is kind of obvious. There is very good support for Clojure in emacs through <a href="https://github.com/clojure/tools.nrepl">nrepl</a> and <a href="https://github.com/clojure-emacs/cider">Cider</a> but it seems having the same level of support for Clojurescript is still challenging.</p>
<ul>
<li>When developping UI ClojureScript code, I mostly use <a href="https://github.com/bhauman/lein-figwheel">figwheel</a> which provides interactive reloading of code in the browser. One needs to start figwheel through <code>lein figwheel</code> which provides a REPL, then load the UI in a browser: The UI connects to the figwheel server which notifies it of code changes that trigger reload of the page,</li>
<li>For (mostly) non-UI code, I tend to favour TDD and use “autotesting” build: Changes in code trigger recompilation and run of all unit tests using the same configuration than batch run,</li>
<li><a href="http://wikemacs.org/wiki/Paredit-mode">paredit-mode</a> provides a structured way to edit LISP-like code: It automatically balances parens, brackets or double-quotes and provides dozens of shortcuts to manipulate the syntax tree ensuring syntactically correct transformations. I tend to use it as much as possible but sometimes find it cumbersome,</li>
<li>What I miss most when developing ClojureScript is a way to identify and navigate across symbols: I could not find an easy way to have some symbols index, something which is provided for Haskell through simple tags support. I am pretty sure there is something out there…</li>
</ul>
<h3 id="devbox">Devbox</h3>
<p>I already discussed in a <a href="/posts/agile-startup.html">previous blog post</a> how we managed to do pair programming with a distributed team. One of the virtual machines we configured was our <em>devbox</em> which we used to do remote pairing and run experiments.</p>
<ul>
<li>The initial configuration was done in the VM. It was pretty complex, requiring setting up full Haskell and ClojureScript toolchain, correct Emacs configuration which means installing and configuring emacs packages in scripts, setting user authentications…</li>
<li>It worked quite well however, except for the time to spin up a box from scratch. We were able to develop our software using the same tools we had on our laptops, except the fancy windowing UI: Emacs works exactly in the same way in a (proper) terminal and in a Mac OS X Window, once you correctly configuring key mappings for tmux and emacs over ssh,</li>
<li>At some point we turned to a container-based configuration with a <em>fat</em> container providing full development environment, including an X server for UI testing. Setting up the VM was much simpler as it only required installing docker but the development image was pretty large (about 4GB) and this meant long download time when pulling the docker image from scratch. This environment provided a full-blown X server which means we could log into it through VNC. However, we lost interactivity of pairing as it was not possible to share connection to X server which actually means it was pretty much useless,</li>
<li>We reverted back to configuring the VM itself but this time we used images snapshot to be able to restore the box quickly,</li>
<li>We also pushed emacs configuration to a <a href="https://github.com/capital-match/cm-dotfiles/blob/master/.emacs">shared git repository</a> which is pulled when configuring the machine, something we should have done earlier of course.</li>
</ul>
<h1 id="discussion">Discussion</h1>
<h2 id="build-process">Build process</h2>
<p>In retrospect I think the biggest issue we faced while developing the platform and working on the dev and prod infrastructure was fighting back increase in <em>build time</em> as we were adding new features and services. Building a deployable container <em>from scratch</em>, including creation of the build machine, configuration of build tools, creation of the needed containers, download and build of dependencies, testing, packaging would take about 2 hours. Here is the breakdown of time for some of the build stages according to the CI:</p>
<table>
<thead>
<tr class="header">
<th>Test</th>
<th>Mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>IntegrationTest</td>
<td>7m51s</td>
</tr>
<tr class="even">
<td>EndToEndTest</td>
<td>7m05s</td>
</tr>
<tr class="odd">
<td>Compile</td>
<td>6m05s</td>
</tr>
<tr class="even">
<td>ParallelDeploy</td>
<td>1m12s</td>
</tr>
<tr class="odd">
<td>UITest</td>
<td>53.46s</td>
</tr>
</tbody>
</table>
<p>Even if tests are run in parallel, this means it takes more than 10 minutes to get to the point where we can deploy code. Actually, CI tells us our mean time to deployable is about 30 minutes, which is clearly an issue we need to tackle. To reduce build time there is no better way than splitting the system into smaller chunks, something the team has been working on for a few months now and is paying off at least by ensuring we can add feature without increasing build time! The next step would be to split the core application which currently contains more than 80 files into more services and components.</p>
<p>On the positive side:</p>
<ul>
<li>Shake provides a somewhat more robust and clearer make, removing cryptic syntax and reliance on shell scripts. All the build is concentrated in a single Haskell source file that requires few dependencies to be built,</li>
<li>Haskell build tooling has been steadily improving in last couple of years especially since stack has taken a prominent position. Stack does not remove dependency on cabal but it actually reduces it what cabal does best: Providing a simple, descriptive configuration for building single packages ; and provides a definitely better experience regarding dependency management, build reproducibility and managing multiple build configuration,</li>
<li>I am less happy with the ClojureScript and Javascript parts, probably because I am much less familiar with them, hence I won’t enter trolling mode,</li>
<li>Packaging build environments with docker greatly reduces development friction: Issues can be reproduced very easily against a reference environment. Developer’s freedom is not comprised: Everyone is free to configure her own environment with CI acting as final gatekeeper while making troubleshooting somewhat easy (grab image and run it locally to reproduce problems),</li>
<li>Using containers also makes onboarding of new developers somewhat easier: They can focus on a single part of the system (e.g. UI) and rely on the containers to run a consistent environment locally.</li>
</ul>
<h2 id="development-environment-1">Development Environment</h2>
<p>The single feature I miss from my former Java development environment is <em>refactoring</em>: The ability to safely rename, move, extract code fragments with a couple key strokes across the whole code base lowers the practical and psychological barrier to improve your code <strong>now</strong>. GHC (esp. with <code>-Wall -Werror</code> flags on) catches of course a whole lot more errors than Javac or gcc but the process of fixing compiler errors after some refactoring of a deeply nested core function is time consuming. On the other hand the lack of global refactoring capabilities is a strong incentive to modularize and encapsulate your code in small packages which can be compiled and even deployed independently.</p>
<blockquote>
<p>To be continued…</p>
</blockquote>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Notes on Failing to Understand Software Transactional Memory</title>
    <link href="http://abailly.github.io/posts/note-on-stm.html" />
    <id>http://abailly.github.io/posts/note-on-stm.html</id>
    <published>2016-05-22T00:00:00Z</published>
    <updated>2016-05-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Notes on Failing to Understand Software Transactional Memory</h1>
<div class="info">Posted on May 22, 2016</div>

<p>I am writing some library to easily implement event sourced services in Haskell based on previous experience at Capital Match, and while doing so I rewrote a simple file-based event store. This store communicates with core service using <a href="https://hackage.haskell.org/package/stm-2.4.4.1/docs/Control-Concurrent-STM-TBQueue.html">TBQueue</a>, a bounded queue implemented over Haskell’s STM. It took me couple of hours on Friday to solve a <a href="http://hackage.haskell.org/package/base-4.8.2.0/docs/Control-Exception-Base.html#t:BlockedIndefinitelyOnSTM">BlockedIndefinitelyOnSTM</a> bug I was facing while testing this simple store. So today I posted a <a href="http://stackoverflow.com/questions/37376419/what-is-the-precise-reason-i-got-blocked-on-stm">question about STM</a> on Stack Overflow, as I did not have a clear intuition on why my code was failing, hence why my fix was correct.</p>
<p>The code of the store boils down to the following simple model.</p>
<p>First some useful imports…</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">{-# LANGUAGE ScopedTypeVariables #-}</span>
<span class="kw">module</span> <span class="dt">Main</span> <span class="kw">where</span>

<span class="kw">import           </span><span class="dt">Control.Concurrent.Async</span>
<span class="kw">import           </span><span class="dt">Control.Concurrent.STM</span>
<span class="kw">import           </span><span class="dt">Control.Exception</span>
<span class="kw">import           </span><span class="dt">Control.Monad</span>            (forever)
<span class="kw">import           </span><span class="dt">Hevents.Eff</span>
<span class="kw">import           </span><span class="dt">System.IO</span></code></pre></div>
<p>The store dequeues some <em>operation</em> from a given queue, writes the operation’s string to <code>stdout</code> then put back the length of the written string into a <a href="http://hackage.haskell.org/package/stm-2.4.4.1/docs/Control-Concurrent-STM-TMVar.html">TMVar</a>, which models communicating the result of the operation back to the caller.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Op</span> <span class="fu">=</span> <span class="dt">Op</span> <span class="dt">String</span> (<span class="dt">TMVar</span> <span class="dt">Int</span>)

<span class="ot">storerun ::</span> <span class="dt">TBQueue</span> <span class="dt">Op</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
storerun q <span class="fu">=</span> <span class="kw">do</span>
  h <span class="ot">&lt;-</span> openFile <span class="st">&quot;store.test&quot;</span> <span class="dt">ReadWriteMode</span>
  hSetBuffering h <span class="dt">NoBuffering</span>
  forever <span class="fu">$</span> <span class="kw">do</span>
    <span class="dt">Op</span> s v <span class="ot">&lt;-</span> atomically <span class="fu">$</span> readTBQueue q
    hPutStrLn h s
    atomically <span class="fu">$</span> putTMVar v (length s)</code></pre></div>
<p>The <code>main</code> function is responsible for creating the jobs queue, starting the “store” in a separate thread then reading lines from <code>stdin</code> and feeding them as “operations” for the store.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> <span class="kw">do</span>
  q <span class="ot">&lt;-</span> newTBQueueIO <span class="dv">100</span>
  _ <span class="ot">&lt;-</span> async <span class="fu">$</span> storerun q
  storeInput q
  <span class="kw">where</span>
    storeInput q <span class="fu">=</span> forever <span class="fu">$</span> <span class="kw">do</span>
      l <span class="ot">&lt;-</span> getLine
      v <span class="ot">&lt;-</span> newEmptyTMVarIO
      r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> <span class="kw">do</span>
        writeTBQueue q (<span class="dt">Op</span> l v)
        takeTMVar v</code></pre></div>
<p>This code deadlocks because STM are actually - surprise! - <strong>transactions</strong>: They do all of their operations, or nothing, and they are serialized. Hence the following block:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> <span class="kw">do</span>
  writeTBQueue q (<span class="dt">Op</span> l v)
  takeTMVar v</code></pre></div>
<p>…can succeeds <em>if and only if</em> it can <strong>atomically</strong> put an operation in the queue and read the result back from <code>v</code>. Which of course is not possible because the result is put back after the operation is read from the queue in another transaction. The correct code is:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">atomically <span class="fu">$</span> writeTBQueue q (<span class="dt">Op</span> l v)
r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> takeTMVar v</code></pre></div>
<p>Pretty obvious, in retrospect. As the person who answered my question on SO, there is no way for two STM transactions to <em>exchange</em> information.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Life Beyond Relational Database in Haskell - The case for Event Sourcing</title>
    <link href="http://abailly.github.io/posts/event-source.html" />
    <id>http://abailly.github.io/posts/event-source.html</id>
    <published>2016-05-12T00:00:00Z</published>
    <updated>2016-05-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Life Beyond Relational Database in Haskell - The case for Event Sourcing</h1>
<div class="info">Posted on May 12, 2016</div>

<p>This post contains the code I demonstrated as part of my talk at <a href="http://ncrafts.io">nCrafts</a>. This work is based on the following references (stepping on the shoulders of giants, as always…):</p>
<ul>
<li><a href="http://okmij.org/ftp/Haskell/extensible/exteff.pdf">Extensible effects paper</a>: Extensible effects theory and practice in Haskell</li>
<li><a href="https://github.com/atnos-org/eff-cats">eff-cats</a>: Same in Scala</li>
<li><a href="http://www.cse.chalmers.se/~rjmh/Papers/QuickCheckST.ps">Testing monadic code with QuickCheck</a></li>
<li><a href="http://abailly.github.io/posts/cm-arch-design.html">Blog post</a> about the architecture implemented at Capital Match</li>
<li>Work-in-progress <a href="https://github.com/abailly/hevents">Haskell library</a> to simplify developing event sourced systems</li>
<li>Original <a href="http://shaffner.us/cs/papers/tarpit.pdf">Out of the Tar Pit</a> paper</li>
</ul>
<h1 id="imports-stuff-to-make-the-compiler-happy">Imports, stuff to make the compiler happy</h1>
<p>We first add the usual <code>LANGUAGE</code> extension incantations… Note they should probably go in to the <code>.cabal</code> file.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">{-# LANGUAGE DataKinds             #-}</span>
<span class="ot">{-# LANGUAGE FlexibleInstances     #-}</span>
<span class="ot">{-# LANGUAGE MultiParamTypeClasses #-}</span>
<span class="ot">{-# LANGUAGE OverloadedStrings     #-}</span>
<span class="ot">{-# LANGUAGE ScopedTypeVariables   #-}</span>
<span class="ot">{-# LANGUAGE TypeOperators         #-}</span>
<span class="kw">module</span> <span class="dt">Hevents.Eff.Demo</span> <span class="kw">where</span></code></pre></div>
<p>Then a whole bunch of imports… I never managed to choose a definite course of action on whether to import full module, import qualified, import only selected symbols. Seems to me this is pretty much a team-level convention.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import           </span><span class="dt">Control.Category</span>
<span class="kw">import           </span><span class="dt">Control.Concurrent.Async</span>
<span class="kw">import           </span><span class="dt">Control.Concurrent.STM</span>
<span class="kw">import qualified</span> <span class="dt">Control.Eff</span>                <span class="kw">as</span> <span class="dt">E</span>
<span class="kw">import           </span><span class="dt">Control.Eff.Exception</span>
<span class="kw">import           </span><span class="dt">Control.Eff.Lift</span>           <span class="kw">as</span> <span class="dt">E</span> <span class="kw">hiding</span> (lift)
<span class="kw">import           </span><span class="dt">Control.Exception</span>          (finally)
<span class="kw">import           </span><span class="dt">Control.Monad.Except</span>
<span class="kw">import qualified</span> <span class="dt">Control.Monad.State</span>        <span class="kw">as</span> <span class="dt">ST</span>
<span class="kw">import           </span><span class="dt">Control.Monad.Trans.Either</span>
<span class="kw">import qualified</span> <span class="dt">Data.ByteString.Builder</span>    <span class="kw">as</span> <span class="dt">BS</span>
<span class="kw">import           </span><span class="dt">Data.Either</span>                (rights)
<span class="kw">import           </span><span class="dt">Data.Proxy</span>
<span class="kw">import           </span><span class="dt">Data.Serialize</span>             (<span class="dt">Serialize</span>, get, put)
<span class="kw">import           </span><span class="dt">Data.Typeable</span>
<span class="kw">import           </span><span class="dt">Data.Void</span>
<span class="kw">import           </span><span class="dt">Hevents.Eff</span>                <span class="kw">as</span> <span class="dt">W</span>
<span class="kw">import           </span><span class="dt">Prelude</span>                    <span class="kw">hiding</span> (init, (.))
<span class="kw">import           </span><span class="dt">Servant</span>
<span class="kw">import           </span><span class="dt">Servant.Client</span>
<span class="kw">import           </span><span class="dt">System.Environment</span>
<span class="kw">import           </span><span class="dt">Test.Hspec</span>
<span class="kw">import           </span><span class="dt">Test.QuickCheck</span>            <span class="kw">as</span> <span class="dt">Q</span>
<span class="kw">import           </span><span class="dt">Test.QuickCheck.Monadic</span>    <span class="kw">as</span> <span class="dt">Q</span></code></pre></div>
<h1 id="the-business-domain">The “Business Domain”</h1>
<p>We want to implement an event-sourced service that will allow us to manipulate a simple integer <em>counter</em>:</p>
<ul>
<li>Our counter changes when some value is <em>added</em> to it,</li>
<li>A value is added when a command is issued that <em>increments</em> the counter,</li>
<li>We also want to modify the counter when a <em>decrement</em> command is issued, which means a <em>negative</em> value will be <em>added</em> to the counter,</li>
<li>We want our counter to be <em>bounded</em>: It shall never go below 0 or beyond 100,</li>
<li>And its initial value will be 0.</li>
</ul>
<h1 id="lets-start-writing-a-test">Let’s start writing a test…</h1>
<p>We’ll first write some property describing the behaviour of our model for a single command. We expect that an <code>Increment</code> command shall set an <code>init</code>ialized counter to the same value than the command, and that a <code>Decrement</code> command will decrease the value of a counter. Note here we anticipate a bit on bounds requirement checking by setting the counter to some value which is greater than any <code>Decrement</code> command we are supposed to issue.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">prop_shouldApplySingleCommandRespectingBounds ::</span> <span class="dt">Command</span> <span class="dt">Counter</span><span class="fu">*&gt;</span> <span class="dt">Bool</span>
prop_shouldApplySingleCommandRespectingBounds c<span class="fu">@</span>(<span class="dt">Increment</span> n) <span class="fu">=</span>
    <span class="kw">let</span> <span class="dt">OK</span> result <span class="fu">=</span> init <span class="ot">`act`</span> c
    <span class="kw">in</span>  init <span class="ot">`apply`</span> result <span class="fu">==</span> <span class="dt">Counter</span> n
prop_shouldApplySingleCommandRespectingBounds c<span class="fu">@</span>(<span class="dt">Decrement</span> n) <span class="fu">=</span>
    <span class="kw">let</span> bounderCounter <span class="fu">=</span> <span class="dt">Counter</span> singleCommandUpperBound
        <span class="dt">OK</span> result <span class="fu">=</span> bounderCounter <span class="ot">`act`</span> c
    <span class="kw">in</span>  bounderCounter <span class="ot">`apply`</span> result <span class="fu">==</span> <span class="dt">Counter</span> (singleCommandUpperBound <span class="fu">-</span> n)</code></pre></div>
<p>This property requires some way to generate <code>Arbitrary</code> instances of our commands, which is straightforward:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Arbitrary</span> (<span class="dt">Command</span> <span class="dt">Counter</span>) <span class="kw">where</span>
  arbitrary <span class="fu">=</span> oneof [ <span class="dt">Increment</span> <span class="fu">&lt;$&gt;</span> singleCommandValue
                    , <span class="dt">Decrement</span> <span class="fu">&lt;$&gt;</span> singleCommandValue
                    ]
    <span class="kw">where</span>
        singleCommandValue <span class="fu">=</span> choose (<span class="dv">0</span>,singleCommandUpperBound)

<span class="ot">singleCommandUpperBound ::</span> <span class="dt">Int</span>
singleCommandUpperBound <span class="fu">=</span> <span class="dv">20</span></code></pre></div>
<p>Another useful property we want to define that our counter respects its bounds, no matter which sequence of events we send to it:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">prop_shouldNotApplyCommandsOverBounds ::</span> [ <span class="dt">Command</span> <span class="dt">Counter</span> ] <span class="ot">-&gt;</span> <span class="dt">Bool</span>
prop_shouldNotApplyCommandsOverBounds commands <span class="fu">=</span>
  <span class="kw">let</span> finalCounter <span class="fu">=</span> ST.execState (mapM updateModel commands) init
  <span class="kw">in</span>  isWithinBounds finalCounter

<span class="ot">isWithinBounds ::</span> <span class="dt">Counter</span> <span class="ot">-&gt;</span> <span class="dt">Bool</span>
isWithinBounds (<span class="dt">Counter</span> value) <span class="fu">=</span> value <span class="fu">&gt;=</span> <span class="dv">0</span> <span class="fu">&amp;&amp;</span> value <span class="fu">&lt;=</span> <span class="dv">100</span></code></pre></div>
<p>And of course we need some implementation of our <code>Command</code>s and <code>Counter</code>. The latter is pretty much a simple wrapping of <code>Int</code> but to define the former we need our <code>Counter</code> type to be an instance of <a href="https://github.com/abailly/hevents/blob/master/src/Hevents/Eff/Model.lhs">Model</a> typeclass, which defines the basic structure of an event-sourced component (or aggregate).</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">Counter</span> <span class="fu">=</span> <span class="dt">Counter</span> {<span class="ot"> counter ::</span> <span class="dt">Int</span> } <span class="kw">deriving</span> (<span class="dt">Eq</span>,<span class="dt">Show</span>)

<span class="kw">instance</span> <span class="dt">Model</span> <span class="dt">Counter</span> <span class="kw">where</span></code></pre></div>
<p>We define the “component” types of our model: Commands, events and errors which here are very simple.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">  <span class="kw">data</span> <span class="dt">Command</span> <span class="dt">Counter</span> <span class="fu">=</span> <span class="dt">Increment</span> <span class="dt">Int</span>
                       <span class="fu">|</span> <span class="dt">Decrement</span> <span class="dt">Int</span>
                       <span class="kw">deriving</span> (<span class="dt">Eq</span>, <span class="dt">Show</span>)
  <span class="kw">data</span> <span class="dt">Event</span> <span class="dt">Counter</span> <span class="fu">=</span> <span class="dt">Added</span> <span class="dt">Int</span> <span class="kw">deriving</span> (<span class="dt">Eq</span>,<span class="dt">Show</span>)
  <span class="kw">data</span> <span class="dt">Error</span> <span class="dt">Counter</span> <span class="fu">=</span> <span class="dt">OutOfBounds</span> <span class="kw">deriving</span> (<span class="dt">Eq</span>,<span class="dt">Show</span>)</code></pre></div>
<p>Then comes our initial value…</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">  init <span class="fu">=</span> <span class="dt">Counter</span> <span class="dv">0</span></code></pre></div>
<p><code>act</code> computes the effect of applying a command to current state of our counter…</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">
  <span class="dt">Counter</span> k <span class="ot">`act`</span> <span class="dt">Increment</span> n <span class="fu">=</span> <span class="kw">if</span> k <span class="fu">+</span> n <span class="fu">&lt;=</span> <span class="dv">100</span>
                                <span class="kw">then</span> <span class="dt">OK</span> <span class="fu">$</span> <span class="dt">Added</span> n
                                <span class="kw">else</span> <span class="dt">KO</span> <span class="dt">OutOfBounds</span>

  <span class="dt">Counter</span> k <span class="ot">`act`</span> <span class="dt">Decrement</span> n <span class="fu">=</span> <span class="kw">if</span> k <span class="fu">-</span> n <span class="fu">&gt;=</span> <span class="dv">0</span>
                                <span class="kw">then</span> <span class="dt">OK</span> <span class="fu">$</span> <span class="dt">Added</span> (<span class="fu">-</span>n)
                                <span class="kw">else</span> <span class="dt">KO</span> <span class="dt">OutOfBounds</span></code></pre></div>
<p>Then <code>apply</code> actually “updates” (or more precisely, create a new updated instance of) the counter by applying the value to add.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">  <span class="dt">Counter</span> k <span class="ot">`apply`</span> <span class="dt">Added</span> n <span class="fu">=</span> <span class="dt">Counter</span> <span class="fu">$</span> k <span class="fu">+</span> n</code></pre></div>
<p>When we check the behaviour of applying a sequence of <code>Command</code>s to our counter, we make use of a library function which runs in the <code>State</code> monad and allow us to “fold” the application of a sequence of commands to a <code>Counter</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">updateModel ::</span> (<span class="dt">Model</span> a) <span class="ot">=&gt;</span> <span class="dt">Command</span> a <span class="ot">-&gt;</span> <span class="dt">State</span> a (<span class="dt">Result</span> a)</code></pre></div>
<h1 id="exposing-services-built-on-our-model">Exposing services built on our model</h1>
<p>As always, we start with the testing part but this time we expect our tests to have side effects and model interactions of the outside world with our system’s fragment. We shall start with very simple modelling of client’s behaviour:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">CounterAction</span> <span class="fu">=</span> <span class="dt">GetCounter</span>
                   <span class="fu">|</span> <span class="dt">IncCounter</span> <span class="dt">Int</span>
                   <span class="fu">|</span> <span class="dt">DecCounter</span> <span class="dt">Int</span>
                   <span class="kw">deriving</span> (<span class="dt">Show</span>)</code></pre></div>
<p>In order to generate samples for our actions we assume some frequency distribution, giving more weight to actions that get state than to actions that update it.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">
<span class="kw">instance</span> <span class="dt">Arbitrary</span> <span class="dt">CounterAction</span> <span class="kw">where</span>
  arbitrary <span class="fu">=</span> frequency [ (<span class="dv">3</span>, return <span class="dt">GetCounter</span>)
                        , (<span class="dv">2</span>, <span class="dt">IncCounter</span> <span class="fu">&lt;$&gt;</span> choose (<span class="dv">0</span>,<span class="dv">10</span>))
                        , (<span class="dv">1</span>, <span class="dt">DecCounter</span> <span class="fu">&lt;$&gt;</span> choose (<span class="dv">0</span>,<span class="dv">10</span>))
                        ]</code></pre></div>
<p>Then we use monadic QuickCheck to run an <code>arbitrary</code> sequence of user actions on an “effectful” model which is initialised with some state holder and a storage backend.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">prop_servicesRespectCounterBounds ::</span> [ <span class="dt">CounterAction</span> ] <span class="ot">-&gt;</span> <span class="dt">Property</span>
prop_servicesRespectCounterBounds actions <span class="fu">=</span> Q.monadicIO <span class="fu">$</span> <span class="kw">do</span>
  results <span class="ot">&lt;-</span> Q.run <span class="fu">$</span> <span class="kw">do</span>
    (model, storage) <span class="ot">&lt;-</span> prepareContext
    mapM (effect storage model <span class="fu">.</span> interpret) actions

  assert <span class="fu">$</span> all isWithinBounds (rights results)</code></pre></div>
<p>This test might be considered to be a little weak, and we could probably enhance it with testing error conditions. That’s something definitely worth doing for production code, however for the sake of simplicity we will not add more tests here.</p>
<p>Prparation step is simple but deserve some explanations:</p>
<ul>
<li>We create a <code>Counter</code> with some initial value and wrap it in a <em>transactional variable</em> because our underlying <code>State</code> effects works within the <code>STM</code> monad. This is so in order to ensure proper atomicity of commands on the model in face of concurrent access,</li>
<li>We create a simple in-memory store, which is a STM-based bounded queue.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">prepareContext <span class="fu">=</span> (,)           <span class="fu">&lt;$&gt;</span>
  newTVarIO (W.init<span class="ot"> ::</span> <span class="dt">Counter</span>) <span class="fu">&lt;*&gt;</span>
  atomically W.makeMemoryStore</code></pre></div>
<p><code>effect</code> is actually a natural transformation that composes all the small little effects we need in our sample and “lift” them in the <code>IO</code> monad. Note the <code>Eff</code> type which exposes explicitly all the effects our code is allowed to make thus constraining its behaviour to a limited subset of possible interactions with outside world. The <code>ServantErr</code> type is the type of <em>exceptions</em> we can “throw” using <code>Exc</code> effect: This anticipates on the needs of the REST API we shall expose later on. Actually it could have been any kind of <code>Exception</code> instance but once again, this makes things simpler and removes a layer of transformation from custom exceptions to Servant errors, something we would probably want to do in production code.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">EventSourced</span> s e a <span class="fu">=</span>
  <span class="dt">E.Eff</span> (<span class="dt">State</span> s <span class="fu">E.:&gt;</span> <span class="dt">Store</span> <span class="fu">E.:&gt;</span> <span class="dt">Exc</span> e <span class="fu">E.:&gt;</span> <span class="dt">Lift</span> <span class="dt">STM</span> <span class="fu">E.:&gt;</span> <span class="dt">Void</span>) a

<span class="ot">effect ::</span> (<span class="dt">Typeable</span> m, <span class="dt">Typeable</span> e, <span class="dt">Storage</span> <span class="dt">STM</span> s, <span class="dt">Registrar</span> <span class="dt">STM</span> m reg)
         <span class="ot">=&gt;</span> s <span class="ot">-&gt;</span> reg
         <span class="ot">-&gt;</span> <span class="dt">E.Eff</span> (<span class="dt">EventSourced</span> <span class="dt">Counter</span> <span class="dt">ServantErr</span>) a
         <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">Either</span> e a)
effect s m <span class="fu">=</span> atomically <span class="fu">.</span> runSync <span class="fu">.</span> runExc <span class="fu">.</span> W.runStore s <span class="fu">.</span>  W.runState m</code></pre></div>
<p>The definition of our services is pretty straightforward:</p>
<ul>
<li><code>getCounter</code> simply return the state of the counter,</li>
<li><code>increment</code> and <code>decrement</code> both send the corresponding commands and store the resulting event, returning the content of the counter.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">CounterService</span> a <span class="fu">=</span> <span class="dt">EventSourced</span> <span class="dt">Counter</span> <span class="dt">ServantErr</span> a

<span class="ot">getCounter ::</span> <span class="dt">CounterService</span> <span class="dt">Int</span>
getCounter <span class="fu">=</span> counter <span class="fu">&lt;$&gt;</span> getState

<span class="ot">increment ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">CounterService</span> <span class="dt">Int</span>
increment n <span class="fu">=</span> applyCommand (<span class="dt">Increment</span> n) <span class="fu">&gt;&gt;=</span> storeEvent

<span class="ot">decrement ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">CounterService</span> <span class="dt">Int</span>
decrement n <span class="fu">=</span> applyCommand (<span class="dt">Decrement</span> n) <span class="fu">&gt;&gt;=</span> storeEvent</code></pre></div>
<p>The <code>storeEvent</code> function is where most of the grunt work happens and notably where we do error handling:</p>
<ul>
<li>We first try to <code>store</code> the produced <code>Event Counter</code>, and if this succeeds we return the state of the counter. If this fails, we convert the error in a <code>500</code> error, passing some hopefully useful message,</li>
<li>If the input is an <code>Error Counter</code> we simply rethrow the converted error as a <code>400</code> error, all errors produced by commands represent precondition violations of the model’s specification.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">storeEvent ::</span> <span class="dt">Either</span> (<span class="dt">Error</span> <span class="dt">Counter</span>) (<span class="dt">Event</span> <span class="dt">Counter</span>)
             <span class="ot">-&gt;</span> <span class="dt">CounterService</span> <span class="dt">Int</span>
storeEvent (<span class="dt">Left</span> e)  <span class="fu">=</span> throwExc <span class="fu">$</span> fromModelError e
storeEvent (<span class="dt">Right</span> e) <span class="fu">=</span> store e <span class="fu">&gt;&gt;=</span> either (throwExc <span class="fu">.</span> fromDBError) (const <span class="fu">$</span> counter <span class="fu">&lt;$&gt;</span> getState)
  <span class="kw">where</span>
    fromModelError e <span class="fu">=</span> err400 { errBody <span class="fu">=</span> makeBody <span class="fu">$</span> <span class="st">&quot;Invalid command &quot;</span> <span class="fu">++</span> show e }
    fromDBError    e <span class="fu">=</span> err500 { errBody <span class="fu">=</span> makeBody <span class="fu">$</span> <span class="st">&quot;DB Error &quot;</span> <span class="fu">++</span> show e }
    makeBody         <span class="fu">=</span> BS.toLazyByteString <span class="fu">.</span> BS.stringUtf8</code></pre></div>
<p>Note that because of the <code>Store</code> effect we need to be able to <em>serialize</em> our events:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Serialize</span> (<span class="dt">Event</span> <span class="dt">Counter</span>) <span class="kw">where</span>
  put (<span class="dt">Added</span> i) <span class="fu">=</span> put i
  get           <span class="fu">=</span> <span class="dt">Added</span> <span class="fu">&lt;$&gt;</span> get</code></pre></div>
<p>The last missing piece is the <code>interpret</code> function which turns our QuickCheck generated actions into actual effectful actions to be run against our system.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">interpret <span class="dt">GetCounter</span>     <span class="fu">=</span> getCounter
interpret (<span class="dt">IncCounter</span> n) <span class="fu">=</span> increment n
interpret (<span class="dt">DecCounter</span> n) <span class="fu">=</span> decrement n</code></pre></div>
<h1 id="expose-our-counter-services-through-a-rest-api">Expose our counter services through a REST API</h1>
<p>The last step of our Counter “microservice” is to expose it as a REST interface. We will leverage the excellent work done on the <a href="http://servant.github.io">Servant</a> and firstly define out API’s type which is a simple exposition of the previously defined services:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">
<span class="kw">type</span> <span class="dt">CounterApi</span> <span class="fu">=</span>
 <span class="st">&quot;counter&quot;</span> <span class="fu">:&gt;</span> (<span class="dt">Get</span> <span class="ch">&#39;[JSON] Int</span>
              <span class="fu">:&lt;|&gt;</span> <span class="st">&quot;increment&quot;</span> <span class="fu">:&gt;</span> <span class="dt">Capture</span> <span class="st">&quot;inc&quot;</span> <span class="dt">Int</span> <span class="fu">:&gt;</span> <span class="dt">Get</span> <span class="ch">&#39;[JSON] Int</span>
              <span class="fu">:&lt;|&gt;</span> <span class="st">&quot;decrement&quot;</span> <span class="fu">:&gt;</span> <span class="dt">Capture</span> <span class="st">&quot;dec&quot;</span> <span class="dt">Int</span> <span class="fu">:&gt;</span> <span class="dt">Get</span> <span class="ch">&#39;[JSON] Int)</span>

<span class="ot">counterApi ::</span> <span class="dt">Proxy</span> <span class="dt">CounterApi</span>
counterApi <span class="fu">=</span> <span class="dt">Proxy</span></code></pre></div>
<p>Writing our test is pretty straightforward and mostly repeats the previous test at the service level layer, the main difference being the effectful services are run within an actual web server on some predefined port. Note this is makes our test brittle and non parallelizable: It would be better to let the server select a free port and return it as part of its startup.</p>
<p>The only noteworthy part is that we can use our previously defined <code>effect</code> “interpreter” natural transformation and wrap it inside an <code>EitherT</code> transformer which is the type expected by Servant.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">prop_counterServerImplementsCounterApi ::</span> [ <span class="dt">CounterAction</span> ] <span class="ot">-&gt;</span> <span class="dt">Property</span>
prop_counterServerImplementsCounterApi actions <span class="fu">=</span> Q.monadicIO <span class="fu">$</span> <span class="kw">do</span>
  results <span class="ot">&lt;-</span> Q.run <span class="fu">$</span> <span class="kw">do</span>
    (model, storage) <span class="ot">&lt;-</span> prepareContext
    server <span class="ot">&lt;-</span> W.runWebServerErr <span class="dv">8082</span> counterApi
                  (<span class="dt">Nat</span> <span class="fu">$</span> <span class="dt">EitherT</span> <span class="fu">.</span> effect storage model) handler
    mapM runClient actions <span class="ot">`finally`</span> cancel server

  assert <span class="fu">$</span> all isWithinBounds (rights results)</code></pre></div>
<p>The client-side services are obtained from a destructured assignment using Servant’s <code>(:&lt;|&gt;)</code> operator which is overloaded at the type and value level and then used to interpret user actions.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">counterState <span class="fu">:&lt;|&gt;</span> incCounter <span class="fu">:&lt;|&gt;</span> decCounter <span class="fu">=</span> client counterApi (<span class="dt">BaseUrl</span> <span class="dt">Http</span> <span class="st">&quot;localhost&quot;</span> <span class="dv">8082</span>)

runClient <span class="dt">GetCounter</span>     <span class="fu">=</span> runEitherT <span class="fu">$</span> counterState
runClient (<span class="dt">IncCounter</span> n) <span class="fu">=</span> runEitherT <span class="fu">$</span> incCounter n
runClient (<span class="dt">DecCounter</span> n) <span class="fu">=</span> runEitherT <span class="fu">$</span> decCounter n</code></pre></div>
<p>It is also noteworthy we can simply build our REST server composing our already defined services. Servant’s type wizardy ensures the expected type for the whole API is matched by actual functions composed with <code>(:&lt;|&gt;)</code>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">handler <span class="fu">=</span> getCounter <span class="fu">:&lt;|&gt;</span> increment <span class="fu">:&lt;|&gt;</span> decrement</code></pre></div>
<p>Writing a <code>main</code> server that is able to listen on some port and runs our services is left as an exercise for the reader.</p>
<h1 id="conclusion">Conclusion</h1>
<p>The goal of this post and the associated talk was to demonstrate how Haskell’s type system and some well designed and though out libraries made it easy to build type-safe “microservices”. In particular, I would like to emphasize the following points:</p>
<ul>
<li>Haskell’s pure functional core makes it a perfect fit for designing, implementing and experimenting business domain models using <em>Domain Driven Design</em> principles: Use a common language which here is embedded in the form of commands, events and errors, provide a pure core which implements core business rules and can be very easily tested, wrap that pure core within a <em>Hexagonal architecture</em> providing needed side-effects…</li>
<li>QuickCheck is a great tool for doing <em>Test Driven Development</em> of such models: One can use it to expose assumptions about the behaviour of the model’s clients in the form of <em>Arbitrary</em> instances and then test potentially complex sequences of actions against the model,</li>
<li>Using monadic QuickCheck, it is possible to leverage that technique at any level of the system’s stack, making it easy to test various effects of our system and how it interacts with the outside world. Something that we could introduce here is testing the server with multiple concurrent clients and then checking our model doesn’t break its invariants in the face of concurrent accesses,</li>
<li>The <em>Extensible effects</em> framework allows us to define and compose tiny effectful “DSLs” over the core domain DSL. More importantly, thanks to its extensibility, it is possible to define new effects without having to recompile any of our existing services (note this would require our services’ types to be more lax, using typeclass constraints instead of concrete type for the <em>Eff</em> monad).</li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Critique de la raison pure&quot;</title>
    <link href="http://abailly.github.io/posts/kant.html" />
    <id>http://abailly.github.io/posts/kant.html</id>
    <published>2016-05-05T00:00:00Z</published>
    <updated>2016-05-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Critique de la raison pure&quot;</h1>
<div class="info">Posted on May  5, 2016</div>

<p>Ceci est une retranscription d’un cours improvisé par <a href="https://directory.unamur.be/staff/pavez">Peggy Penez-Avez</a> lors d’une session d’<a href="http://agenda-agile.org/showevent.php?id=487">Agile Open France 2016</a>, conçu plus ou moins comme une expérimentation du <a href="http://dojophilo.net/">Dojo Philo</a>. J’ai pu ajouté quelques notes personnelles…</p>
<ul>
<li>Kant développe une <em>philosophie transcendantal</em> et cherche à répondre à la question <em>“que puis-je connaître ?”</em>, qui peut se comprendre à la fois comme <em>“qu’est ce qui est digne d’être connu ?”</em> et <em>“qu’est ce que mes facultés me permettent de connaître ?”</em></li>
<li>Il s’agit donc d’explorer les condition de possibilité d’une connaissance, qui se résument (à l’époque de Kant) à trois approches:
<ul>
<li><strong>dogmatique</strong>: on peut tout connaître et en particulier l’existence de Dieu peut être objet d’une connaissance, toute la métaphysique est un objet de connaissance. Le problème, c’est que les thèses métaphysiques sont en désaccord les unes avec les autres, qu’il semble ne pas y avoir de progrès dans ce domaine : peut on vraiment parler de connaissance alors ?</li>
<li><strong>sceptique et empiriste</strong>: Hume réveille Kant du sommeil de la raison. Pour les sceptiques, la base des idées ce sont les observations et l’expérience, pas la raison (interne) : je dis que le soleil va se lever parce que j’en ai l’habitude, qu’il se lève tous les matins que j’ai pu expérimenter. L’esprit a l’habitude de voir une succession entre les phénomènes et en déduit une relation de <em>causalité</em> mais rien ne permet de prouver que c’est bien la réalité (en termes modernes, on pourrait parler d’une confusion entre <em>corrélation</em> et <em>causation</em>). Ce qu’on prend pour de la connaissance n’est que de la <em>croyance partagée</em></li>
<li><strong>critique</strong>: l’expérience est fondamentale pour qu’il y ait connaissance, mais pas que. C’est l’approche de Kant.</li>
</ul></li>
<li>Les questions de l’existence de Dieu, de l’âme et d’autres questions métaphysiques ne peuvent pas être objets d’expérience. Ces idées ne sont pas dans la connaissance mais dans la <em>pensée</em> et il y a donc une différence entre pensée et connaissance</li>
<li>Il faut donc exclure du champ de la connaissance les objets de la philosophie et en faire donc la <em>critique</em></li>
<li>Ce que nous connaissons par l’expérience, nous le connaissons <em>objectivement</em>, donc il n’y a pas d’expérience s’il n’y a pas de <em>catégories</em> en nous permettant de construire cette connaissance à partir de l’expérience</li>
<li>Le <em>transcendental</em> est ce dont l’expérience a besoin pour exister, ce qui est <em>a priori</em> et permet de former des jugements synthétiques a priori
<ul>
<li>Les formes a priori de la sensibilité (intuition) sont le <em>temps</em> et l’<em>espace</em> : tout ce que je perçois est dans l’espace et le temps, c’est une disposition qui est nécessairement en nous pour qu’il y ait expérience</li>
<li>Les concepts a priori de l’entendement sont au nombre de 12, par groupes de 3 (inspirés des catégories aristotélicienne):
<ul>
<li>Quantité: Unité, Pluralité, Totalité</li>
<li>Qualité: Réalité, Négation, Limitation</li>
<li>Relation: Substance/accident,Cause/Effet,Réciprocité</li>
<li>Modalité: Possibilité/impossibilité, Existence/non-existence, Nécessité/contingence</li>
</ul></li>
</ul></li>
<li>Les objets d’expérience possibles sont les <em>phénomènes</em>. Rien ne prouve que le réel soit identique aux phénomènes, le réel <em>en soi</em> (nouméne) ne peut être connu.</li>
<li>L’enjeu de Kant qui s’inscrit dans le mouvement des Lumières est d’atteindre à l’universalité de la raison. Ce que l’on peut connaître et penser peut l’être par tous les êtres humains, parce qu’il ne peut être autrement que ce qu’il est en vertu des conditions nécessaires à la raison</li>
<li>La méthode relève quelque peu de l’imagination d’un maniaque qui prétendrait repartir de 0. Kant divise l’exposition en:
<ul>
<li>l’esthétique transcendantale, qui est la définition des formes de la sensibilité</li>
<li>l’analytique transcendantale, qui construit les concepts a priori de l’entendement</li>
<li>la dialectique transcendantale enfin, qui définit les limites de la connaissance et ce que l’on peut penser en dehors d’elle.</li>
</ul></li>
<li>Si je ne peux pas connaître Dieu, pourquoi en ai-je l’idée ? C’est un travers de l’esprit qui cherche systématiquement à absolutiser : par exemple l’idée de Dieu est l’absolutisation de la <em>causalité</em>
<ul>
<li>Cette tendance à la totalisation nous pousse à l’inconditionné, à chercher des fondements absolus et définitifs à toute chose</li>
<li>C’est une “maladie” de l’esprit d’élaborer des illusions à partir des catégories de l’entendement, en dehors de toute expérience possible</li>
</ul></li>
<li>Mais par ailleurs l’impossibilité de s’arrêter à l’expérience fait de l’homme un être libre et moral. Les idées de la raison qui ne sont pas de l’ordre de la connaissance sont la condition de la vie morale</li>
<li>L’idée morale chez Kant consiste à renverser la proposition “tu peux donc tu dois” en “tu dois donc tu peux”: c’est l’impératif catégorique</li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>On &quot;The World Beyond Your Head&quot;</title>
    <link href="http://abailly.github.io/posts/the-world-beyond-your-head.html" />
    <id>http://abailly.github.io/posts/the-world-beyond-your-head.html</id>
    <published>2016-04-28T00:00:00Z</published>
    <updated>2016-04-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>On &quot;The World Beyond Your Head&quot;</h1>
<div class="info">Posted on April 28, 2016</div>

<p>I have read Matthew Crawford’s <a href="http://www.editionsladecouverte.fr/catalogue/index-__loge_du_carburateur-9782707160065.html">Éloge du carburateur</a> or <a href="http://www.matthewbcrawford.com/new-page-1-1-2/">Shop Class as Soulcraft</a> a few years ago, in French and really liked the way it praised manual work, of the kind one does in a mechanics shop, and reconciled it with intellectual work. I bought <a href="http://www.matthewbcrawford.com/new-page-1-1/">The World Beyond Your Head</a> and read it in English this time.</p>
<p>I have mixed feelings about Crawford’s statements and philosophy and I am writing this post to make those feelings clearer to my self, to try to separate what I like and what I don’t like, and possibly to raise discussion and criticism. After all English is not my mother tongue and I am not a professionnal philosopher hence there are things I might have misunderstood.</p>
<h1 id="summary">Summary</h1>
<p>The book’s subtitle - <em>How to Flourish in an Age of Distraction</em> - exposes its program: A moralist view on our (post-)modern condition entrapped in the thralls of <em>engineered hyper pallatable desires</em> bestowed upon us by big business, and how to escape this condition and rebuild meaning.</p>
<p>The book starts with the somewhat obvious statement that our <em>attention</em> has becomed a key resource that is being harvested by companies and governments. The former seek to extract profit by engineering experiences that will attract and retain our attention, as exemplified by how successful Internet giants are gathering personal data and constantly creating new ways of making profit out of that (big) data. The latter seek enhance social control and <em>conformance</em> in order to govern through consensus and norm, rather than through strength and police. This is exemplified by <em>nudges</em> which are now routinely used to induce expected behaviour without resorting to coercition.</p>
<p>The question of <em>attention</em> is key as it is the expression of our relationship to the world and ultimately to our individuality, or coherence of <em>self</em>. The <em>homo economicus</em> view of free will and rationality that is our common horizon those days implies that we are individually responsible for our attention and exercise of free will, that we can <em>rationally choose</em> at all time what to focus on. But advances in psychology and behavioural economics tend to demonstrate this is not actually true, that our desires and thoughts are driven by our culture and environment, leading to a deterministic view of human rationality and ultimately to engineering our behaviour, at least statiscally.</p>
<p>Through the example of the <em>motorcycle rider</em>’s experience, the author offers another view of attention and free will, one that relates the mind to <em>reality</em> through <em>affordances</em>, or rather one that makes the individual situated, a part of, embodied, in reality. By dismissing the view of the mind - or self - as an <em>observer</em> of reality, one can account for the rider’s experience which would seem impossible to explain in purely rational terms. The experience of the road and riding one accumulates through direct relationship with the reality, the speed of wind, the road, the noise of the engine, the surrounding traffic must be physical, mediated through the motorcycle, makes riding possible. And this cannot be engineered but must be learnt: The increasing sophistication of today’s cars remove the driver from the experience of driving thus removing the possibility of taking decisions, leading ultimately to the driverless car.</p>
<p>Crawford’s give two counterexamples to this <em>situated self experience</em>. The first one is the <em>Mickey Mouse Clubhouse</em> which is a TV program with educational motivation but which depicts a highly virtual and <em>magical</em> world: Problems happening to Mickey and his friends are almost invariably solved by pushing some button and invoking some magical device that solves the problem. The second example is how gambling industry crafts the gamblers’ environment to induce more and more gambling and generate addiction. The goal of the whole gambling industry is to make gamblers lose contact with reality so that gambling <em>becomes</em> reality.</p>
<p>The extreme libertarianism that expresses itself in those few examples and the accepted social norm of individualism and self-responsibility of adults that makes all this possible can be traced back, according to Matthew Crawford, to the philosophers of the European Enlightnement, Descartes, Locke and last but not least Kant. Those philosophers struggled against the absolutism of their time and the dogmatism of the Church and King, and they built a philosophy based on the overarching principle of a fully autonomous self, radically separated from the World. Kant’s moral philosophy in particular, needs to posit one’s moral self as disconnected from any particular experience in order to be able to reach universalism. The <em>moral imperative</em> that one shall only treat others as an end and never as a mean is universal because it is <em>not</em> inferred from experience or intuition but is at the root of our judgment. And Locke’s rejection of authority to make individual freedom possible implies a radical shift on the source of truth from the outside - authorities, dogma - to the inside - one’s mind and rational judgment. In the end, we are led to live in a world of <em>representations</em> that abstract ourselves from the reality.</p>
<p>The second part of the book offers another view of individualism as <em>shared experience</em> of the world. From the baby which is led to discover the world by her caregiver to the student or apprentice which is led to discover a new field and learn new skills by a teacher or master, one can infer that our individuality <em>needs</em> other people and things, needs an actual - dialectical as Hegel says - confrontation with the reality <em>beyond my head</em>. But this requires <em>attention</em>, and <em>care</em>, and <em>effort</em> as the real world might not be very nice or my be adversarial to my current desires and feelings. Yet because there is a feedback loop between the inner self and the outer world, one can choose to consciously act in order to change his feelings and thoughts. Crawford talks about the <em>erotics of attention</em> or the desire to encounter an <em>other</em> as a way to enrichen and enliven my own <em>self</em>.</p>
<p>But a key contradiction of our modern world is that although it theoretically puts individualism as the ultimate measure of things, in practice we are more and more treated as <em>statistical units</em>, e.g. generic representatives of some group, trend, fashion, community. This movement started in the 20s and 30s with the advent of polls, going hand in hand with industrialisation and rationalisation of organisations and of course the triumph of collectivist movements. But Tocqueville wrote about it a century ago when he described the <em>tyranny of majority</em> in democratic America. Enjoined on one side to <em>be oneself</em> and on the other side pressured to <em>abide by the social norms</em>, the modern person seeks refuge in political correctness, fashion and muzak, keeping one’s own thoughts private lest he or she runs the risk of being confronted to others. Kant is once again convicted of being at the root of this contradiction in his efforts to build a universal moral: Each man or woman must act as being a representative of humanity as a whole and som ust somehow lose his or her individuality in the process. As Matrix said it: <em>Welcome in the desert of the real</em>.</p>
<p>The third and shortest part of the book offers a path out of this modern <em>flattening</em>, and this path builds on <em>inheritance</em> and <em>craftsmanship</em>. The author visits <a href="http://www.taylorandboody.com/">Taylor and Boody</a>, a small organmaker shop in the U.S., and through what he experiences there and what the people working there tell about their work, suggests that organmaking is a good archetype of how to rebuild true individuality in our modern days. The key characteristics of the organmakers is that:</p>
<ol style="list-style-type: decimal">
<li>They are inheritors to a centuries old tradition, building upon techniques, tools and artefacts that were devised in the 17th century or 18th century,</li>
<li>They are not lavishly <em>imitating</em> the past, they are working in constant <em>discussion</em> with the old masters, sometimes replacing outdated materials with modern ones (e.g. carbon fiber), sometimes rediscovering lost techniques. There actually was a Baroque organ revival in the first half of the 20th century that lead to renewal of techniques to uncover lost sound of organs,</li>
<li>They are <em>situated</em> and <em>embodied</em> in reality, crafting complex objects out of carefully chosen materials, using skillful techniques that require years to master,</li>
<li>They are working as a community, led by the founders but running in a somewhat self-organised process where each person knows what she has to do and each one has his or herown area of expertise. Because Baroque organs are complex and very expensive things to build, customers understand the constraints and in particular that one cannot build an organ in days,</li>
<li>They are building tools that are supposed to last for centuries, just like the organs from previous periods they are repairing or studying.</li>
</ol>
<p>Matthew Crawford concludes his book with a call to <em>reclaim the real</em> and in particular to overhaul our education system which is currently <em>undeserving of the attention of the students</em>. This overhauling should go through a rehabilitation of hand-crafting, giving the possibility to students to reclaim the real by actually working on it.</p>
<h1 id="discussion">Discussion</h1>
<p>I find the French title of the book <em>Contact</em> better than the English one: It better conveys the idea this book is about getting back in touch with the real and reclaiming it for ourself, to live it fully and consciously and not mediated through experiences crafted by others for their own means.</p>
<p>As a software developer, this is something I have sometimes been struggling with. Because we work mostly in a virtual world, and a very abstract one where we are required to manipulate concepts interacting in very complex ways, it is a constant temptation to isolate oneself from the material reality. In a sense we as developers play a key role in the <em>attention engineering</em> movement Crawford is criticizing as it is through our tools, techniques, software, data centers, algorithms that people from Big Corps can harvest so much personal data and manipulate our interaction with the world to suit their needs.</p>
<p>Social networks, virtual reality, hyper-communication, apps… all struggle to interpose themselves between us and reality in order to monetize those interactions, directly or indirectly. They all strive to capture a share of our attention and to impel their representations on us. They are mediating our access to the real and like all media before them, because they mediate this access to the world, they can control and tweak it. Or they can use the gathered data to serve other needs like advertising, industry optimisation or mass surveillance. And as software developers we have a responsibility with this state of the world, we cannot dismiss the issue saying <em>we are just techs</em>.</p>
<p>Yet those tools we are creating and using are also giving us access to another reality. They make new <em>interactions</em> possible that were not even dreamt of in the past. It is possible to focus one’s attention on things that matter in virtual worlds, or in social networks. It is possible to foster and nurture deep - even <em>erotic</em> - interactions with people living on the other side of the planet. I have some personal experiences pair programming with people remotely that were really rich, and I have build friendship through virtual communications before I have a chance to meet people in real life. I believe, from first-hand experience, that the kind of individuality which is appealing to Crawford, individuality built on shared experience and confrontation can be built through mediation. But this of course requires energy, and actually more energy than one would need in real life, as the signal vs. noise ratio is lower hence misunderstanding can happen more quickly. And this also requires <em>action</em> and <em>intention</em>, the reliance on more neutral or individually-controlled media, e.g. open-source, free software, community run servers and networks…</p>
<p>I also felt much empathy with Crawford’s praise of craft and the account he gives of Taylor and Boody’s way of working. As a long-time proponent of agile development, self organising teams, software craftsmanship and software quality, extreme programming… I cannot but recognise the way I would like to work, and sometimes managed to work, in how he describes teamwork at the organmakers’ shop. In the narrowest sense, software development obviously rests on a much younger tradition than organmaking. Yet even with a decades old tradition it is possible to build the kind of critical dialogue Crawford highlights in Taylor and Boody’s work:</p>
<ul>
<li>More often than not we are working with existing software and systems. This so-called <em>legacy code</em> is often viewed negatively, carrying with it stigmatas of impenetrability, accidental complexity, technological obsolescence… Yet this code has often been around for years and served its purpose well, and it is actually running the business be it a for-profit company or a non-profit organisation. It may have more than its share of warts but this is where the capability to engage in a <em>critical dialogue</em> comes into play. One of my favourite software development books is still Michael Feather’s <a href="">Working Effectively with Legacy Code</a>,</li>
<li>Furthermore, we have built over the past 50 or 60 years a body of knowledge and experience which is still valuable, and valued. Technology fads come and go, but computer science, algorithms and engineering principles stay and accumulate. And with these too we can engage in a critical dialogue. <a href="https://en.wikipedia.org/wiki/Dijkstra&#39;s_algorithm">Dijkstra’s shortest path</a>, <a href="http://lcm.csa.iisc.ernet.in/dsa/node184.html">Kruskal’s spanning tree</a>, <a href="http://www-formal.stanford.edu/jmc/recursive.ps">McCarthy’s LISP</a>, <a href="http://www.inf.fu-berlin.de/lehre/WS03/alpi/lambda.pdf">Church’s lambda-calculus</a>, <a href="http://spinroot.com/courses/summer/Papers/hoare_1978.pdf">Hoare’s CSP</a>, <a href="https://intuitionistic.files.wordpress.com/2010/07/martin-lof-tt.pdf">Martin-Löf’s type theory</a>, <a href="http://infolab.stanford.edu/pub/papers/google.pdf">Page and Brin’s page rank</a> are all examples of knowledge that exist we must take care of when building new software. There is a kind of breathing in computer systems going back and forth between centralised systems with thin clients and decentralised systems with fat clients. Work on shared memory and parallel computers from the 80’s and 90’s is relevant for today’s massively distributed systems. And I am not even talking about the huge body of knowledge from mathematics, social sciences, physics, psychology one could put to good use when developing software systems.</li>
</ul>
<p>Moreover it is not true that our trade is a purely intellectual one. When working on a difficult problem or when encountering some unexpected road-block that forces me halt, it is often the case I grow a pain in my back, like I have been <em>pushing</em> a big rock uphill or doing some hard workout. Thinking can be helped or hindered by our physical sensations, the way we move or put to rest our body, walking, sitting, couching. Going out for a walk helps solving tough problems just like going to sleep while letting problems to rest can often have a “magical” effect. Drawing, writing or even typing are all part of our thinking process, or at least part of my thinking process. <a href="/posts/cake-custard-category.html">Eugenia Cheng</a> is not only a great category theorist, a pure mind, she is also a concert-level pianist. And how many great programmers do I know who also practice some sport or art, sometimes at competitive level?</p>
<p>More generally, it is obvious the brain needs fuel and energy to work at its best and being well fed, rested, energized with a healthy way of life has deep impact on how fast, deep and well we can think. We <em>are</em> bodies and any attempt at denying this fact leads nowhere.</p>
<p>Interestingly, Kant himself, whom Matthew Crawford criticizes so much in his book as being at the root of all the modern evil induced by individualism, the paragon of <em>idealism</em> nevertheless relates directly mind to body. In his <a href="https://en.wikipedia.org/wiki/Critique_of_Pure_Reason">Critics of Pure Reason</a> Kant aims at providing a grand unifying theory of <em>knowledge</em>. From what I understand - feel free to correct me - Kant posits that <em>knowledge</em> comes from the interaction of <em>understanding</em> which is the part of our mind that forms concepts and <em>intuition</em> which is the part that forms experiences. Both faculties are made possible because there exists <em>a priori</em> categories that <em>shape</em> understanding and intuition: <em>Space</em> and <em>time</em> are the tow categories that shape our experience of the world, while <em>causality</em>, <em>totality</em>, <em>unicity</em> and a bunch of others are the categories that shape concepts. I won’t - and can’t - delve into the intricacies of Kant’s philosophy but from what I understand Kant does <em>not</em> state the subject or mind exists independently of the world: On the contrary, he explicitly states that knowledge is only derived from experience and refutes <em>subjective idealism</em>: Self-consciousness exists through interactions with the real world, even though we only perceive phenomena and not the <em>reality in itself</em>. Time and space are “just” the shapes our mind give to our experience.</p>
<p>Trying an analogy, I would say that Kant demonstrated or discovered the <em>language of the mind</em>, and he showed this language is separated in <em>pure</em> - the understanding and concepts - and <em>impure</em> - the intuition and senses - parts. The <em>pure</em> part is what is used to produce meaningful results, but it is useless and inobservable without the <em>impure</em> part which gives it <em>data</em> to process and means to act on the world. “What is the sound of a single hand clapping?” asks the famous Zen koan.</p>
<p>Moreover Kant’s main goal seems to have been to establish solid philosophical foundations for <em>universality</em>: Of objective knowledge, reason and moral judgments. How can different people, with different experiences, can ever reach agreement, know something in common, act for a common good, if there is nothing else but <em>subjective monads</em> isolated from one another? If experience is always personal, nothing can ever be shared. Kant’s answer lies in the <em>a priori</em> of the understanding and perception which shape the way we think and thus makes shared knowledge and perceptions possible, because we all share the same internal machinery to <em>interpret</em> the phenomenal world.</p>
<h1 id="conclusion">Conclusion</h1>
<p>The ambivalent feelings I have with this book can be stated in a very simple way: Although I subscribe to the conclusion of the book, I am doubtful about its premises and I fear that he might be throwing the baby out with the bath’s water:</p>
<ul>
<li>There is a need to reclaim our attention which has been captured and privatised by corporations and state,</li>
<li>This should come from increasing our <em>surface of contact</em> with reality, something that is fostered by shop work and skillful knowledge,</li>
<li>The master-apprentice relationship and the transmission that happens there is key to build skillful and meaningful knowledge, one that is <em>situated</em> both in space and time,</li>
<li>However this <em>communautarian</em> and <em>aristocratic</em> process might come at the price of universality and democracy, as exemplified by the stratified and fragmented societies of the past against which philosophers of the Enlightenment struggled. <em>Corporatism</em> is the reverse of a coin whose observe is <em>craftsmanship</em>.</li>
</ul>
<p>I don’t follow Crawford in his rejections of the project of the <em>Enlightenment</em>, namely the project of founding a universal community of humans. Of course, in the time and place this project’s was born, humanity was restricted to wealthy white european males. And the time of the <em>great tales</em> has passed: We live in post-(post?-)modernist times where irony reigns. And Kant’s philosophy itself might be outdated. But I am not ready to throw away the idea that we need to found, and refound again and again, some form of universal that makes it possible to share the world’s experience and build common knowledge.</p>
<p>I cannot conclude this post without citing Spinoza whose philosophy traces the kind of path Matthew Crawford’s is proposing to us, one of reconciling mind, body and the world in a universal shared by all human beings. Spinoza viewed reality was made of a single <em>substance</em> which manifested itself through an infinity of <em>attributes</em>, only two of which are accessible to us: <em>thought</em> And <em>extension</em>. Hence the deep parallelism between the mind and the body: Whatever affects one affects the other. From those principles Spinoza builds a philosophy that seeks to enhance <em>life</em> maximilizing <em>joy</em> under the guidance of <em>reason</em>. Spinoza himself exemplified this unity of mind and body by being one of the most renowned lens polisher of his time.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>

</feed>
