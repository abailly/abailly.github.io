<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Arnaud Bailly's  Blog</title>
    <link href="http://abailly.github.io/atom.xml" rel="self" />
    <link href="http://abailly.github.io" />
    <id>http://abailly.github.io/atom.xml</id>
    <author>
        <name>Arnaud Bailly</name>
        <email>arnaud@igitur.io</email>
    </author>
    <updated>2016-05-23T00:00:00Z</updated>
    <entry>
    <title>Haskell-based Development Environment</title>
    <link href="http://abailly.github.io/posts/cm-infra-1.html" />
    <id>http://abailly.github.io/posts/cm-infra-1.html</id>
    <published>2016-05-23T00:00:00Z</published>
    <updated>2016-05-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Haskell-based Development Environment</h1>
<div class="info">Posted on May 23, 2016</div>

<p>In a <a href="/posts/cm-arch-design.html">previous post</a> I described the overall design and architecture of Capital Match’s core system. I now turn to providing more details on our development and operations environment which uses mostly Haskell tools and code. As there are quite a lot of moving parts, this large topic will be covered in two posts: The present one will focus on basic principles, build tools and development environment ; it shall be followed by another post on configuration management, deployment and monitoring. I consider both development and production environments as a single integrated system as, obviously, there is a porous membrane between the two especially in a small company with 4 developers. Although I have been interested in that topic since my first systems programming course in university, some 18 years ago, I do not consider myself a genuine systems administrator and I made a lot of mistakes while building Capital Match platform. But I do believe in the <em>“you build it, you run it”</em> motto and this is all the more true for a small startup team. Hence I have tried to pay attention to building a flexible yet robust system.</p>
<h1 id="principles">Principles</h1>
<p>When we started to setup this environment, we were guided by a few principles:</p>
<ul>
<li>Automate, automate, automate: As much setup as possible should be automated,</li>
<li>Every system-level part should be containerized,</li>
<li>There should be a single versioned source of authority for configuration,</li>
<li>Use as much Haskell as possible.</li>
</ul>
<h2 id="automate">Automate</h2>
<blockquote>
<p>Automate all the things!</p>
</blockquote>
<p>Deployment to production should be as much automated as possible, involving as few manual steps as possible. The end goal is to reach a state of continuous deployment where pushed changes are built, verified and deployed continuously over the day. This implies all the steps involved in getting some feature delivered to end-users should be identified and linked into a coherent process that is implemented in code, apart from the actual coding of the feature itself. There should be no fiddling with SSHing on production machine to fix some configuration script, no manual migration process when upgrading data schema, no copying of binaries from development environment to production…</p>
<h2 id="everything-docker">Everything Docker</h2>
<blockquote>
<p>Containerize all the things!</p>
</blockquote>
<p><a href="http://docker.io">docker</a> is still a controversial technology, esp. among system and cloud specialists, and the topic of hot debates which is a sure sign it is a game changer. And back in 2014 when we started developing Capital Match’s platform, docker was in its infancy. I have had some experience in the past working with <a href="http://linux-vserver.org/Welcome_to_Linux-VServer.org">VServer</a> and <a href="https://linuxcontainers.org/">LXC</a> and containers are definitely great as a way to package (parts of) a system. Using docker allows us to:</p>
<ul>
<li>Provide seamless integration of development and production environments: The exact same software can be produced anywhere and used anywhere, whatever OS or configuration the actual developer is using, and the production configuration can be reproduced easily for testing or staging purposes,</li>
<li>Encapsulate components in immutable “packages” that require minimal system-level configuration, e.g. no more fiddling with ports, machine names, environment variables… docker-compose takes care of running everything, and we can make services dependent to stable names,</li>
<li>Simplify “hardware” configuration: All we need is something that is running docker (and a compatible kernel of course…) which means machines provisioning becomes a no-brainer,</li>
<li>Isolate build and run components from system-level dependencies conflicts,</li>
<li>Provide some level of reuse across containers and components thanks to layered FS.</li>
</ul>
<p>Note that we stuck to the initial docker “philosophy” of <em>one process per container</em>, except for some very specific needs (e.g. Selenium testing): It is not possible to ssh into our applicative containers.</p>
<h2 id="single-source-of-authority">Single Source of Authority</h2>
<blockquote>
<p>Version all the things!</p>
</blockquote>
<p>This means we should of course version our application’s code, but also the system’s configuration and as much dependencies as possible. Ideally, we should be able to reconstruct the whole system from a handful commands:</p>
<ul>
<li><code>git clone &lt;the repo&gt; cm</code></li>
<li><code>cd cm; ./build ; ./deploy</code></li>
</ul>
<p>In practice this is quite a bit more complicated as there are some glue parts missing to ensure the whole system can be rebuilt from scratch, but still we came quite close to that ideal. We are using 2 different repositories, one for the application code and one for the environment, mostly for technical reasons related to how our configuration management software works. The only unversioned part is the description of the “hardware” and the provisioning part which is still done “manually”.</p>
<h2 id="everything-haskell">Everything Haskell</h2>
<blockquote>
<p>Typecheck all the things!</p>
</blockquote>
<p>There is not a dearth of tools when it comes to configuration management, systems provisioning and deployment, build tools… When starting small you usually don’t want to invest a lot of time in learning new tools hence a common choice is simply to start small with shell scripts. But tools usually exist for a reason: Scripts quickly become a tangled maze of scattered knowledge. Yet we have at our disposal a powerful tool: Haskell itself, the language and its ecosystem, hence we decided to try as much as possible to stick to using Haskell-based tools. Beside the obvious simplification this brings us (one compiler, one toolchain, one language…), the advantages Haskell provides over other languages (type safety, lazy evaluation, immutable data structures) seemed to be equally valuable at the applicative level than at the system level.</p>
<h1 id="overview">Overview</h1>
<div class="figure">
<img src="/images/system-architecture.png" width="900" />

</div>
<p>The above figure gives a high-level overview of the system:</p>
<ul>
<li>Developers work on local machines (or <em>dev boxes</em>, see below), pushing changes to <a href="http://git-scm.com">git</a>,</li>
<li>Pushing to remote repository triggers build on <em>continuous integration</em> server <a href="https://github.com/ndmitchell/bake">bake</a>,</li>
<li>The final output of CI is a bunch of containers which are deployed to a private repositories on <a href="https://hub.docker.com/">docker hub</a>,</li>
<li>When we are ready to deploy, we update the system configuration in another git repository then run <a href="http://propellor.branchable.com/">propellor</a>,</li>
<li>This triggers configuration of <em>run</em> system which usually entails downloading correct container from repository and running it,</li>
<li>Data (also stored in a container) is regularly backed-up on S3,</li>
<li>Various components of the system feed events to <a href="http://riemann.io">riemann</a> monitoring system.</li>
</ul>
<h1 id="build-toolchain">Build &amp; Toolchain</h1>
<h2 id="build">Build</h2>
<h3 id="cabal">Cabal</h3>
<p>For building the Haskell part, we started obviously with <a href="https://www.haskell.org/cabal/">Cabal</a> which is the defacto build system/package manager in Haskell. The structure of GHC+Cabal packages system makes it quite hard to create insulated and <strong>reproducible</strong> build environments as there are various interactions between what’s installed globally (with GHC) and what’s installed per user and per project. There was no <a href="http://docs.haskellstack.org">stack</a> two years ago so we had to roll our own. Here are some key features of our cabal-based build:</p>
<ul>
<li>We used cabal snapshots with pinned down versions of all dependencies through <code>cabal freeze</code></li>
<li>Build became more complex when we started to add subpackages and sharing dependencies (&gt;100) seemed like a good idea. We shared a single sandbox by setting <code>CABAL_SANDBOX_CONFIG</code> to point to toplevel directory sandbox configuration file for all packages, then <code>add-source</code> sub-packages. This make it easier to simultaneously:
<ul>
<li>Build everything in one go,</li>
<li>Work in a sub-package,</li>
<li>Work in main (top-level) package,</li>
</ul></li>
<li>This does not prevent rebuilds when moving across packages as the build directory used by cabal is still located within each package,</li>
<li>We are still dependent on a globally available GHC. When upgrading GHC versions, you need to change globally installed GHC before rebuilding,</li>
<li>Several concurrent versions can coexist and be used in the same directory as GHC maintains version/OS dependent packages database, but care need to be taken with <code>PATH</code>s as the cabal version is likely different too…</li>
</ul>
<h3 id="stack">Stack</h3>
<p><a href="https://github.com/commercialhaskell/stack/">stack</a> represented a huge improvement for managing our build but it took us a few months to ensure it built consistently.</p>
<ul>
<li>Stack provides truly repeatable builds and segregate build environments tightly, including the tooling (compiler, lexer, parser…), managing downloads, setting package databases paths…</li>
<li>There is a single executable to install which makes creating build containers much easier: install stack, run setup and you have a fully configured container at required version. It is also very easy to upgrade,</li>
<li>Stack manages dependencies through <a href="https://www.stackage.org/">stackage</a> meaning you only have to provide a single version number and you are guaranteed to have compatible versions of libraries. This might be sometimes problematic if you require some specific version of a library that is not part of the dependency package, but it is still possible to provide custom versions,</li>
<li>I was sometimes surprised by stack not reusing some previous build result, although I could make it work manually,</li>
<li>The biggest hurdle we had to overcome to make stack work for us were the tests. Some tests relied on specific files to be present which means we had to manage relative paths: depending on whether or not tests are run from toplevel (which is the case in CI for example) or from local package directory (which is the case when using stack to build a tree of packages), relative directory may not be correctly set. Moreover stack runs tests in parallel, which is a good thing to force you to implement parallelizable tests but failed for us as we relied on starting server on some port for integration tests. We should get rid of hardwired port and allow the server to use some randomly allocated one but we chosed the simplest path and configured stack to run tests sequentially.</li>
<li>A minor annoyance is (was?) that stack maintains a build directory in each sub package, even when run from the toplevel, which is not the case when using cabal sandbox. This implies that reusing previous builds is a bit more cumbersome as one needs to save each <code>.stack-work</code> directory.</li>
</ul>
<h3 id="leiningen">Leiningen</h3>
<p><a href="http://leiningen.org/">leiningen</a> is (was?) the prominent build tool for clojure and clojurescript. We chose Clojurescript for the UI mostly because this allowed us to develop it using the excellent <a href="https://github.com/omcljs/om/">Om</a> wrapper over React. It took us quite a lot of time to get our project build comfortable and it did not evolve as quickly as the Haskell one.</p>
<ul>
<li>When to distinguish various build targets: Development mode where we want some interactive reload within the browser, test mode to run unit tests (automatically or in batch) and production mode which needs to be optimiszed,</li>
<li>Getting the tests to run correctly proved difficult and is still dependent on some manual configuration: To run clojurescript tests, we need to install <a href="http://phantomjs.org/">phantomjs</a> and configure correctly <a href="https://github.com/cljsjs/packages/wiki/Creating-Externs">externs</a> for the few javascript libraries we use and compile both code and tess <strong>with only whitespace</strong> optimizations (tests don’t run in fully optimized mode),</li>
<li>This actually means code is compiled as much as 3 times, which takes some time…</li>
<li>The CSS part of the UI is written using <a href="https://github.com/noprompt/garden">garden</a>, which means we have to compile it to proper CSS then pack and compress all CSS files together to improve load time. In retrospect, this was probably a mistake: We don’t use clojure’s power to write our CSS and it is still a mess, so we would have been better off using some standard CSS language like Less or Sass (although this adds the burden of running some thirdparty tool as part of the build…).</li>
</ul>
<h3 id="javascript">Javascript</h3>
<p>When we introduced the mobile UI for Capital Match, we had to integrate its build inside our process. This caused some headache as this part of the system is developed in pure Javascript using <a href="http://emberjs.com/">Emberjs</a> and relies on various tools in the JS ecosystem I was not familiar with. It also used <a href="http://sass-lang.com/">sass</a> to write CSS which means we needed ruby to run the compiler.</p>
<ul>
<li>We packaged all system-level dependencies into a single docker container. Note that official distribution’s package for node and npm were outdated hence we had to install them “by hand” in the container which is apparently the right way anyway,</li>
<li>There is a single top-level script which builds everything and is ran from the container.</li>
</ul>
<h3 id="shake">Shake</h3>
<p>Given the diversity of tools and components we are building, we needed a way to orchestrate build of the full solution which could be easily run as part of <em>Continuous integration</em>. We settled on <a href="http://shakebuild.com">shake</a> which is a Haskell-based tool similar to <em>make</em>.</p>
<ul>
<li>Rules are written in Haskell and shake provides support for all system-level tasks one would need to do in a build, including running arbitrary processes, manipulating their output, manipulating files… Using this embedded DSL makes it possible to track dependencies more easily. Shake maintains a database of dependencies that can be populated with arbitrary data,</li>
<li>The default target of our build is a list of docker containers, one for each service of the system plus the nginx container,</li>
<li>At the root of the dependency graph lies our build containers: one for <em>ghc + clojurescript</em> and one for building <em>javascript</em> code. Those containers are only expected to change (and be built) when we upgrade our toolchain. They are somewhat expensive to build as they need to provide all the needed tools to build (and run) our system,</li>
<li>On the server side, we use the <code>ghc-clojure</code> container to run a top-level build script that builds all services and the web UI. Given it takes ages to download and build all dependencies, then build all the various parts of the system, we tried to maximize reuse across builds: The build artifacts are exported as data containers and we link to the <span class="math inline"><em>n</em> − 1</span> build container in the <span class="math inline"><em>n</em></span> build run,</li>
<li>In order to minimize the size of our containers, we extract each service’s executable from the full build container and repack it into another container which contains a minimal runtime environment. We initially tried to do something like <a href="https://github.com/fpco/haskell-scratch/">haskell-scratch</a> but this did not work when our code needed to issue client-side HTTPS request: For some network and SSL reason the service fails to initialize properly. We resorted to use the standard busybox image, to which we add some prepackaged runtime libraries. This allows us to deploy containers with a “small” size: Our main application container weighs in at about 27MB and a typical service weighs 10MB. Note this has the additional benefit of drastically limiting the attack surface of the containers as they only contain the bare minimum to run our services and nothing else,</li>
<li>Shake build also contains rules to run different class of tests: Unit/integration server-side tests, UI tests and end-to-end-tests (see below), and rules to clean build artifacts and docker containers.</li>
</ul>
<h2 id="development-environment">Development Environment</h2>
<h3 id="haskell">Haskell</h3>
<p>There has been various attempts at providing an IDE for Haskell: * <a href="http://leksah.org/">leksah</a> is an Eclipse-based Haskell IDE, * <a href="http://haskellformac.com/">Haskell for Mac</a>, * FPComplete used to provide some web-based environment.</p>
<p>Having used emacs for years, I feel comfortable with and besides there are actually benefits using a plain-text tool for coding when you are part of a distributed team: It allows you to easily setup a distributed pairing environment with minimal latency. Yet configuring a proper Haskell development environment in Emacs can be a challenging task, and it seems this is a moving target.</p>
<ul>
<li>Starting from <a href="https://github.com/haskell/haskell-mode/">Haskell-mode</a> page is good idea as it is the base upon which one builds her own Emacs Haskell experience.</li>
<li><a href="https://github.com/serras/emacs-haskell-tutorial/blob/master/tutorial.md">Emacs haskell tutorial</a> provides some more details on how to set things up,</li>
<li><a href="https://github.com/chrisdone/emacs-haskell-config">Chris Done’s Haskell config</a> provides an easy to use full-blown configuration,</li>
<li>I tried <a href="https://github.com/chrisdone/structured-haskell-mode">SHM</a> a couple of times but could not get used to it, or could not make it work properly, or both… Might want to retry at some point in the future,</li>
<li><a href="http://tim.dysinger.net/posts/2014-02-18-haskell-with-emacs.html">this blog post</a> is a bit older but I remember having gone through it and try to reproduce some of the proposed features</li>
<li><a href="http://blog.hoersten.co/post/110096363794/modern-emacs-haskell-mode">This other post</a></li>
<li><a href="http://www.mew.org/~kazu/proj/ghc-mod/en/">ghc-mod</a> is useful but With cabal sandboxes and multiple projects it seems to be pretty unusable. I am also having a hard time making it work properly for test code: This requires different configurations and package dependencies are not properly picked up by ghc-mod. I need to investigate a bit more as I found this extension quite interesting,</li>
<li>Some people at Capital Match have started to use <a href="http://spacemacs.org/">spacemacs</a> which seems to come with a correctly configured Haskell environment out of the box.</li>
</ul>
<p>Here is my current .emacs content:</p>
<div class="sourceCode"><pre class="sourceCode scheme"><code class="sourceCode scheme">(eval-after-load <span class="st">&quot;haskell-mode&quot;</span>
  &#39;(progn
     (setq haskell-stylish-on-save t)
     (setq haskell-tags-on-save t)

     (setq haskell-process-type &#39;stack-ghci)
     (setq haskell-process-args-stack-ghci &#39;(<span class="st">&quot;--test&quot;</span>))
     
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-,&quot;</span>) &#39;haskell-move-nested-left)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-.&quot;</span>) &#39;haskell-move-nested-right)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c v c&quot;</span>) &#39;haskell-cabal-visit-file)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c v c&quot;</span>) &#39;haskell-cabal-visit-file)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c C-t&quot;</span>) &#39;ghc-show-type)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-x C-d&quot;</span>) nil)
     (setq haskell-font-lock-symbols t)

     <span class="co">;; Do this to get a variable in scope</span>
     (auto-complete-mode)

     <span class="co">;; from http://pastebin.com/tJyyEBAS</span>
     (ac-define-source ghc-mod
       &#39;((depends ghc)
         (candidates . (ghc-select-completion-symbol))
         (symbol . <span class="st">&quot;s&quot;</span>)
         (cache)))
     
     (defun my-ac-haskell-mode ()
       (setq ac-sources &#39;(ac-source-words-in-same-mode-buffers
                          ac-source-dictionary
                          ac-source-ghc-mod)))
     (add-hook &#39;haskell-mode-hook &#39;my-ac-haskell-mode)
     
  
     (defun my-haskell-ac-init ()
       (when (<span class="kw">member</span> (file-name-extension buffer-file-name) &#39;(<span class="st">&quot;hs&quot;</span> <span class="st">&quot;lhs&quot;</span>))
         (auto-complete-mode t)
         (setq ac-sources &#39;(ac-source-words-in-same-mode-buffers
                            ac-source-dictionary
                            ac-source-ghc-mod))))
     (add-hook &#39;find-file-hook &#39;my-haskell-ac-init)))

(add-hook &#39;haskell-mode-hook &#39;turn-on-haskell-decl-scan)
(add-hook &#39;haskell-mode-hook &#39;turn-on-haskell-indentation)
(add-hook &#39;haskell-mode-hook &#39;interactive-haskell-mode)

(add-hook &#39;haskell-interactive-mode-hook &#39;turn-on-comint-history)

(eval-after-load <span class="st">&quot;which-func&quot;</span>
  &#39;(add-to-list &#39;which-func-modes &#39;haskell-mode))

(eval-after-load <span class="st">&quot;haskell-cabal&quot;</span>
    &#39;(define-key haskell-cabal-mode-map (kbd <span class="st">&quot;C-c C-c&quot;</span>) &#39;haskell-compile))</code></pre></div>
<p>Thanks to discussions with <a href="https://twitter.com/solirc_">Simon</a> and <a href="https://twitter.com/amarpotghan">Amar</a> I am now using the REPL much more than I used to. My current workflow when working on Haskell code looks like:</p>
<ul>
<li>Load currently worked on file in interpreter using <code>C-c C-l</code>: This starts an inferior-haskell which is configured to use <code>stack ghci --test</code> under the hood, meaning all files including tests are in scope,</li>
<li>Code till it compiles properly and I can run a test,</li>
<li>Make test pass in the REPL,</li>
<li>When it’s OK, run full build, e.g. <code>stack test</code> in the console. This might trigger some more changes downstream which I need to fix,</li>
<li>When all unit tests pass, commit and push to CI.</li>
</ul>
<h3 id="clojurescript">Clojurescript</h3>
<p>The nice thing when using non-modern languages like Haskell and Clojure is that you only need to be able to edit text files to develop software, hence the choice of Emacs to develop both is kind of obvious. There is very good support for Clojure in emacs through <a href="https://github.com/clojure/tools.nrepl">nrepl</a> and <a href="https://github.com/clojure-emacs/cider">Cider</a> but it seems having the same level of support for Clojurescript is still challenging.</p>
<ul>
<li>When developping UI ClojureScript code, I mostly use <a href="https://github.com/bhauman/lein-figwheel">figwheel</a> which provides interactive reloading of code in the browser. One needs to start figwheel through <code>lein figwheel</code> which provides a REPL, then load the UI in a browser: The UI connects to the figwheel server which notifies it of code changes that trigger reload of the page,</li>
<li>For (mostly) non-UI code, I tend to favour TDD and use “autotesting” build: Changes in code trigger recompilation and run of all unit tests using the same configuration than batch run,</li>
<li><a href="http://wikemacs.org/wiki/Paredit-mode">paredit-mode</a> provides a structured way to edit LISP-like code: It automatically balances parens, brackets or double-quotes and provides dozens of shortcuts to manipulate the syntax tree ensuring syntactically correct transformations. I tend to use it as much as possible but sometimes find it cumbersome,</li>
<li>What I miss most when developing ClojureScript is a way to identify and navigate across symbols: I could not find an easy way to have some symbols index, something which is provided for Haskell through simple tags support. I am pretty sure there is something out there…</li>
</ul>
<h3 id="devbox">Devbox</h3>
<p>I already discussed in a <a href="/posts/agile-startup.html">previous blog post</a> how we managed to do pair programming with a distributed team. One of the virtual machines we configured was our <em>devbox</em> which we used to do remote pairing and run experiments.</p>
<ul>
<li>The initial configuration was done in the VM. It was pretty complex, requiring setting up full Haskell and ClojureScript toolchain, correct Emacs configuration which means installing and configuring emacs packages in scripts, setting user authentications…</li>
<li>It worked quite well however, except for the time to spin up a box from scratch. We were able to develop our software using the same tools we had on our laptops, except the fancy windowing UI: Emacs works exactly in the same way in a (proper) terminal and in a Mac OS X Window, once you correctly configuring key mappings for tmux and emacs over ssh,</li>
<li>At some point we turned to a container-based configuration with a <em>fat</em> container providing full development environment, including an X server for UI testing. Setting up the VM was much simpler as it only required installing docker but the development image was pretty large (about 4GB) and this meant long download time when pulling the docker image from scratch. This environment provided a full-blown X server which means we could log into it through VNC. However, we lost interactivity of pairing as it was not possible to share connection to X server which actually means it was pretty much useless,</li>
<li>We reverted back to configuring the VM itself but this time we used images snapshot to be able to restore the box quickly,</li>
<li>We also pushed emacs configuration to a <a href="https://github.com/capital-match/cm-dotfiles/blob/master/.emacs">shared git repository</a> which is pulled when configuring the machine, something we should have done earlier of course.</li>
</ul>
<h1 id="discussion">Discussion</h1>
<h2 id="build-process">Build process</h2>
<p>In retrospect I think the biggest issue we faced while developing the platform and working on the dev and prod infrastructure was fighting back increase in <em>build time</em> as we were adding new features and services. Building a deployable container <em>from scratch</em>, including creation of the build machine, configuration of build tools, creation of the needed containers, download and build of dependencies, testing, packaging would take about 2 hours. Here is the breakdown of time for some of the build stages according to the CI:</p>
<table>
<thead>
<tr class="header">
<th align="left">Test</th>
<th align="left">Mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">IntegrationTest</td>
<td align="left">7m51s</td>
</tr>
<tr class="even">
<td align="left">EndToEndTest</td>
<td align="left">7m05s</td>
</tr>
<tr class="odd">
<td align="left">Compile</td>
<td align="left">6m05s</td>
</tr>
<tr class="even">
<td align="left">ParallelDeploy</td>
<td align="left">1m12s</td>
</tr>
<tr class="odd">
<td align="left">UITest</td>
<td align="left">53.46s</td>
</tr>
</tbody>
</table>
<p>Even if tests are run in parallel, this means it takes more than 10 minutes to get to the point where we can deploy code. Actually, CI tells us our mean time to deployable is about 30 minutes, which is clearly an issue we need to tackle. To reduce build time there is no better way than splitting the system into smaller chunks, something the team has been working on for a few months now and is paying off at least by ensuring we can add feature without increasing build time! The next step would be to split the core application which currently contains more than 80 files into more services and components.</p>
<p>On the positive side:</p>
<ul>
<li>Shake provides a somewhat more robust and clearer make, removing cryptic syntax and reliance on shell scripts. All the build is concentrated in a single Haskell source file that requires few dependencies to be built,</li>
<li>Haskell build tooling has been steadily improving in last couple of years especially since stack has taken a prominent position. Stack does not remove dependency on cabal but it actually reduces it what cabal does best: Providing a simple, descriptive configuration for building single packages ; and provides a definitely better experience regarding dependency management, build reproducibility and managing multiple build configuration,</li>
<li>I am less happy with the ClojureScript and Javascript parts, probably because I am much less familiar with them, hence I won’t enter trolling mode,</li>
<li>Packaging build environments with docker greatly reduces development friction: Issues can be reproduced very easily against a reference environment. Developer’s freedom is not comprised: Everyone is free to configure her own environment with CI acting as final gatekeeper while making troubleshooting somewhat easy (grab image and run it locally to reproduce problems),</li>
<li>Using containers also makes onboarding of new developers somewhat easier: They can focus on a single part of the system (e.g. UI) and rely on the containers to run a consistent environment locally.</li>
</ul>
<h2 id="development-environment-1">Development Environment</h2>
<p>The single feature I miss from my former Java development environment is <em>refactoring</em>: The ability to safely rename, move, extract code fragments with a couple key strokes across the whole code base lowers the practical and psychological barrier to improve your code <strong>now</strong>. GHC (esp. with <code>-Wall -Werror</code> flags on) catches of course a whole lot more errors than Javac or gcc but the process of fixing compiler errors after some refactoring of a deeply nested core function is time consuming. On the other hand the lack of global refactoring capabilities is a strong incentive to modularize and encapsulate your code in small packages which can be compiled and even deployed independently.</p>
<blockquote>
<p>To be continued…</p>
</blockquote>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Notes on Failing to Understand Software Transactional Memory</title>
    <link href="http://abailly.github.io/posts/note-on-stm.html" />
    <id>http://abailly.github.io/posts/note-on-stm.html</id>
    <published>2016-05-22T00:00:00Z</published>
    <updated>2016-05-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Notes on Failing to Understand Software Transactional Memory</h1>
<div class="info">Posted on May 22, 2016</div>

<p>I am writing some library to easily implement event sourced services in Haskell based on previous experience at Capital Match, and while doing so I rewrote a simple file-based event store. This store communicates with core service using <a href="https://hackage.haskell.org/package/stm-2.4.4.1/docs/Control-Concurrent-STM-TBQueue.html">TBQueue</a>, a bounded queue implemented over Haskell’s STM. It took me couple of hours on Friday to solve a <a href="http://hackage.haskell.org/package/base-4.8.2.0/docs/Control-Exception-Base.html#t:BlockedIndefinitelyOnSTM">BlockedIndefinitelyOnSTM</a> bug I was facing while testing this simple store. So today I posted a <a href="http://stackoverflow.com/questions/37376419/what-is-the-precise-reason-i-got-blocked-on-stm">question about STM</a> on Stack Overflow, as I did not have a clear intuition on why my code was failing, hence why my fix was correct.</p>
<p>The code of the store boils down to the following simple model.</p>
<p>First some useful imports…</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">{-# LANGUAGE ScopedTypeVariables #-}</span>
<span class="kw">module</span> <span class="dt">Main</span> <span class="kw">where</span>

<span class="kw">import           </span><span class="dt">Control.Concurrent.Async</span>
<span class="kw">import           </span><span class="dt">Control.Concurrent.STM</span>
<span class="kw">import           </span><span class="dt">Control.Exception</span>
<span class="kw">import           </span><span class="dt">Control.Monad</span>            (forever)
<span class="kw">import           </span><span class="dt">Hevents.Eff</span>
<span class="kw">import           </span><span class="dt">System.IO</span></code></pre></div>
<p>The store dequeues some <em>operation</em> from a given queue, writes the operation’s string to <code>stdout</code> then put back the length of the written string into a <a href="http://hackage.haskell.org/package/stm-2.4.4.1/docs/Control-Concurrent-STM-TMVar.html">TMVar</a>, which models communicating the result of the operation back to the caller.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Op</span> <span class="fu">=</span> <span class="dt">Op</span> <span class="dt">String</span> (<span class="dt">TMVar</span> <span class="dt">Int</span>)

<span class="ot">storerun ::</span> <span class="dt">TBQueue</span> <span class="dt">Op</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
storerun q <span class="fu">=</span> <span class="kw">do</span>
  h <span class="ot">&lt;-</span> openFile <span class="st">&quot;store.test&quot;</span> <span class="dt">ReadWriteMode</span>
  hSetBuffering h <span class="dt">NoBuffering</span>
  forever <span class="fu">$</span> <span class="kw">do</span>
    <span class="dt">Op</span> s v <span class="ot">&lt;-</span> atomically <span class="fu">$</span> readTBQueue q
    hPutStrLn h s
    atomically <span class="fu">$</span> putTMVar v (length s)</code></pre></div>
<p>The <code>main</code> function is responsible for creating the jobs queue, starting the “store” in a separate thread then reading lines from <code>stdin</code> and feeding them as “operations” for the store.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> <span class="kw">do</span>
  q <span class="ot">&lt;-</span> newTBQueueIO <span class="dv">100</span>
  _ <span class="ot">&lt;-</span> async <span class="fu">$</span> storerun q
  storeInput q
  <span class="kw">where</span>
    storeInput q <span class="fu">=</span> forever <span class="fu">$</span> <span class="kw">do</span>
      l <span class="ot">&lt;-</span> getLine
      v <span class="ot">&lt;-</span> newEmptyTMVarIO
      r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> <span class="kw">do</span>
        writeTBQueue q (<span class="dt">Op</span> l v)
        takeTMVar v</code></pre></div>
<p>This code deadlocks because STM are actually - surprise! - <strong>transactions</strong>: They do all of their operations, or nothing, and they are serialized. Hence the following block:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> <span class="kw">do</span>
  writeTBQueue q (<span class="dt">Op</span> l v)
  takeTMVar v</code></pre></div>
<p>…can succeeds <em>if and only if</em> it can <strong>atomically</strong> put an operation in the queue and read the result back from <code>v</code>. Which of course is not possible because the result is put back after the operation is read from the queue in another transaction. The correct code is:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">atomically <span class="fu">$</span> writeTBQueue q (<span class="dt">Op</span> l v)
r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> takeTMVar v</code></pre></div>
<p>Pretty obvious, in retrospect. As the person who answered my question on SO, there is no way for two STM transactions to <em>exchange</em> information.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Life Beyond Relational Database in Haskell - The case for Event Sourcing</title>
    <link href="http://abailly.github.io/posts/event-source.html" />
    <id>http://abailly.github.io/posts/event-source.html</id>
    <published>2016-05-12T00:00:00Z</published>
    <updated>2016-05-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Life Beyond Relational Database in Haskell - The case for Event Sourcing</h1>
<div class="info">Posted on May 12, 2016</div>

<p>This post contains the code I demonstrated as part of my talk at <a href="http://ncrafts.io">nCrafts</a>. This work is based on the following references (stepping on the shoulders of giants, as always…):</p>
<ul>
<li><a href="http://okmij.org/ftp/Haskell/extensible/exteff.pdf">Extensible effects paper</a>: Extensible effects theory and practice in Haskell</li>
<li><a href="https://github.com/atnos-org/eff-cats">eff-cats</a>: Same in Scala</li>
<li><a href="http://www.cse.chalmers.se/~rjmh/Papers/QuickCheckST.ps">Testing monadic code with QuickCheck</a></li>
<li><a href="http://abailly.github.io/posts/cm-arch-design.html">Blog post</a> about the architecture implemented at Capital Match</li>
<li>Work-in-progress <a href="https://github.com/abailly/hevents">Haskell library</a> to simplify developing event sourced systems</li>
<li>Original <a href="http://shaffner.us/cs/papers/tarpit.pdf">Out of the Tar Pit</a> paper</li>
</ul>
<h1 id="imports-stuff-to-make-the-compiler-happy">Imports, stuff to make the compiler happy</h1>
<p>We first add the usual <code>LANGUAGE</code> extension incantations… Note they should probably go in to the <code>.cabal</code> file.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">{-# LANGUAGE DataKinds             #-}</span>
<span class="ot">{-# LANGUAGE FlexibleInstances     #-}</span>
<span class="ot">{-# LANGUAGE MultiParamTypeClasses #-}</span>
<span class="ot">{-# LANGUAGE OverloadedStrings     #-}</span>
<span class="ot">{-# LANGUAGE ScopedTypeVariables   #-}</span>
<span class="ot">{-# LANGUAGE TypeOperators         #-}</span>
<span class="kw">module</span> <span class="dt">Hevents.Eff.Demo</span> <span class="kw">where</span></code></pre></div>
<p>Then a whole bunch of imports… I never managed to choose a definite course of action on whether to import full module, import qualified, import only selected symbols. Seems to me this is pretty much a team-level convention.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import           </span><span class="dt">Control.Category</span>
<span class="kw">import           </span><span class="dt">Control.Concurrent.Async</span>
<span class="kw">import           </span><span class="dt">Control.Concurrent.STM</span>
<span class="kw">import qualified</span> <span class="dt">Control.Eff</span>                <span class="kw">as</span> <span class="dt">E</span>
<span class="kw">import           </span><span class="dt">Control.Eff.Exception</span>
<span class="kw">import           </span><span class="dt">Control.Eff.Lift</span>           <span class="kw">as</span> <span class="dt">E</span> <span class="kw">hiding</span> (lift)
<span class="kw">import           </span><span class="dt">Control.Exception</span>          (finally)
<span class="kw">import           </span><span class="dt">Control.Monad.Except</span>
<span class="kw">import qualified</span> <span class="dt">Control.Monad.State</span>        <span class="kw">as</span> <span class="dt">ST</span>
<span class="kw">import           </span><span class="dt">Control.Monad.Trans.Either</span>
<span class="kw">import qualified</span> <span class="dt">Data.ByteString.Builder</span>    <span class="kw">as</span> <span class="dt">BS</span>
<span class="kw">import           </span><span class="dt">Data.Either</span>                (rights)
<span class="kw">import           </span><span class="dt">Data.Proxy</span>
<span class="kw">import           </span><span class="dt">Data.Serialize</span>             (<span class="dt">Serialize</span>, get, put)
<span class="kw">import           </span><span class="dt">Data.Typeable</span>
<span class="kw">import           </span><span class="dt">Data.Void</span>
<span class="kw">import           </span><span class="dt">Hevents.Eff</span>                <span class="kw">as</span> <span class="dt">W</span>
<span class="kw">import           </span><span class="dt">Prelude</span>                    <span class="kw">hiding</span> (init, (.))
<span class="kw">import           </span><span class="dt">Servant</span>
<span class="kw">import           </span><span class="dt">Servant.Client</span>
<span class="kw">import           </span><span class="dt">System.Environment</span>
<span class="kw">import           </span><span class="dt">Test.Hspec</span>
<span class="kw">import           </span><span class="dt">Test.QuickCheck</span>            <span class="kw">as</span> <span class="dt">Q</span>
<span class="kw">import           </span><span class="dt">Test.QuickCheck.Monadic</span>    <span class="kw">as</span> <span class="dt">Q</span></code></pre></div>
<h1 id="the-business-domain">The “Business Domain”</h1>
<p>We want to implement an event-sourced service that will allow us to manipulate a simple integer <em>counter</em>:</p>
<ul>
<li>Our counter changes when some value is <em>added</em> to it,</li>
<li>A value is added when a command is issued that <em>increments</em> the counter,</li>
<li>We also want to modify the counter when a <em>decrement</em> command is issued, which means a <em>negative</em> value will be <em>added</em> to the counter,</li>
<li>We want our counter to be <em>bounded</em>: It shall never go below 0 or beyond 100,</li>
<li>And its initial value will be 0.</li>
</ul>
<h1 id="lets-start-writing-a-test">Let’s start writing a test…</h1>
<p>We’ll first write some property describing the behaviour of our model for a single command. We expect that an <code>Increment</code> command shall set an <code>init</code>ialized counter to the same value than the command, and that a <code>Decrement</code> command will decrease the value of a counter. Note here we anticipate a bit on bounds requirement checking by setting the counter to some value which is greater than any <code>Decrement</code> command we are supposed to issue.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">prop_shouldApplySingleCommandRespectingBounds ::</span> <span class="dt">Command</span> <span class="dt">Counter</span><span class="fu">*&gt;</span> <span class="dt">Bool</span>
prop_shouldApplySingleCommandRespectingBounds c<span class="fu">@</span>(<span class="dt">Increment</span> n) <span class="fu">=</span>
    <span class="kw">let</span> <span class="dt">OK</span> result <span class="fu">=</span> init <span class="ot">`act`</span> c
    <span class="kw">in</span>  init <span class="ot">`apply`</span> result <span class="fu">==</span> <span class="dt">Counter</span> n
prop_shouldApplySingleCommandRespectingBounds c<span class="fu">@</span>(<span class="dt">Decrement</span> n) <span class="fu">=</span>
    <span class="kw">let</span> bounderCounter <span class="fu">=</span> <span class="dt">Counter</span> singleCommandUpperBound
        <span class="dt">OK</span> result <span class="fu">=</span> bounderCounter <span class="ot">`act`</span> c
    <span class="kw">in</span>  bounderCounter <span class="ot">`apply`</span> result <span class="fu">==</span> <span class="dt">Counter</span> (singleCommandUpperBound <span class="fu">-</span> n)</code></pre></div>
<p>This property requires some way to generate <code>Arbitrary</code> instances of our commands, which is straightforward:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Arbitrary</span> (<span class="dt">Command</span> <span class="dt">Counter</span>) <span class="kw">where</span>
  arbitrary <span class="fu">=</span> oneof [ <span class="dt">Increment</span> <span class="fu">&lt;$&gt;</span> singleCommandValue
                    , <span class="dt">Decrement</span> <span class="fu">&lt;$&gt;</span> singleCommandValue
                    ]
    <span class="kw">where</span>
        singleCommandValue <span class="fu">=</span> choose (<span class="dv">0</span>,singleCommandUpperBound)

<span class="ot">singleCommandUpperBound ::</span> <span class="dt">Int</span>
singleCommandUpperBound <span class="fu">=</span> <span class="dv">20</span></code></pre></div>
<p>Another useful property we want to define that our counter respects its bounds, no matter which sequence of events we send to it:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">prop_shouldNotApplyCommandsOverBounds ::</span> [ <span class="dt">Command</span> <span class="dt">Counter</span> ] <span class="ot">-&gt;</span> <span class="dt">Bool</span>
prop_shouldNotApplyCommandsOverBounds commands <span class="fu">=</span>
  <span class="kw">let</span> finalCounter <span class="fu">=</span> ST.execState (mapM updateModel commands) init
  <span class="kw">in</span>  isWithinBounds finalCounter

<span class="ot">isWithinBounds ::</span> <span class="dt">Counter</span> <span class="ot">-&gt;</span> <span class="dt">Bool</span>
isWithinBounds (<span class="dt">Counter</span> value) <span class="fu">=</span> value <span class="fu">&gt;=</span> <span class="dv">0</span> <span class="fu">&amp;&amp;</span> value <span class="fu">&lt;=</span> <span class="dv">100</span></code></pre></div>
<p>And of course we need some implementation of our <code>Command</code>s and <code>Counter</code>. The latter is pretty much a simple wrapping of <code>Int</code> but to define the former we need our <code>Counter</code> type to be an instance of <a href="https://github.com/abailly/hevents/blob/master/src/Hevents/Eff/Model.lhs">Model</a> typeclass, which defines the basic structure of an event-sourced component (or aggregate).</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">Counter</span> <span class="fu">=</span> <span class="dt">Counter</span> {<span class="ot"> counter ::</span> <span class="dt">Int</span> } <span class="kw">deriving</span> (<span class="dt">Eq</span>,<span class="dt">Show</span>)

<span class="kw">instance</span> <span class="dt">Model</span> <span class="dt">Counter</span> <span class="kw">where</span></code></pre></div>
<p>We define the “component” types of our model: Commands, events and errors which here are very simple.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">  <span class="kw">data</span> <span class="dt">Command</span> <span class="dt">Counter</span> <span class="fu">=</span> <span class="dt">Increment</span> <span class="dt">Int</span>
                       <span class="fu">|</span> <span class="dt">Decrement</span> <span class="dt">Int</span>
                       <span class="kw">deriving</span> (<span class="dt">Eq</span>, <span class="dt">Show</span>)
  <span class="kw">data</span> <span class="dt">Event</span> <span class="dt">Counter</span> <span class="fu">=</span> <span class="dt">Added</span> <span class="dt">Int</span> <span class="kw">deriving</span> (<span class="dt">Eq</span>,<span class="dt">Show</span>)
  <span class="kw">data</span> <span class="dt">Error</span> <span class="dt">Counter</span> <span class="fu">=</span> <span class="dt">OutOfBounds</span> <span class="kw">deriving</span> (<span class="dt">Eq</span>,<span class="dt">Show</span>)</code></pre></div>
<p>Then comes our initial value…</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">  init <span class="fu">=</span> <span class="dt">Counter</span> <span class="dv">0</span></code></pre></div>
<p><code>act</code> computes the effect of applying a command to current state of our counter…</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">
  <span class="dt">Counter</span> k <span class="ot">`act`</span> <span class="dt">Increment</span> n <span class="fu">=</span> <span class="kw">if</span> k <span class="fu">+</span> n <span class="fu">&lt;=</span> <span class="dv">100</span>
                                <span class="kw">then</span> <span class="dt">OK</span> <span class="fu">$</span> <span class="dt">Added</span> n
                                <span class="kw">else</span> <span class="dt">KO</span> <span class="dt">OutOfBounds</span>

  <span class="dt">Counter</span> k <span class="ot">`act`</span> <span class="dt">Decrement</span> n <span class="fu">=</span> <span class="kw">if</span> k <span class="fu">-</span> n <span class="fu">&gt;=</span> <span class="dv">0</span>
                                <span class="kw">then</span> <span class="dt">OK</span> <span class="fu">$</span> <span class="dt">Added</span> (<span class="fu">-</span>n)
                                <span class="kw">else</span> <span class="dt">KO</span> <span class="dt">OutOfBounds</span></code></pre></div>
<p>Then <code>apply</code> actually “updates” (or more precisely, create a new updated instance of) the counter by applying the value to add.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">  <span class="dt">Counter</span> k <span class="ot">`apply`</span> <span class="dt">Added</span> n <span class="fu">=</span> <span class="dt">Counter</span> <span class="fu">$</span> k <span class="fu">+</span> n</code></pre></div>
<p>When we check the behaviour of applying a sequence of <code>Command</code>s to our counter, we make use of a library function which runs in the <code>State</code> monad and allow us to “fold” the application of a sequence of commands to a <code>Counter</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">updateModel ::</span> (<span class="dt">Model</span> a) <span class="ot">=&gt;</span> <span class="dt">Command</span> a <span class="ot">-&gt;</span> <span class="dt">State</span> a (<span class="dt">Result</span> a)</code></pre></div>
<h1 id="exposing-services-built-on-our-model">Exposing services built on our model</h1>
<p>As always, we start with the testing part but this time we expect our tests to have side effects and model interactions of the outside world with our system’s fragment. We shall start with very simple modelling of client’s behaviour:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">CounterAction</span> <span class="fu">=</span> <span class="dt">GetCounter</span>
                   <span class="fu">|</span> <span class="dt">IncCounter</span> <span class="dt">Int</span>
                   <span class="fu">|</span> <span class="dt">DecCounter</span> <span class="dt">Int</span>
                   <span class="kw">deriving</span> (<span class="dt">Show</span>)</code></pre></div>
<p>In order to generate samples for our actions we assume some frequency distribution, giving more weight to actions that get state than to actions that update it.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">
<span class="kw">instance</span> <span class="dt">Arbitrary</span> <span class="dt">CounterAction</span> <span class="kw">where</span>
  arbitrary <span class="fu">=</span> frequency [ (<span class="dv">3</span>, return <span class="dt">GetCounter</span>)
                        , (<span class="dv">2</span>, <span class="dt">IncCounter</span> <span class="fu">&lt;$&gt;</span> choose (<span class="dv">0</span>,<span class="dv">10</span>))
                        , (<span class="dv">1</span>, <span class="dt">DecCounter</span> <span class="fu">&lt;$&gt;</span> choose (<span class="dv">0</span>,<span class="dv">10</span>))
                        ]</code></pre></div>
<p>Then we use monadic QuickCheck to run an <code>arbitrary</code> sequence of user actions on an “effectful” model which is initialised with some state holder and a storage backend.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">prop_servicesRespectCounterBounds ::</span> [ <span class="dt">CounterAction</span> ] <span class="ot">-&gt;</span> <span class="dt">Property</span>
prop_servicesRespectCounterBounds actions <span class="fu">=</span> Q.monadicIO <span class="fu">$</span> <span class="kw">do</span>
  results <span class="ot">&lt;-</span> Q.run <span class="fu">$</span> <span class="kw">do</span>
    (model, storage) <span class="ot">&lt;-</span> prepareContext
    mapM (effect storage model <span class="fu">.</span> interpret) actions

  assert <span class="fu">$</span> all isWithinBounds (rights results)</code></pre></div>
<p>This test might be considered to be a little weak, and we could probably enhance it with testing error conditions. That’s something definitely worth doing for production code, however for the sake of simplicity we will not add more tests here.</p>
<p>Prparation step is simple but deserve some explanations:</p>
<ul>
<li>We create a <code>Counter</code> with some initial value and wrap it in a <em>transactional variable</em> because our underlying <code>State</code> effects works within the <code>STM</code> monad. This is so in order to ensure proper atomicity of commands on the model in face of concurrent access,</li>
<li>We create a simple in-memory store, which is a STM-based bounded queue.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">prepareContext <span class="fu">=</span> (,)           <span class="fu">&lt;$&gt;</span>
  newTVarIO (W.init<span class="ot"> ::</span> <span class="dt">Counter</span>) <span class="fu">&lt;*&gt;</span>
  atomically W.makeMemoryStore</code></pre></div>
<p><code>effect</code> is actually a natural transformation that composes all the small little effects we need in our sample and “lift” them in the <code>IO</code> monad. Note the <code>Eff</code> type which exposes explicitly all the effects our code is allowed to make thus constraining its behaviour to a limited subset of possible interactions with outside world. The <code>ServantErr</code> type is the type of <em>exceptions</em> we can “throw” using <code>Exc</code> effect: This anticipates on the needs of the REST API we shall expose later on. Actually it could have been any kind of <code>Exception</code> instance but once again, this makes things simpler and removes a layer of transformation from custom exceptions to Servant errors, something we would probably want to do in production code.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">EventSourced</span> s e a <span class="fu">=</span>
  <span class="dt">E.Eff</span> (<span class="dt">State</span> s <span class="fu">E.:&gt;</span> <span class="dt">Store</span> <span class="fu">E.:&gt;</span> <span class="dt">Exc</span> e <span class="fu">E.:&gt;</span> <span class="dt">Lift</span> <span class="dt">STM</span> <span class="fu">E.:&gt;</span> <span class="dt">Void</span>) a

<span class="ot">effect ::</span> (<span class="dt">Typeable</span> m, <span class="dt">Typeable</span> e, <span class="dt">Storage</span> <span class="dt">STM</span> s, <span class="dt">Registrar</span> <span class="dt">STM</span> m reg)
         <span class="ot">=&gt;</span> s <span class="ot">-&gt;</span> reg
         <span class="ot">-&gt;</span> <span class="dt">E.Eff</span> (<span class="dt">EventSourced</span> <span class="dt">Counter</span> <span class="dt">ServantErr</span>) a
         <span class="ot">-&gt;</span> <span class="dt">IO</span> (<span class="dt">Either</span> e a)
effect s m <span class="fu">=</span> atomically <span class="fu">.</span> runSync <span class="fu">.</span> runExc <span class="fu">.</span> W.runStore s <span class="fu">.</span>  W.runState m</code></pre></div>
<p>The definition of our services is pretty straightforward:</p>
<ul>
<li><code>getCounter</code> simply return the state of the counter,</li>
<li><code>increment</code> and <code>decrement</code> both send the corresponding commands and store the resulting event, returning the content of the counter.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">CounterService</span> a <span class="fu">=</span> <span class="dt">EventSourced</span> <span class="dt">Counter</span> <span class="dt">ServantErr</span> a

<span class="ot">getCounter ::</span> <span class="dt">CounterService</span> <span class="dt">Int</span>
getCounter <span class="fu">=</span> counter <span class="fu">&lt;$&gt;</span> getState

<span class="ot">increment ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">CounterService</span> <span class="dt">Int</span>
increment n <span class="fu">=</span> applyCommand (<span class="dt">Increment</span> n) <span class="fu">&gt;&gt;=</span> storeEvent

<span class="ot">decrement ::</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">CounterService</span> <span class="dt">Int</span>
decrement n <span class="fu">=</span> applyCommand (<span class="dt">Decrement</span> n) <span class="fu">&gt;&gt;=</span> storeEvent</code></pre></div>
<p>The <code>storeEvent</code> function is where most of the grunt work happens and notably where we do error handling:</p>
<ul>
<li>We first try to <code>store</code> the produced <code>Event Counter</code>, and if this succeeds we return the state of the counter. If this fails, we convert the error in a <code>500</code> error, passing some hopefully useful message,</li>
<li>If the input is an <code>Error Counter</code> we simply rethrow the converted error as a <code>400</code> error, all errors produced by commands represent precondition violations of the model’s specification.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">storeEvent ::</span> <span class="dt">Either</span> (<span class="dt">Error</span> <span class="dt">Counter</span>) (<span class="dt">Event</span> <span class="dt">Counter</span>)
             <span class="ot">-&gt;</span> <span class="dt">CounterService</span> <span class="dt">Int</span>
storeEvent (<span class="dt">Left</span> e)  <span class="fu">=</span> throwExc <span class="fu">$</span> fromModelError e
storeEvent (<span class="dt">Right</span> e) <span class="fu">=</span> store e <span class="fu">&gt;&gt;=</span> either (throwExc <span class="fu">.</span> fromDBError) (const <span class="fu">$</span> counter <span class="fu">&lt;$&gt;</span> getState)
  <span class="kw">where</span>
    fromModelError e <span class="fu">=</span> err400 { errBody <span class="fu">=</span> makeBody <span class="fu">$</span> <span class="st">&quot;Invalid command &quot;</span> <span class="fu">++</span> show e }
    fromDBError    e <span class="fu">=</span> err500 { errBody <span class="fu">=</span> makeBody <span class="fu">$</span> <span class="st">&quot;DB Error &quot;</span> <span class="fu">++</span> show e }
    makeBody         <span class="fu">=</span> BS.toLazyByteString <span class="fu">.</span> BS.stringUtf8</code></pre></div>
<p>Note that because of the <code>Store</code> effect we need to be able to <em>serialize</em> our events:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Serialize</span> (<span class="dt">Event</span> <span class="dt">Counter</span>) <span class="kw">where</span>
  put (<span class="dt">Added</span> i) <span class="fu">=</span> put i
  get           <span class="fu">=</span> <span class="dt">Added</span> <span class="fu">&lt;$&gt;</span> get</code></pre></div>
<p>The last missing piece is the <code>interpret</code> function which turns our QuickCheck generated actions into actual effectful actions to be run against our system.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">interpret <span class="dt">GetCounter</span>     <span class="fu">=</span> getCounter
interpret (<span class="dt">IncCounter</span> n) <span class="fu">=</span> increment n
interpret (<span class="dt">DecCounter</span> n) <span class="fu">=</span> decrement n</code></pre></div>
<h1 id="expose-our-counter-services-through-a-rest-api">Expose our counter services through a REST API</h1>
<p>The last step of our Counter “microservice” is to expose it as a REST interface. We will leverage the excellent work done on the <a href="http://servant.github.io">Servant</a> and firstly define out API’s type which is a simple exposition of the previously defined services:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">
<span class="kw">type</span> <span class="dt">CounterApi</span> <span class="fu">=</span>
 <span class="st">&quot;counter&quot;</span> <span class="fu">:&gt;</span> (<span class="dt">Get</span> <span class="ch">&#39;[JSON] Int</span>
              <span class="fu">:&lt;|&gt;</span> <span class="st">&quot;increment&quot;</span> <span class="fu">:&gt;</span> <span class="dt">Capture</span> <span class="st">&quot;inc&quot;</span> <span class="dt">Int</span> <span class="fu">:&gt;</span> <span class="dt">Get</span> <span class="ch">&#39;[JSON] Int</span>
              <span class="fu">:&lt;|&gt;</span> <span class="st">&quot;decrement&quot;</span> <span class="fu">:&gt;</span> <span class="dt">Capture</span> <span class="st">&quot;dec&quot;</span> <span class="dt">Int</span> <span class="fu">:&gt;</span> <span class="dt">Get</span> <span class="ch">&#39;[JSON] Int)</span>

<span class="ot">counterApi ::</span> <span class="dt">Proxy</span> <span class="dt">CounterApi</span>
counterApi <span class="fu">=</span> <span class="dt">Proxy</span></code></pre></div>
<p>Writing our test is pretty straightforward and mostly repeats the previous test at the service level layer, the main difference being the effectful services are run within an actual web server on some predefined port. Note this is makes our test brittle and non parallelizable: It would be better to let the server select a free port and return it as part of its startup.</p>
<p>The only noteworthy part is that we can use our previously defined <code>effect</code> “interpreter” natural transformation and wrap it inside an <code>EitherT</code> transformer which is the type expected by Servant.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">prop_counterServerImplementsCounterApi ::</span> [ <span class="dt">CounterAction</span> ] <span class="ot">-&gt;</span> <span class="dt">Property</span>
prop_counterServerImplementsCounterApi actions <span class="fu">=</span> Q.monadicIO <span class="fu">$</span> <span class="kw">do</span>
  results <span class="ot">&lt;-</span> Q.run <span class="fu">$</span> <span class="kw">do</span>
    (model, storage) <span class="ot">&lt;-</span> prepareContext
    server <span class="ot">&lt;-</span> W.runWebServerErr <span class="dv">8082</span> counterApi
                  (<span class="dt">Nat</span> <span class="fu">$</span> <span class="dt">EitherT</span> <span class="fu">.</span> effect storage model) handler
    mapM runClient actions <span class="ot">`finally`</span> cancel server

  assert <span class="fu">$</span> all isWithinBounds (rights results)</code></pre></div>
<p>The client-side services are obtained from a destructured assignment using Servant’s <code>(:&lt;|&gt;)</code> operator which is overloaded at the type and value level and then used to interpret user actions.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">counterState <span class="fu">:&lt;|&gt;</span> incCounter <span class="fu">:&lt;|&gt;</span> decCounter <span class="fu">=</span> client counterApi (<span class="dt">BaseUrl</span> <span class="dt">Http</span> <span class="st">&quot;localhost&quot;</span> <span class="dv">8082</span>)

runClient <span class="dt">GetCounter</span>     <span class="fu">=</span> runEitherT <span class="fu">$</span> counterState
runClient (<span class="dt">IncCounter</span> n) <span class="fu">=</span> runEitherT <span class="fu">$</span> incCounter n
runClient (<span class="dt">DecCounter</span> n) <span class="fu">=</span> runEitherT <span class="fu">$</span> decCounter n</code></pre></div>
<p>It is also noteworthy we can simply build our REST server composing our already defined services. Servant’s type wizardy ensures the expected type for the whole API is matched by actual functions composed with <code>(:&lt;|&gt;)</code>.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">handler <span class="fu">=</span> getCounter <span class="fu">:&lt;|&gt;</span> increment <span class="fu">:&lt;|&gt;</span> decrement</code></pre></div>
<p>Writing a <code>main</code> server that is able to listen on some port and runs our services is left as an exercise for the reader.</p>
<h1 id="conclusion">Conclusion</h1>
<p>The goal of this post and the associated talk was to demonstrate how Haskell’s type system and some well designed and though out libraries made it easy to build type-safe “microservices”. In particular, I would like to emphasize the following points:</p>
<ul>
<li>Haskell’s pure functional core makes it a perfect fit for designing, implementing and experimenting business domain models using <em>Domain Driven Design</em> principles: Use a common language which here is embedded in the form of commands, events and errors, provide a pure core which implements core business rules and can be very easily tested, wrap that pure core within a <em>Hexagonal architecture</em> providing needed side-effects…</li>
<li>QuickCheck is a great tool for doing <em>Test Driven Development</em> of such models: One can use it to expose assumptions about the behaviour of the model’s clients in the form of <em>Arbitrary</em> instances and then test potentially complex sequences of actions against the model,</li>
<li>Using monadic QuickCheck, it is possible to leverage that technique at any level of the system’s stack, making it easy to test various effects of our system and how it interacts with the outside world. Something that we could introduce here is testing the server with multiple concurrent clients and then checking our model doesn’t break its invariants in the face of concurrent accesses,</li>
<li>The <em>Extensible effects</em> framework allows us to define and compose tiny effectful “DSLs” over the core domain DSL. More importantly, thanks to its extensibility, it is possible to define new effects without having to recompile any of our existing services (note this would require our services’ types to be more lax, using typeclass constraints instead of concrete type for the <em>Eff</em> monad).</li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Critique de la raison pure&quot;</title>
    <link href="http://abailly.github.io/posts/kant.html" />
    <id>http://abailly.github.io/posts/kant.html</id>
    <published>2016-05-05T00:00:00Z</published>
    <updated>2016-05-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Critique de la raison pure&quot;</h1>
<div class="info">Posted on May  5, 2016</div>

<p>Ceci est une retranscription d’un cours improvisé par <a href="https://directory.unamur.be/staff/pavez">Peggy Penez-Avez</a> lors d’une session d’<a href="http://agenda-agile.org/showevent.php?id=487">Agile Open France 2016</a>, conçu plus ou moins comme une expérimentation du <a href="http://dojophilo.net/">Dojo Philo</a>. J’ai pu ajouté quelques notes personnelles…</p>
<ul>
<li>Kant développe une <em>philosophie transcendantal</em> et cherche à répondre à la question <em>“que puis-je connaître ?”</em>, qui peut se comprendre à la fois comme <em>“qu’est ce qui est digne d’être connu ?”</em> et <em>“qu’est ce que mes facultés me permettent de connaître ?”</em></li>
<li>Il s’agit donc d’explorer les condition de possibilité d’une connaissance, qui se résument (à l’époque de Kant) à trois approches:
<ul>
<li><strong>dogmatique</strong>: on peut tout connaître et en particulier l’existence de Dieu peut être objet d’une connaissance, toute la métaphysique est un objet de connaissance. Le problème, c’est que les thèses métaphysiques sont en désaccord les unes avec les autres, qu’il semble ne pas y avoir de progrès dans ce domaine : peut on vraiment parler de connaissance alors ?</li>
<li><strong>sceptique et empiriste</strong>: Hume réveille Kant du sommeil de la raison. Pour les sceptiques, la base des idées ce sont les observations et l’expérience, pas la raison (interne) : je dis que le soleil va se lever parce que j’en ai l’habitude, qu’il se lève tous les matins que j’ai pu expérimenter. L’esprit a l’habitude de voir une succession entre les phénomènes et en déduit une relation de <em>causalité</em> mais rien ne permet de prouver que c’est bien la réalité (en termes modernes, on pourrait parler d’une confusion entre <em>corrélation</em> et <em>causation</em>). Ce qu’on prend pour de la connaissance n’est que de la <em>croyance partagée</em></li>
<li><strong>critique</strong>: l’expérience est fondamentale pour qu’il y ait connaissance, mais pas que. C’est l’approche de Kant.</li>
</ul></li>
<li>Les questions de l’existence de Dieu, de l’âme et d’autres questions métaphysiques ne peuvent pas être objets d’expérience. Ces idées ne sont pas dans la connaissance mais dans la <em>pensée</em> et il y a donc une différence entre pensée et connaissance</li>
<li>Il faut donc exclure du champ de la connaissance les objets de la philosophie et en faire donc la <em>critique</em></li>
<li>Ce que nous connaissons par l’expérience, nous le connaissons <em>objectivement</em>, donc il n’y a pas d’expérience s’il n’y a pas de <em>catégories</em> en nous permettant de construire cette connaissance à partir de l’expérience</li>
<li>Le <em>transcendental</em> est ce dont l’expérience a besoin pour exister, ce qui est <em>a priori</em> et permet de former des jugements synthétiques a priori
<ul>
<li>Les formes a priori de la sensibilité (intuition) sont le <em>temps</em> et l’<em>espace</em> : tout ce que je perçois est dans l’espace et le temps, c’est une disposition qui est nécessairement en nous pour qu’il y ait expérience</li>
<li>Les concepts a priori de l’entendement sont au nombre de 12, par groupes de 3 (inspirés des catégories aristotélicienne):
<ul>
<li>Quantité: Unité, Pluralité, Totalité</li>
<li>Qualité: Réalité, Négation, Limitation</li>
<li>Relation: Substance/accident,Cause/Effet,Réciprocité</li>
<li>Modalité: Possibilité/impossibilité, Existence/non-existence, Nécessité/contingence</li>
</ul></li>
</ul></li>
<li>Les objets d’expérience possibles sont les <em>phénomènes</em>. Rien ne prouve que le réel soit identique aux phénomènes, le réel <em>en soi</em> (nouméne) ne peut être connu.</li>
<li>L’enjeu de Kant qui s’inscrit dans le mouvement des Lumières est d’atteindre à l’universalité de la raison. Ce que l’on peut connaître et penser peut l’être par tous les êtres humains, parce qu’il ne peut être autrement que ce qu’il est en vertu des conditions nécessaires à la raison</li>
<li>La méthode relève quelque peu de l’imagination d’un maniaque qui prétendrait repartir de 0. Kant divise l’exposition en:</li>
<li>l’esthétique transcendantale, qui est la définition des formes de la sensibilité</li>
<li>l’analytique transcendantale, qui construit les concepts a priori de l’entendement</li>
<li>la dialectique transcendantale enfin, qui définit les limites de la connaissance et ce que l’on peut penser en dehors d’elle.</li>
<li>Si je ne peux pas connaître Dieu, pourquoi en ai-je l’idée ? C’est un travers de l’esprit qui cherche systématiquement à absolutiser : par exemple l’idée de Dieu est l’absolutisation de la <em>causalité</em></li>
<li>Cette tendance à la totalisation nous pousse à l’inconditionné, à chercher des fondements absolus et définitifs à toute chose</li>
<li>C’est une “maladie” de l’esprit d’élaborer des illusions à partir des catégories de l’entendement, en dehors de toute expérience possible</li>
<li>Mais par ailleurs l’impossibilité de s’arrêter à l’expérience fait de l’homme un être libre et moral. Les idées de la raison qui ne sont pas de l’ordre de la connaissance sont la condition de la vie morale</li>
<li>L’idée morale chez Kant consiste à renverser la proposition “tu peux donc tu dois” en “tu dois donc tu peux”: c’est l’impératif catégorique</li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>On &quot;The World Beyond Your Head&quot;</title>
    <link href="http://abailly.github.io/posts/the-world-beyond-your-head.html" />
    <id>http://abailly.github.io/posts/the-world-beyond-your-head.html</id>
    <published>2016-04-28T00:00:00Z</published>
    <updated>2016-04-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>On &quot;The World Beyond Your Head&quot;</h1>
<div class="info">Posted on April 28, 2016</div>

<p>I have read Matthew Crawford’s <a href="http://www.editionsladecouverte.fr/catalogue/index-__loge_du_carburateur-9782707160065.html">Éloge du carburateur</a> or <a href="http://www.matthewbcrawford.com/new-page-1-1-2/">Shop Class as Soulcraft</a> a few years ago, in French and really liked the way it praised manual work, of the kind one does in a mechanics shop, and reconciled it with intellectual work. I bought <a href="http://www.matthewbcrawford.com/new-page-1-1/">The World Beyond Your Head</a> and read it in English this time.</p>
<p>I have mixed feelings about Crawford’s statements and philosophy and I am writing this post to make those feelings clearer to my self, to try to separate what I like and what I don’t like, and possibly to raise discussion and criticism. After all English is not my mother tongue and I am not a professionnal philosopher hence there are things I might have misunderstood.</p>
<h1 id="summary">Summary</h1>
<p>The book’s subtitle - <em>How to Flourish in an Age of Distraction</em> - exposes its program: A moralist view on our (post-)modern condition entrapped in the thralls of <em>engineered hyper pallatable desires</em> bestowed upon us by big business, and how to escape this condition and rebuild meaning.</p>
<p>The book starts with the somewhat obvious statement that our <em>attention</em> has becomed a key resource that is being harvested by companies and governments. The former seek to extract profit by engineering experiences that will attract and retain our attention, as exemplified by how successful Internet giants are gathering personal data and constantly creating new ways of making profit out of that (big) data. The latter seek enhance social control and <em>conformance</em> in order to govern through consensus and norm, rather than through strength and police. This is exemplified by <em>nudges</em> which are now routinely used to induce expected behaviour without resorting to coercition.</p>
<p>The question of <em>attention</em> is key as it is the expression of our relationship to the world and ultimately to our individuality, or coherence of <em>self</em>. The <em>homo economicus</em> view of free will and rationality that is our common horizon those days implies that we are individually responsible for our attention and exercise of free will, that we can <em>rationally choose</em> at all time what to focus on. But advances in psychology and behavioural economics tend to demonstrate this is not actually true, that our desires and thoughts are driven by our culture and environment, leading to a deterministic view of human rationality and ultimately to engineering our behaviour, at least statiscally.</p>
<p>Through the example of the <em>motorcycle rider</em>’s experience, the author offers another view of attention and free will, one that relates the mind to <em>reality</em> through <em>affordances</em>, or rather one that makes the individual situated, a part of, embodied, in reality. By dismissing the view of the mind - or self - as an <em>observer</em> of reality, one can account for the rider’s experience which would seem impossible to explain in purely rational terms. The experience of the road and riding one accumulates through direct relationship with the reality, the speed of wind, the road, the noise of the engine, the surrounding traffic must be physical, mediated through the motorcycle, makes riding possible. And this cannot be engineered but must be learnt: The increasing sophistication of today’s cars remove the driver from the experience of driving thus removing the possibility of taking decisions, leading ultimately to the driverless car.</p>
<p>Crawford’s give two counterexamples to this <em>situated self experience</em>. The first one is the <em>Mickey Mouse Clubhouse</em> which is a TV program with educational motivation but which depicts a highly virtual and <em>magical</em> world: Problems happening to Mickey and his friends are almost invariably solved by pushing some button and invoking some magical device that solves the problem. The second example is how gambling industry crafts the gamblers’ environment to induce more and more gambling and generate addiction. The goal of the whole gambling industry is to make gamblers lose contact with reality so that gambling <em>becomes</em> reality.</p>
<p>The extreme libertarianism that expresses itself in those few examples and the accepted social norm of individualism and self-responsibility of adults that makes all this possible can be traced back, according to Matthew Crawford, to the philosophers of the European Enlightnement, Descartes, Locke and last but not least Kant. Those philosophers struggled against the absolutism of their time and the dogmatism of the Church and King, and they built a philosophy based on the overarching principle of a fully autonomous self, radically separated from the World. Kant’s moral philosophy in particular, needs to posit one’s moral self as disconnected from any particular experience in order to be able to reach universalism. The <em>moral imperative</em> that one shall only treat others as an end and never as a mean is universal because it is <em>not</em> inferred from experience or intuition but is at the root of our judgment. And Locke’s rejection of authority to make individual freedom possible implies a radical shift on the source of truth from the outside - authorities, dogma - to the inside - one’s mind and rational judgment. In the end, we are led to live in a world of <em>representations</em> that abstract ourselves from the reality.</p>
<p>The second part of the book offers another view of individualism as <em>shared experience</em> of the world. From the baby which is led to discover the world by her caregiver to the student or apprentice which is led to discover a new field and learn new skills by a teacher or master, one can infer that our individuality <em>needs</em> other people and things, needs an actual - dialectical as Hegel says - confrontation with the reality <em>beyond my head</em>. But this requires <em>attention</em>, and <em>care</em>, and <em>effort</em> as the real world might not be very nice or my be adversarial to my current desires and feelings. Yet because there is a feedback loop between the inner self and the outer world, one can choose to consciously act in order to change his feelings and thoughts. Crawford talks about the <em>erotics of attention</em> or the desire to encounter an <em>other</em> as a way to enrichen and enliven my own <em>self</em>.</p>
<p>But a key contradiction of our modern world is that although it theoretically puts individualism as the ultimate measure of things, in practice we are more and more treated as <em>statistical units</em>, e.g. generic representatives of some group, trend, fashion, community. This movement started in the 20s and 30s with the advent of polls, going hand in hand with industrialisation and rationalisation of organisations and of course the triumph of collectivist movements. But Tocqueville wrote about it a century ago when he described the <em>tyranny of majority</em> in democratic America. Enjoined on one side to <em>be oneself</em> and on the other side pressured to <em>abide by the social norms</em>, the modern person seeks refuge in political correctness, fashion and muzak, keeping one’s own thoughts private lest he or she runs the risk of being confronted to others. Kant is once again convicted of being at the root of this contradiction in his efforts to build a universal moral: Each man or woman must act as being a representative of humanity as a whole and som ust somehow lose his or her individuality in the process. As Matrix said it: <em>Welcome in the desert of the real</em>.</p>
<p>The third and shortest part of the book offers a path out of this modern <em>flattening</em>, and this path builds on <em>inheritance</em> and <em>craftsmanship</em>. The author visits <a href="http://www.taylorandboody.com/">Taylor and Boody</a>, a small organmaker shop in the U.S., and through what he experiences there and what the people working there tell about their work, suggests that organmaking is a good archetype of how to rebuild true individuality in our modern days. The key characteristics of the organmakers is that:</p>
<ol style="list-style-type: decimal">
<li>They are inheritors to a centuries old tradition, building upon techniques, tools and artefacts that were devised in the 17th century or 18th century,</li>
<li>They are not lavishly <em>imitating</em> the past, they are working in constant <em>discussion</em> with the old masters, sometimes replacing outdated materials with modern ones (e.g. carbon fiber), sometimes rediscovering lost techniques. There actually was a Baroque organ revival in the first half of the 20th century that lead to renewal of techniques to uncover lost sound of organs,</li>
<li>They are <em>situated</em> and <em>embodied</em> in reality, crafting complex objects out of carefully chosen materials, using skillful techniques that require years to master,</li>
<li>They are working as a community, led by the founders but running in a somewhat self-organised process where each person knows what she has to do and each one has his or herown area of expertise. Because Baroque organs are complex and very expensive things to build, customers understand the constraints and in particular that one cannot build an organ in days,</li>
<li>They are building tools that are supposed to last for centuries, just like the organs from previous periods they are repairing or studying.</li>
</ol>
<p>Matthew Crawford concludes his book with a call to <em>reclaim the real</em> and in particular to overhaul our education system which is currently <em>undeserving of the attention of the students</em>. This overhauling should go through a rehabilitation of hand-crafting, giving the possibility to students to reclaim the real by actually working on it.</p>
<h1 id="discussion">Discussion</h1>
<p>I find the French title of the book <em>Contact</em> better than the English one: It better conveys the idea this book is about getting back in touch with the real and reclaiming it for ourself, to live it fully and consciously and not mediated through experiences crafted by others for their own means.</p>
<p>As a software developer, this is something I have sometimes been struggling with. Because we work mostly in a virtual world, and a very abstract one where we are required to manipulate concepts interacting in very complex ways, it is a constant temptation to isolate oneself from the material reality. In a sense we as developers play a key role in the <em>attention engineering</em> movement Crawford is criticizing as it is through our tools, techniques, software, data centers, algorithms that people from Big Corps can harvest so much personal data and manipulate our interaction with the world to suit their needs.</p>
<p>Social networks, virtual reality, hyper-communication, apps… all struggle to interpose themselves between us and reality in order to monetize those interactions, directly or indirectly. They all strive to capture a share of our attention and to impel their representations on us. They are mediating our access to the real and like all media before them, because they mediate this access to the world, they can control and tweak it. Or they can use the gathered data to serve other needs like advertising, industry optimisation or mass surveillance. And as software developers we have a responsibility with this state of the world, we cannot dismiss the issue saying <em>we are just techs</em>.</p>
<p>Yet those tools we are creating and using are also giving us access to another reality. They make new <em>interactions</em> possible that were not even dreamt of in the past. It is possible to focus one’s attention on things that matter in virtual worlds, or in social networks. It is possible to foster and nurture deep - even <em>erotic</em> - interactions with people living on the other side of the planet. I have some personal experiences pair programming with people remotely that were really rich, and I have build friendship through virtual communications before I have a chance to meet people in real life. I believe, from first-hand experience, that the kind of individuality which is appealing to Crawford, individuality built on shared experience and confrontation can be built through mediation. But this of course requires energy, and actually more energy than one would need in real life, as the signal vs. noise ratio is lower hence misunderstanding can happen more quickly. And this also requires <em>action</em> and <em>intention</em>, the reliance on more neutral or individually-controlled media, e.g. open-source, free software, community run servers and networks…</p>
<p>I also felt much empathy with Crawford’s praise of craft and the account he gives of Taylor and Boody’s way of working. As a long-time proponent of agile development, self organising teams, software craftsmanship and software quality, extreme programming… I cannot but recognise the way I would like to work, and sometimes managed to work, in how he describes teamwork at the organmakers’ shop. In the narrowest sense, software development obviously rests on a much younger tradition than organmaking. Yet even with a decades old tradition it is possible to build the kind of critical dialogue Crawford highlights in Taylor and Boody’s work:</p>
<ul>
<li>More often than not we are working with existing software and systems. This so-called <em>legacy code</em> is often viewed negatively, carrying with it stigmatas of impenetrability, accidental complexity, technological obsolescence… Yet this code has often been around for years and served its purpose well, and it is actually running the business be it a for-profit company or a non-profit organisation. It may have more than its share of warts but this is where the capability to engage in a <em>critical dialogue</em> comes into play. One of my favourite software development books is still Michael Feather’s <a href="">Working Effectively with Legacy Code</a>,</li>
<li>Furthermore, we have built over the past 50 or 60 years a body of knowledge and experience which is still valuable, and valued. Technology fads come and go, but computer science, algorithms and engineering principles stay and accumulate. And with these too we can engage in a critical dialogue. <a href="https://en.wikipedia.org/wiki/Dijkstra&#39;s_algorithm">Dijkstra’s shortest path</a>, <a href="http://lcm.csa.iisc.ernet.in/dsa/node184.html">Kruskal’s spanning tree</a>, <a href="http://www-formal.stanford.edu/jmc/recursive.ps">McCarthy’s LISP</a>, <a href="http://www.inf.fu-berlin.de/lehre/WS03/alpi/lambda.pdf">Church’s lambda-calculus</a>, <a href="http://spinroot.com/courses/summer/Papers/hoare_1978.pdf">Hoare’s CSP</a>, <a href="https://intuitionistic.files.wordpress.com/2010/07/martin-lof-tt.pdf">Martin-Löf’s type theory</a>, <a href="http://infolab.stanford.edu/pub/papers/google.pdf">Page and Brin’s page rank</a> are all examples of knowledge that exist we must take care of when building new software. There is a kind of breathing in computer systems going back and forth between centralised systems with thin clients and decentralised systems with fat clients. Work on shared memory and parallel computers from the 80’s and 90’s is relevant for today’s massively distributed systems. And I am not even talking about the huge body of knowledge from mathematics, social sciences, physics, psychology one could put to good use when developing software systems.</li>
</ul>
<p>Moreover it is not true that our trade is a purely intellectual one. When working on a difficult problem or when encountering some unexpected road-block that forces me halt, it is often the case I grow a pain in my back, like I have been <em>pushing</em> a big rock uphill or doing some hard workout. Thinking can be helped or hindered by our physical sensations, the way we move or put to rest our body, walking, sitting, couching. Going out for a walk helps solving tough problems just like going to sleep while letting problems to rest can often have a “magical” effect. Drawing, writing or even typing are all part of our thinking process, or at least part of my thinking process. <a href="/posts/cake-custard-category.html">Eugenia Cheng</a> is not only a great category theorist, a pure mind, she is also a concert-level pianist. And how many great programmers do I know who also practice some sport or art, sometimes at competitive level?</p>
<p>More generally, it is obvious the brain needs fuel and energy to work at its best and being well fed, rested, energized with a healthy way of life has deep impact on how fast, deep and well we can think. We <em>are</em> bodies and any attempt at denying this fact leads nowhere.</p>
<p>Interestingly, Kant himself, whom Matthew Crawford criticizes so much in his book as being at the root of all the modern evil induced by individualism, the paragon of <em>idealism</em> nevertheless relates directly mind to body. In his <a href="https://en.wikipedia.org/wiki/Critique_of_Pure_Reason">Critics of Pure Reason</a> Kant aims at providing a grand unifying theory of <em>knowledge</em>. From what I understand - feel free to correct me - Kant posits that <em>knowledge</em> comes from the interaction of <em>understanding</em> which is the part of our mind that forms concepts and <em>intuition</em> which is the part that forms experiences. Both faculties are made possible because there exists <em>a priori</em> categories that <em>shape</em> understanding and intuition: <em>Space</em> and <em>time</em> are the tow categories that shape our experience of the world, while <em>causality</em>, <em>totality</em>, <em>unicity</em> and a bunch of others are the categories that shape concepts. I won’t - and can’t - delve into the intricacies of Kant’s philosophy but from what I understand Kant does <em>not</em> state the subject or mind exists independently of the world: On the contrary, he explicitly states that knowledge is only derived from experience and refutes <em>subjective idealism</em>: Self-consciousness exists through interactions with the real world, even though we only perceive phenomena and not the <em>reality in itself</em>. Time and space are “just” the shapes our mind give to our experience.</p>
<p>Trying an analogy, I would say that Kant demonstrated or discovered the <em>language of the mind</em>, and he showed this language is separated in <em>pure</em> - the understanding and concepts - and <em>impure</em> - the intuition and senses - parts. The <em>pure</em> part is what is used to produce meaningful results, but it is useless and inobservable without the <em>impure</em> part which gives it <em>data</em> to process and means to act on the world. “What is the sound of a single hand clapping?” asks the famous Zen koan.</p>
<p>Moreover Kant’s main goal seems to have been to establish solid philosophical foundations for <em>universality</em>: Of objective knowledge, reason and moral judgments. How can different people, with different experiences, can ever reach agreement, know something in common, act for a common good, if there is nothing else but <em>subjective monads</em> isolated from one another? If experience is always personal, nothing can ever be shared. Kant’s answer lies in the <em>a priori</em> of the understanding and perception which shape the way we think and thus makes shared knowledge and perceptions possible, because we all share the same internal machinery to <em>interpret</em> the phenomenal world.</p>
<h1 id="conclusion">Conclusion</h1>
<p>The ambivalent feelings I have with this book can be stated in a very simple way: Although I subscribe to the conclusion of the book, I am doubtful about its premises and I fear that he might be throwing the baby out with the bath’s water:</p>
<ul>
<li>There is a need to reclaim our attention which has been captured and privatised by corporations and state,</li>
<li>This should come from increasing our <em>surface of contact</em> with reality, something that is fostered by shop work and skillful knowledge,</li>
<li>The master-apprentice relationship and the transmission that happens there is key to build skillful and meaningful knowledge, one that is <em>situated</em> both in space and time,</li>
<li>However this <em>communautarian</em> and <em>aristocratic</em> process might come at the price of universality and democracy, as exemplified by the stratified and fragmented societies of the past against which philosophers of the Enlightenment struggled. <em>Corporatism</em> is the reverse of a coin whose observe is <em>craftsmanship</em>.</li>
</ul>
<p>I don’t follow Crawford in his rejections of the project of the <em>Enlightenment</em>, namely the project of founding a universal community of humans. Of course, in the time and place this project’s was born, humanity was restricted to wealthy white european males. And the time of the <em>great tales</em> has passed: We live in post-(post?-)modernist times where irony reigns. And Kant’s philosophy itself might be outdated. But I am not ready to throw away the idea that we need to found, and refound again and again, some form of universal that makes it possible to share the world’s experience and build common knowledge.</p>
<p>I cannot conclude this post without citing Spinoza whose philosophy traces the kind of path Matthew Crawford’s is proposing to us, one of reconciling mind, body and the world in a universal shared by all human beings. Spinoza viewed reality was made of a single <em>substance</em> which manifested itself through an infinity of <em>attributes</em>, only two of which are accessible to us: <em>thought</em> And <em>extension</em>. Hence the deep parallelism between the mind and the body: Whatever affects one affects the other. From those principles Spinoza builds a philosophy that seeks to enhance <em>life</em> maximilizing <em>joy</em> under the guidance of <em>reason</em>. Spinoza himself exemplified this unity of mind and body by being one of the most renowned lens polisher of his time.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Using agile in a startup</title>
    <link href="http://abailly.github.io/posts/agile-startup.html" />
    <id>http://abailly.github.io/posts/agile-startup.html</id>
    <published>2016-04-24T00:00:00Z</published>
    <updated>2016-04-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Using agile in a startup</h1>
<div class="info">Posted on April 24, 2016</div>

<p>This post is a follow-up to my <a href="/posts/cm-arch-design.html">previous post</a> on designing an application in Haskell and part of a series of post I intend to write that reflect on my experience as CTO of Haskell-based startup. Whereas the previous post was very technical, focusing on <em>what</em> we built, this one focuses on <em>how</em> we built it: Processes, methods and tools we used, how the team was built and how it interacts on a daily basis, which problems we encountered and how we solved them (or not)… As before I have tried to be as honest as possible, highlighting both what worked and what did not work so well.</p>
<p>Coming from an Agile background it is no surprise that I consciously tried to reuse the knowledge and tools I knew from previous implementations of Scrum, eXtreme Programming or Kanban. One of the lesson learned during the past year is that Agile needs some serious overhauling to be applied within a startup setting, even more so when the team is distributed. In the conclusion I try to draw on this experience to hint at some trails I would like to explore in the future.</p>
<h1 id="a-bit-of-context">A Bit of Context</h1>
<p>I started working on Capital Match at the end of August 2014. The first commit in the git repository of the application is dated on Wednesday, 20th of August 2014. I worked in the background for a couple of months, mostly to setup the infrastructure, flex my muscles on Haskell, explore the business domain space.</p>
<p>I met physically my co-founder in October. At that time I was still working alone but I already had a working solution that was deployed and “usable”, for some definition of usable. Willem van den Ende joined me to develop the application to production stage at the end of October and brought with him lot of XP and DevOps experience. We were joined by another developer at the beginning of March but this employment lasted only a month.</p>
<p>We went live on the 20th of March, one month after the initial target set in December. The tech team is now 4 people, including me, all of which are mainly developers. We do not have a dedicated operations team and the tech team is responsible for both developing new features and maintaining the application in good operational conditions.</p>
<h1 id="planning">Planning</h1>
<h2 id="project-planning">Project Planning</h2>
<p>We started using <a href="http://taiga.io">taiga.io</a> from November to plan the go-live, first without then with spring planning. It was a good thing to explain to non-tech people we can deliver so much in a period. We quickly settled on 1 week sprints and it took us a while to get to some form of regularity and cadence, never really get to smooth release and meaningful <em>Story Points</em> values. A month or so after go-live we switched to a kanban style process which is not really well supported by taiga.</p>
<p>It seems people are having a hard time understanding SP, and when they understand they start trying to game it and discuss evaluations. It fairly quickly gets back to “when will it be done?” and “can’t we really do it faster?” and “what if we did XX?” questions… Smart people used to work with figures are prone to get to the conclusion figures are acutally measuring output and value and then we will use those figures to measure success.</p>
<p>We dropped formal estimates, even before golive: what’s done is done, when it is not done it is not done. In order to cope with unrealistic expectations and requirements we strived hard to make everything visible, deploy very quickly and allow people to test easily, work in baby steps… in other words reduce the length of the <em>feedback loop</em>. We don’t provide estimates anymore, and people don’t ask for them, except in very broad terms for high-level features which we (I) estimate as S/M/L or some combination thereof.</p>
<p>People also had a hard time using taiga (and I am not sure it would have been better with any other tool…): Response is a bit slow, most of the things don’t make sense for them, they don’t follow really tickets and comments on them… nor do they care much about tracking SPs progress.</p>
<p>So we finally switched to using plain trello:</p>
<ul>
<li>Its interface is very intuitive to pick, and most people already have used it at some previous point,</li>
<li>The user interface is super-fast and reactive,</li>
<li>It provides nearly all the features we need, except swimlanes but we use tags instead,</li>
<li>It is available on a wide variety of platforms, e.g. as a mobile app.</li>
</ul>
<p>We currently use 2 boards:</p>
<ul>
<li><em>Software Development</em> board is used for day-to-day work. It contains baby step features and bugs, and has very simple workflow:
<ul>
<li><em>To prioritize</em> is used for brain dumping features, and we try to clean up at frequent interval,</li>
<li><em>To Do</em> is for actual stuff to do. We strive to keep those items fine-grained, e.g. no more than 1-2 day of work,</li>
<li><em>Doing</em> says it all. We try to minimize Work-in-progress by ensuring people do not work in parallel on more than one feature. It is at this stage that tickets are assigned and not before,</li>
<li><em>Ready for testing</em> means ticket has passed CI (more on this later) and is ready to be tested on <em>staging</em> platform with non-production data. Once or twice a day we send an email notifying people of whatever is available to test on <em>staging</em> platform,</li>
<li><em>Deployed</em> means feature has been deployed to <em>production</em> platform. Just like for staging, we send an email to involved people every time we deploy new feature to production.</li>
</ul></li>
<li><em>Product roadmap</em> board is used for larger scale planning. It contains 3-months columns and coarse grained features estimated using S/M/L t-shirt sizes. There is one <em>Ongoing</em> column which contains features we are currently working on. It is mostly used as a reminder of “large” things we want/need to do.</li>
</ul>
<h2 id="product-development">Product Development</h2>
<p>I wrote a “walking skeleton” in a month or so, starting from initial idea, while my partner was sorting out the business side of things and trying to find seed investors in the project. This walking skeleton was, well, very skeletal, being able to handle only very basic scenario: register borrower/investor, create new simple, loan, commit funding to loan then accept loan.</p>
<p>When go live started to come close, business people got scared and wanted to go into <em>command and control</em> mode, and wanted to go into the following process:</p>
<ul>
<li>They designed very detailed “screens” in Excel with lot of complex business rules, strict wordings… covering the complete scope of the application as we initially discussed it,</li>
<li>Devs would work one screen at a time and <em>complete</em> it before going to the next,</li>
<li>Then they would tests what devs produce,</li>
<li>Then bugs would be notified and needed to be fixed,till business is happy</li>
<li>In short, we were reinventing <em>Waterfall</em> without the good parts (e.g. formal V&amp;V)</li>
</ul>
<p>I used the initial provided design documet to slice everything into small stories with estimates and put that into Taiga, then we started working on it following the aforementioned process. After 1-2 weeks it became obvious to everybody we would not be able to deliver everything that has been designed in excruciating details, because we simply could not code fast enough. Something like about 40-50% only of the designed features were actually shipped on go-live. Hence we reverted to priority-based scheduling and <a href="http://agileatlas.org/articles/item/dimensional-planning">Dimensional planning</a> with one week sprints and a target release date.</p>
<p>At some early stage I tried to use <a href="http://www.agileproductdesign.com/presentations/user_story_mapping/e">Story mapping</a>, maintaining a map of the software’s features using <a href="https://www.mindmup.com/">MindMup</a> a hosted mind-mapping application:</p>
<div class="figure">
<img src="/images/story-map.png" alt="A fragment of Capital Match’s Story Map" />
<p class="caption">A fragment of Capital Match’s Story Map</p>
</div>
<p>The idea was that we would represent the whole process in a map, distinguishing manual/automated parts and filling the leaves with actually available features. However this did not gel and people never get accustomed to use that representation of the software, so I quickly stopped maintaining it.</p>
<h1 id="programming-practices">Programming Practices</h1>
<h2 id="pair-programming">Pair Programming</h2>
<p>We started doing remote pairing with Willem and we still try to do it on a regular basis. Remote pairing works really fine if the network has no hiccup. We have the following simple setting:</p>
<ul>
<li>We setup a remote VM containing the development environment (compilers, source code) and accessible only to the team. Configuration of this VM is kept versioned in our code repository hence it follows the evolution of the code itself which may require over time different dependencies, different compilers… To be able to quickly setup a VM, we use a snapshot instead of full-blown configuration</li>
<li>People connect on the VM using with <a href="http://www.openssh.com/">ssh</a> and <a href="https://tmux.github.io/">tmux</a><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, and we use console-based <a href="https://www.gnu.org/software/emacs/">emacs</a> for hacking. OF course this is possible because we are using languages and tools that do not need a complex visual IDE to work<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>,</li>
<li>We use hangout for voice + video. Small tip, thanks to <a href="">Emmanuel Gaillot</a>: Set your terminal to be slightly transparent so that you can see the remote persons behind the code!</li>
</ul>
<p>I really like pair programming but I found its remote version is more exhausting than its face to face counterpart. It requires more focus and engagement because it is very easy to get distracted as your partner is not there to snoop over your shoulder and see you are actually browsing your emails or twitter. And the lower fidelity communication requires even more focus. However we found that timezone differences forced us to make something like <em>Deferred Pairing</em>: I start some work in France, using <a href="http://slack.com">slack</a> as a stream of consciousness, pushing code to github repository, then I go to sleep. In the middle of the night someone in Asia picks up where I left code and continue working on it till we manage to have some time overlap. Then we can pair for a couple of hours if needed, and restart the whole cycle.</p>
<h2 id="development-automation">Development Automation</h2>
<p><strong>Continuous Integration</strong> is core practice of XP and we embraced it fully from the onset of the project in the form of <em>continous deployment</em>: Each code change’s integration in the existing codebase is checked as soon as the code is published to be available for the whole team to use. Continuous should of course be understood in the mathematical sense, e.g. opposite of <strong>discrete</strong>: You are able to deploy at any point in time, not at certain gateways or releases milestones. I plan to provide more details in another blog post but practically speaking this means:</p>
<ul>
<li>People push to a “central” git repository located on a CI server. Note this repository is central only by virtue of being on the CI server and we could deploy other servers and “central” repositories at will. There is nothing special and we try to keep using git in a distributed way,</li>
<li>This triggers a job on the CI server which, among other things, runs automated tests (more on this later) and deploy an instance of the application for testing, and pushes the same instance to a central repository for deployment to production.</li>
</ul>
<p>This implies managing infrastructure, e.g. VMs, containers, processes and would not be possible without strong automation: <a href="http://www.jedi.be/blog/2013/05/24/Infrastructure%20as%20Code/">Infrastructure as Code</a> and DevOps everywhere, the slogan is: Automate all the things!</p>
<ul>
<li>We can rebuild all our infrastructure from a couple of git repositories
<ul>
<li><strong>Note</strong>: CI server is itself versioned and deployable</li>
<li>VM deployments is not fully automated yet but is scripted</li>
<li>Configuraiton management is versionned and handled in Haskell too</li>
</ul></li>
</ul>
<p>Continuous Integration is really our most important tool for maintaining cohesion in the team and integrity of the software: Any commit pushed to CI triggers whole chain of build down to the point we obtain a <em>deployable application container</em></p>
<h2 id="test-driven-development">Test Driven Development</h2>
<p>I have <a href="/posts/tdd.html">already written</a> on TDD and how much I loved it: To me TDD is <em>THE</em> core practice of XP and its main contribution to the advance of software development. Even in a startup setting I don’t think we made a lot of compromise on writing tests, but the amount of tests that need to be written in a strongly-typed language like Haskell is less than what you would need to write in Ruby or even Java.</p>
<p>Our automated tests are currently divided into 4 types:</p>
<ul>
<li><strong>Property based tests</strong>, expressing pure code’s properties like symmetry of read/write, description of processes, computations… There aren’t that many properties in our code, mostly I think because our domain is rather simple and not easily amenable to compact formulation of properties: There is no point in expressing a property in a way that is as complicated as the code it is supposed to specify,</li>
<li><strong>Integration tests</strong> check our code within the context of I/O, mostly through its REST interface but sometimes only using basic I/O or imperative code. This is where we catch most of our errors because it is very easy to make a mistake when interacting with the outside world, whereas the compiler and explicit types help a lot in catching internal programming mistakes,</li>
<li><strong>User Interface tests</strong> are actually unit tests for the UI code which is written in Clojurescript. These are the least developed part of our test stack which is a pity given the dynamic nature of the language we use and the amount of UI code we have, but we try to remove logic from UI as much as possible and most of the issues we have at this level are actually user interactions problems which can more quickly be caught through actually using the interface,</li>
<li><strong>End-to-End tests</strong> like their name implies tests the application at the highest-level using <a href="http://www.seleniumhq.org/">Selenium</a> to drive a browser to interact with the application like a human being would do. We have about 20 tests in this category and we try to keep that number low as obviously they are the more costly ones to run. However they are really invaluable in catching complex integration issues.</li>
</ul>
<h1 id="team">Team</h1>
<h2 id="on-being-remote">On Being Remote</h2>
<p>Working remotely has been an integral part of the organization since the beginning. We are 6-7 hours apart, e.g. it is afternoon in Singapore when I wake up. This means we have about 3-4 hours of overlap, but we span 16-17 hours of wall clock time. Here are some features that are entailed by being remote:</p>
<ul>
<li>This removes the need for a dedicated support/ops team, at least as long as we are smallish (see above notes about automation)</li>
<li>We do our stand-up meeting at 9am or 10am Paris Time, acts as a sync point,</li>
<li>We use overlap time for discussing stuff, pairing, solving design or hard technical problems. Hangout works ok but it would probably be better with dedicated software e.g. gotomeeting or equivalent)</li>
<li>We found that timezone differences are actually great for catching date/time related bugs!</li>
<li>We use <a href="http://slack.com">Slack</a> <strong>a lot</strong>. We could use IRC of course but it would require some more infrastructure and it is not as friendly to non tech-savvy persons:
<ul>
<li>We use ut to chat within the team and discuss technical stuff, post screnshots, code examples, design ideas…</li>
<li>We use it as a <strong>stream of consciousness</strong> endpoint: I dump what I am doing, jot down ideas, humours, feelings… When people wake up in the morning they have a trace of what I have done apart from the actual code/builds I produced and what I have been thinking of</li>
<li>We also use it as an endpoint for some important monitoring information, e.g. when something is pushed to central git repository or when state of a server changes.</li>
</ul></li>
</ul>
<p>There is a great post about <em>Remote First</em> culture: http://zachholman.com/posts/remote-first/ which you should read, along with 37 Signal’s <a href="http://37signals.com/remote">Remote</a>. They both emphasizes the fact that working remotely works <strong>if and only if</strong> the whole organisation is built around this premise. Think as a counter-example organisations that have a handful of offices which need to work distributedly. Distribution was an afterthought, something that came up as a constraint because of mergers, and no amount of tooling can make that kind of culture work.</p>
<p>Remote work can help reduce stress, especially in startups: Being remote means you can simply <em>remove</em> pressure from business people when it becomes too heavy. It can also help minimizes personality clash, cool down interactions. Being face-to-face increases cues and hints about the other person’s feelings but is also a great way to generate stress and emotions. The counterparty is <em>trust</em>: People at the other side of the world trust you to do what needs to be done</p>
<h2 id="hiring">Hiring</h2>
<p>The team is currently very small but hiring has been and will stay a team matter. Because we use a niche technology our recruitment is necessarily international and we must be prepared to recruit and work remotely, and actually <em>I was recruited as co-founder remotely…</em></p>
<p>Our hiring process is currently quite simple:</p>
<ul>
<li>Initial interview with me and/or another dev where I try to assess current skill level of candidate. Usually ask questions related to basic XP practices like TDD</li>
<li>2 hours pairing (or tripling) session using our remote dev environment: We usually tackle the <a href="https://github.com/emilybache/GildedRose-Refactoring-Kata/">GildedRoseKata</a> in Haskell, or if candidate is not comfortable enough in his favourite language (Javascript, Java…)</li>
<li>Interview with CEO and negotiations…</li>
<li>Here we go!</li>
</ul>
<p>Applying agile principles to hiring means that we are ready to experiment for a week or a month, reflect and improve, and possibly stop early (this occured already once). Doing this remotely also means more flexibility and more risks:</p>
<ul>
<li>If the person you hire wants to cheat, e.g. steal your code, she can do so quite easily,</li>
<li>Developers are freelance in their country, which means they can stop at any time,</li>
<li>Hence finally there is an incentive for Capital Match to keep people happy and motivated.</li>
</ul>
<p>Hiring is one of those (numerous) areas where I see a lot of improvements and where being remote is a game changer.</p>
<h1 id="theorizing">Theorizing</h1>
<p>Lessons learnt are most interesting if you can leverage them into some form of theoretical knowledge that can be turned into useful guidelines for future decisions. This section tries to extract some possibly useful insights and generalisations from this limited experience, which I can summarize in three points:</p>
<ul>
<li>Treating software as <em>development projects</em> alone is a fallacy that leads to costly errors,</li>
<li><em>Technology matters</em>,</li>
<li>Our software is part of a <em>system</em> that has different requirements at different moments in time.</li>
</ul>
<h2 id="the-software-development-project-fallacy">The Software Development Project Fallacy</h2>
<p>There is not a dearth of software development project management methods, whether Agile or not: Kanban, Scrum, RUP, Waterfall, V, W, Design Controls… And symetrically there are quite a few methods targeted at managing operations and support in IT, like ITIL, although I am much less familiar with those. The fact is they are all inspired by the logic of <em>manufactured goods design and production</em> where:</p>
<ol style="list-style-type: decimal">
<li>The good undertakes a series of transformations, from design to production, up to the point it is ready for consumption by the “public”,</li>
<li>Where it falls into the hands of another group of people which is responsible for <em>maintenance</em> or <em>end-users support</em>.</li>
</ol>
<p>If we focus on Scrum alone, we find the core artifact to be the <strong>sprint</strong> and a number of sprints ultimately leading to a <strong>release</strong>. But sprints, and for that matter any form of time-constrained activity, are inherently exhausting and ultimately unsustainable, hence the mutiplications of <em>hardening sprints</em>, <em>release sprints</em>, <em>sprint 0</em>… which are all attempts to depart from the sprint/release straightjacket. What Scrum and even XP which is dearer to my heart misses is the <em>Operations</em> part of a system</p>
<blockquote>
<p>Scrum is a management and control process that cuts through complexity to focus on <em>building software</em> that meets business needs. Management and teams are able to get their hands around the requirements and technologies, never let go, and deliver working software, incrementally and empirically.</p>
<p>Scrum itself is a simple framework for effective team collaboration on complex <em>software projects</em>.</p>
<p><a href="https://www.scrum.org/resources/what-is-scrum">Scrum.org</a></p>
</blockquote>
<p>The way of thinking this methods promote is inherently constrained by a time-bound horizon: The moment the product will be considered “finished” and leave the organisation that produced it, hence the emphasis of the <strong>release</strong>. Lets remember that <em>Deliver</em><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> also means <em>give birth</em> and bears with it the idea that something we have been fostering for months is freed from our control, which also suggests we are freeing ourselves of it. Deliver’s substantive is <a href="http://www.wordreference.com/enfr/deliverance">deliverance</a>… The <em>release</em> becomes the horizon of the team and with it comes relief, and then we move on to something else.</p>
<p>What I have learnt over the years but even more so over the past months working on this project is the importance of evaluating your capability to deliver features against your capability to maintain your software and make it able to sustain more change in the future. Viewing software systems solely under the angle of <em>projects</em> leads to a bias, from all persons involved, towards delivering more under time pressure which is the biggest source of errors. When your horizon is time constrained you cannot pay enough attention to the small warnings that will lead to big failures.</p>
<h2 id="technology-matters">Technology matters</h2>
<blockquote>
<p>“The technology, stupid.”</p>
<p>liberally adapted from <a href="https://en.wikipedia.org/wiki/It&#39;s_the_economy,_stupid">James Carville</a></p>
</blockquote>
<p>Obviously a lot of the things we do are made possible thanks to technology:</p>
<ul>
<li>Being distributed is now workable because there are quite a few affordable tools out there that make this style of working possible for small teams: Google Hangouts, Skype, Slack/IRC, mails of course, Git, SSH, Cloud providers, Docker, Linux are all key ingredients to make our distributed workplace possible<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>,</li>
<li>Developing our business as an online platform is also a key factor in enabling both an <em>iterative</em> and inherently <em>agile</em> style of software but also in the availability of tools and systems. It is much harder to develop an embedded controller’s system in a remote way because your software is physically tied to something concrete,</li>
<li>The free and/or open-source movement has popularised geographically distributed teams and flat hierarchies for developing even very large pieces of software.</li>
</ul>
<p>But I do think that our particular technology stack (e.g. Haskell) choice has a deep impact in enabling this distributed agile style of working:</p>
<ul>
<li>Haskell is (still) a <a href="http://githut.info/">niche language</a> for at least two reasons: Because of its paradigm which is very different from maintstream languages and platforms, and because of its history which ties it to academic and esoteric PLT research more than to the production of mundane web applications, <img src="/images/haskell-ranking.png" alt="Latest Ranking from http://githut.info" /></li>
<li>Due to its niche nature, it attracts programmers that either want to distinguish themselves and/or are inherently attracted by the different, not to say the bizarre… This is often the kind of people that are ready to make some extra efforts to keep on working with such a language, including working with shifted hours, moving to a foreign country, learning new tools and processes…</li>
<li>On a more technical side, this particular choice allows us to work mostly through lightweight text-based tools, e.g. terminals, text editors, SSH… something which is invaluable when you have to communicate over 10000 kilometers and flacky Internet.</li>
</ul>
<p>Technology is not neutral. As explained by <a href="/posts/eme.html">Bruno Latour</a>, technology is embodied into technical beings whose needs must be adressed in specific ways and with whom we need to interact in specific ways. Technology shapes our worldview and the way we work in a lot of different and sometimes surprising ways. But it is always worthwhile to think about it beforehand…</p>
<h2 id="from-project-to-system">From Project to System</h2>
<p>My experience suggests a different approach which does not reject the benefits of iterative software <em>development</em> but makes it part of a bigger process which also encompasses the need for periods of reflection and calm. We should acknowledge the duality (at least) in our processes:</p>
<ul>
<li><strong>Period I</strong>: Moments of <em>intense</em> activity, which might be due to deadlines, objectives, production incidents to solve, security issues…</li>
<li><strong>Period II</strong>: Moments of <em>routine</em> activity where team can reflect, define processes and procedures, refine things, document…</li>
</ul>
<p>Agile methods are good at channelling the intensity of period I through a simple process but they are much less appropriate for period II which is mostly characterized by the absence of definite goal(s). This explains the rise of “hybrid” approaches and the success of Kanban which offers a much more appropriate framework to handle period II work (and conversely is not very well suited to period I…). This also explains the moderate success (at best) Agile methods have with operations or highly regulated settings.</p>
<p>There is a lot to get inspired from the way <a href="http://high-reliability.org/">Highly Reliable Organisations</a> work and the numerous research studies that have been written about those organisations. I was also personally heavily influenced by <a href="/posts/decisions-absurdes.html">“Les décisions absurdes”</a> which describes the mechanics of group thinking and how they can lead to catastrophic failures. HRO studies show that those organisations which <strong>must</strong> be reliable actually acknowledge the existence of those two modes of operations. The best such organisations know how to take advantage of <em>routine</em> mode (what I call Period II) to become better when the need arises to go into <em>intense</em> mode or Period I.</p>
<p>Think of those analogies:</p>
<ul>
<li>In sport, athletes do not spend 100% of their time competing, and actually competition accounts for a small fraction of their worktime, most of it is dedicated to training, learning, improving, reflecting on past competitions,</li>
<li>Musicians and other performers do the same: A lot of time training and practicing, small fraction of their time on stage,</li>
<li>Soldiers and military are an even better analogy because period of conflicts can last for an extended period of time and even then, army takes care of rotating personel, replacing people on the front with fresh troops on a regular basis.</li>
</ul>
<blockquote>
<p>The content of this post was used to present a session at <a href="http://www.agilenantes.org/agile-tour-nantes-2015/">Agile Tour Nantes 2015</a>: Thanks to the organisers for having accepted that talk.</p>
<p>Thanks to Anne Caron-Perlon for her very helpful comments and remarks.</p>
<p>Thanks to Capital Match Team for those exciting 2 years.</p>
</blockquote>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>It seems that <a href="http://tmate.io/">tmate</a> provides even better support for that at the expense of having to setup a centralised server for people to log in.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Looks like the smart people at /ut7 have given a name to this: They call it <a href="http://ut7.fr/posts/blog/2015/03/05/les-pieds-dans-la-bassine.html">La bassine</a> and apparently this has been developed as part of work on project for <a href="http://blog.deliverous.com/2015-03-06.bassine.html">Deliverous</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>This comes from the French <em>Délivrer</em> which can be translated to <em>get rid of</em>, <em>relieve</em>, <em>set free</em><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Back in the 90s or even early 2000s you would have to be either a large corporation, a university or deep hacker group to be able to work distributedly in real time<a href="#fnref4">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Spinoza encule Hegel&quot;</title>
    <link href="http://abailly.github.io/posts/spinoza-encule-hegel.html" />
    <id>http://abailly.github.io/posts/spinoza-encule-hegel.html</id>
    <published>2016-04-23T00:00:00Z</published>
    <updated>2016-04-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Spinoza encule Hegel&quot;</h1>
<div class="info">Posted on April 23, 2016</div>

<p>Une France post-apocalyptique et comme suspendue. Des gangs sillonent l’ex-capitale et le pays pour s’entretuer. Ils ont nom <em>Sang Noir de Bakounine</em>, <em>Docteur Jdanov</em>, <em>Planète Potlatch</em>, <em>Jeunes Hégeliens</em>… Julius Puech est le chef de la <em>Fraction Armée Spinoziste</em>. Il porte des bottes de lézard mauves et voue une haine farouche aux Hégeliens dont le chef s’appelle Thorez. Il aime Spinoza et François. Il a de la sympathie pour le Diable. Tout ça finira très mal.</p>
<div class="figure">
<img src="/images/spinoza-encule-hegel.jpg" class="floating" height="300" />

</div>
<p>Plutôt que <em>La septième fonction du langage</em> de Laurent Binet qui y fait référence, mieux vaut lire <a href="https://fr.wikipedia.org/wiki/Spinoza_encule_Hegel">Spinoza encule Hegel</a> de Jean-Bernard Pouy. Si possible vite, très vite. Avec une bouteille d’alcool fort à portée de la main, et les Stones à fond dans les oreilles. Ou alors entre deux propositions de l’Éthique. Mais le texte n’a pas besoin d’adjuvants pour exciter les sens, enivrer. La prose est hypnotique et balistique, mais sait se faire lyrique quand elle évoque les amours - exclusivement masculines - des héros. Manière élégante somme toute de dépasser le sexisme inhérent aux situations riches en testostérone. D’ailleurs, le héros finira esclave d’un gang exclusivement féminin pas moins nihiliste que ses congénères masculins.</p>
<p>Métaphore sous acide d’un mai 68 qui s’éloigne et dont on sait les fruits amers, SEH est un livre coup-de-poing-dans-le-bide autant qu’une blague de potache. Un éclat de rire autant qu’un chant mélancolique. Je ne sais pas si je l’aime par nostalgie d’une époque fantasmée, par regret d’être venu trop tard, à l’époque de la Grande Récupération - ou de la Grande Trahison - après que les plus malins eurent transformés le capital intellectuel accumulé dans les seventies en capital tout court.</p>
<p>Ou parce qu’il me reste encore un peu de la rage adolescente.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>First Steps with MirageOS</title>
    <link href="http://abailly.github.io/posts/mirage-os-newbie.html" />
    <id>http://abailly.github.io/posts/mirage-os-newbie.html</id>
    <published>2016-04-22T00:00:00Z</published>
    <updated>2016-04-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>First Steps with MirageOS</h1>
<div class="info">Posted on April 22, 2016</div>

<p>This post is a follow-up to the session I gave at <a href="http://cfp.devoxx.fr/2016/talk/KEN-7124/Unikernel:_Le_conteneur_du_futur">Devoxx France</a> on <a href="http://mirage.io">MirageOS</a>. It provides detailed instructions on how to setup a development environment to be able to:</p>
<ul>
<li>Build locally Mirage projects and generate native binaries with <code>--unix</code> configuration flag,</li>
<li>Install and configure a VirtualBox VM that runs Xen Hypervisor,</li>
<li>Build Xen-enabled Mirage unikernels on this VM.</li>
</ul>
<h2 id="references">References</h2>
<p>Those points are already covered in other documentation material available here and there on the web and I mainly did some synthesis from a <em>newbie</em> perspective. Here is a list of resources that were helpful in making this post:</p>
<ul>
<li><a href="https://mirage.io/wiki/">Official MirageOS Wiki</a> which contains various tutorials,</li>
<li><a href="https://github.com/mirage/mirage-www/">mirage-www</a>, the self-hosted website,</li>
<li><a href="http://www.skjegstad.com/blog/2015/01/19/mirageos-xen-virtualbox/">Magnus Skjegstad</a> blog post which mostly covers point 2. above, and <a href="http://www.skjegstad.com/blog/2015/03/25/mirageos-vm-per-url-experiment/">another post</a> which covers more advanced stuff,</li>
<li><a href="https://www.somerandomidiot.com/blog/2014/07/25/doing-nothing-in-mirage/">Doing nothing in Mirage</a>, an older post on basic configuration,</li>
<li>An account on recent Solo5 development to <a href="https://mirage.io/blog/introducing-solo5">run Mirage on Qemu</a>,</li>
<li>Another <em>getting started</em> <a href="http://roscidus.com/blog/blog/2014/07/28/my-first-unikernel%2F">blog post</a></li>
<li>Some random pages on Xen configuration:
<ul>
<li><a href="http://superuser.com/questions/737976/how-do-i-get-xen-domu-guests-to-have-internet-access">Accessing the Internet from domU kernels</a>,</li>
<li><a href="http://wiki.xenproject.org/wiki/Host_Configuration/Networking">Networking in Xen</a>, not for the faint of heart,</li>
<li>Related work for <a href="https://github.com/GaloisInc/HaLVM/wiki/Building-a-Development-Virtual-Machine">HaLVM</a>, the unikernel system in Haskell.</li>
</ul></li>
</ul>
<h1 id="a-naive-authentication-service">A Naive Authentication Service</h1>
<h2 id="goal">Goal</h2>
<p>The goal of this post is to build a simple HTTP service that can authenticate users based on their password. This service’s specification is simple, not to say simplistic and naive:</p>
<ul>
<li>It maintains a key/value store from user names to passwords (we do not care about encryption here but of course they should be),</li>
<li>It receives <code>GET</code> HTTP requests on port 80 and expects two parameters in the query part: A <code>user</code> string and a <code>password</code> string,</li>
<li>If the given password for given user matches stored password, it responds with <code>200 OK</code>,</li>
<li>In all other cases it should return <code>401 UNAUTHORIZED</code>.</li>
</ul>
<p>To build this service we need to:</p>
<ul>
<li>Run a HTTP Server: I will use <a href="https://github.com/mirage/ocaml-cohttp">ocaml-cohttp</a> which is built specifically to be run within MirageOS applications,</li>
<li>Store data in some key/value store: MirageOS provides <code>kv_ro</code> which is an abstract key/value store which can be backed in code or in a FAT-formatted disk image.</li>
</ul>
<h2 id="server-code">Server Code</h2>
<p>The server code resides in a <code>unikernel.ml</code> file. I am not at all familiar with OCaml so my code is probably not really idiomatic. Learning OCaml is one of the reasons I became interested in MirageOS in the first place !</p>
<p>We first need some usual incantations to “import” names, e.g. opening modules in OCaml:</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="ot">open</span> String
<span class="ot">open</span> Lwt
<span class="ot">open</span> Lwt<span class="kw">.</span>Infix
<span class="ot">open</span> V1_LWT
<span class="ot">open</span> Printf</code></pre></div>
<p>The <code>string_of_stream</code> function is adapted from the basic <code>kv_ro</code> example provided in <a href="https://github.com/mirage/mirage-skeleton">mirage-skeleton</a>. Its name is pretty explicit…</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">let</span> string_of_stream stream =
  <span class="kw">let</span> s = List<span class="kw">.</span>map Cstruct<span class="kw">.</span>to_string stream <span class="kw">in</span>
  return (String<span class="kw">.</span>concat <span class="st">&quot;&quot;</span> s)</code></pre></div>
<p>The main module is parameterized by 3 signatures which are provided by MirageOS according to the configuration given at build-time. Here we have 3 modules: The console for outputting some logs, the Key/Value store and <code>conduit</code> which provides network connectivity:</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="ot">module</span> Main (<span class="dt">C</span>:<span class="dt">CONSOLE</span>) (<span class="dt">K</span>: <span class="dt">KV_RO</span>) (<span class="dt">CON</span>:Conduit_mirage<span class="kw">.</span><span class="dt">S</span>) = <span class="kw">struct</span></code></pre></div>
<p>We build a new module by passing underlying connection manager to our HTTP server implementation then we can define our <code>start</code> entry point:</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml">  <span class="ot">module</span> H = Cohttp_mirage<span class="kw">.</span><span class="dt">Server</span>(Conduit_mirage<span class="kw">.</span><span class="dt">Flow</span>)

  <span class="kw">let</span> start console k conduit =</code></pre></div>
<p>We first define the function that will check the database for matching username/password pair, given an access request. The main thing to note here is that reading from the store happens within the context of so-called <em>light-weight threads</em> or <code>Lwt</code> which is the basic Mirage cooperative thread execution model. Potentially blocking operations expect a <em>continuation</em> that will be passed the result of the operation.</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml">    <span class="kw">let</span> check_pwd u p =
      K<span class="kw">.</span>read k u <span class="dv">0</span> <span class="dv">4096</span> &gt;&gt;= <span class="kw">fun</span> readpwd -&gt;
      <span class="kw">match</span> readpwd <span class="kw">with</span>
      | <span class="dt">`Ok</span> pwds -&gt;
         string_of_stream pwds &gt;&gt;= <span class="kw">fun</span> pwd -&gt;
         return $ compare (trim pwd) p == <span class="dv">0</span>
      | _ -&gt; return <span class="kw">false</span>
    <span class="kw">in</span> </code></pre></div>
<p>Then comes the meat of the server, the <code>http_callback</code> function that will be called by cohttp upon everyrequest. We extract interesting parts of the request’s URI then check whether or not the username/password pair matches, and finally return a response.</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml">    <span class="kw">let</span> http_callback _conn_id req _body =
      <span class="kw">let</span> uri  = Cohttp<span class="kw">.</span>Request<span class="kw">.</span>uri req             <span class="kw">in</span>
      <span class="kw">let</span> path = Uri<span class="kw">.</span>path uri                       <span class="kw">in</span>
      <span class="kw">let</span> user = Uri<span class="kw">.</span>get_query_param uri <span class="st">&quot;user&quot;</span>     <span class="kw">in</span>
      <span class="kw">let</span> pwd  = Uri<span class="kw">.</span>get_query_param uri <span class="st">&quot;password&quot;</span> <span class="kw">in</span>
      <span class="kw">match</span> (user,pwd) <span class="kw">with</span>
      | (<span class="dt">Some</span> u, <span class="dt">Some</span> p) -&gt;
          check_pwd u p &gt;&gt;= <span class="kw">fun</span> chk -&gt; 
          <span class="kw">if</span> chk
          <span class="kw">then</span> H<span class="kw">.</span>respond_string ~status:<span class="dt">`OK</span> ~body:(sprintf <span class="st">&quot;hello %s!</span><span class="ch">\n</span><span class="st">&quot;</span> u) ()
          <span class="kw">else</span> H<span class="kw">.</span>respond_string ~status:<span class="dt">`Unauthorized</span> ~body:<span class="st">&quot;Invalid login</span><span class="ch">\n</span><span class="st">&quot;</span> ()
      | _                -&gt;
          H<span class="kw">.</span>respond_string ~status:<span class="dt">`Unauthorized</span> ~body:<span class="st">&quot;No user given</span><span class="ch">\n</span><span class="st">&quot;</span> ()
    <span class="kw">in</span></code></pre></div>
<p>It remains to start the ball rolling by creating the HTTP server and listening on some port, using underlying <code>CON</code>duit module implementation:</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml">    <span class="kw">let</span> spec = H<span class="kw">.</span>make ~callback:http_callback () <span class="kw">in</span>
    CON<span class="kw">.</span>listen conduit (<span class="dt">`TCP</span> <span class="dv">8088</span>) (H<span class="kw">.</span>listen spec)
end</code></pre></div>
<p>The single most important thing to note here is that this code is pretty much system-agnostic: There is no dependency on a particular low-level runtime infrastructure and the same code can be run either as a native binary on Unix or packaged as unikernel on Xen (or QEMU). Implementation details are hidden behind the signatures, e.g. interfaces, that parameterize the <code>Main</code> module and whose instances are passed to the <code>start</code> function.</p>
<h2 id="configuring-mirage">Configuring Mirage</h2>
<p>The second important file one has to write for a MirageOS application is the <code>config.ml</code> file which is used by <code>mirage</code> tool to generate the needed boilerplate to run the actual code.</p>
<p>After the incantation to access <code>Mirage</code> module’s content, we define our first component that will be melded in our application. This one is a simple generic key/value store whose content will be built from the <code>data/</code> directory. In Unix mode requests for some key will be matched to the content of the <code>data/</code> directory, whereas in Xen mode we will need to pack that data inside a block device and mount that device in the built kernel</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="ot">open</span> Mirage

<span class="kw">let</span> auth_data = generic_kv_ro <span class="st">&quot;data&quot;</span></code></pre></div>
<p>Our second component is the HTTP server. We can see here our configuration depends on the underlying platform. Note that the <code>generic_stackv4</code> provides IPv4 implementation for both Unix and Xen and strictly speaking we could get rid of the <code>if_impl</code> construct. It is also possible to use a <code>direct_stackv4_with_default_ipv4</code> implementation on Xen: This will assign a static IP to the kernel which can be changed when configuring mirage.</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">let</span> server =
  <span class="kw">let</span> network =
    if_impl Key<span class="kw">.</span>is_xen
            (generic_stackv4 default_console tap0)
            (socket_stackv4 default_console [Ipaddr<span class="kw">.</span>V4<span class="kw">.</span>any]) <span class="kw">in</span>
  conduit_direct network</code></pre></div>
<p>The <code>handler</code> function defines the general structure of our service and adds some libraries and packages to be imported by mirage. Then we can finally register our <code>auth_service</code> passing it the result of invoking handler with actual implementation of the modules it requires.</p>
<div class="sourceCode"><pre class="sourceCode ocaml"><code class="sourceCode ocaml"><span class="kw">let</span> handler =
  <span class="kw">let</span> libraries = [<span class="st">&quot;mirage-http&quot;</span>] <span class="kw">in</span>
  <span class="kw">let</span> packages = [<span class="st">&quot;mirage-http&quot;</span>] <span class="kw">in</span>
  foreign
    ~libraries ~packages
    <span class="st">&quot;Unikernel.Main&quot;</span> (console @-&gt; kv_ro @-&gt; conduit @-&gt; job)

<span class="kw">let</span> () =
  register <span class="st">&quot;auth_service&quot;</span> [handler $ default_console $ auth_data $ server]</code></pre></div>
<p>I must confessh this part is still a bit mysterious to me…</p>
<h2 id="building-on-unix">Building on Unix</h2>
<p>We will assume <a href="https://mirage.io/wiki/install">mirage is installed</a> according to the instructions. At the time of this writing, we use:</p>
<pre><code>$ opam --version
1.2.2
$ ocamlc -version
4.02.3
$ mirage --version
2.8.0</code></pre>
<p>We can first try to build and run our service on Unix, e.g. locally. We first need to populate a <code>data/</code> directory with some files representing usernames and add a password inside each file. Then we can configure Mirage, build the executable using the generated <code>Makefile</code> and run it.</p>
<pre><code>$ mirage configure -vv --unix
...
$ make
$ ./mir-auth_service
Manager: connect
Manager: configuring</code></pre>
<p>In another console, we can test that our authentication service works correctly:</p>
<pre><code>$ curl -v http://localhost:8088/foo/bar?user=john\&amp;password=password
&lt; HTTP/1.1 200 OK
&lt; content-length: 12
&lt; 
hello john!
$ curl -v http://localhost:8088/foo/bar?user=john\&amp;password=passwor
&lt; HTTP/1.1 401 Unauthorized
&lt; content-length: 14
&lt; 
Invalid login</code></pre>
<p>So far, so good! We are now ready to test our unikernel for “real”, e.g. to configure a VM running Xen in VirtualBox…</p>
<h1 id="configuring-a-xen-vm-on-virtualbox">Configuring a Xen VM on Virtualbox</h1>
<blockquote>
<p><strong>Note</strong>: This has only been tested on the Ubuntu 14.04 box</p>
</blockquote>
<p>Fortunately for us, all the grunt work has already been done in the <a href="https://github.com/abailly/mirage-vagrant-vms">mirage-vagrant-vms</a> which I simply forked and extended to add the following features:</p>
<ul>
<li>Install the latest <em>Official</em> version of ocaml toolchain and mirage environment,</li>
<li>Configure a <em>host-only</em> network for the VM,</li>
<li>Configure <em>bridge</em>, <em>dnsmasq</em> and <em>IP forwarding</em> in the VM to be used by Xen domU kernels.</li>
</ul>
<h2 id="networking">Networking</h2>
<p>The part I had most difficulties with is of course the networking part. We want the <em>domU</em> virtual machines running on top of Xen hypervisor inside the VirtualBox VM to be visible from our <em>host</em>. The following picture tries to render my understanding of the network topology and configuration we want to achieve (actual IPs/MACs may of course differ).</p>
<div class="figure">
<img src="/images/xen-vm-network-topo.png" />

</div>
<p>The VirtualBox engine exposes the host-only interface to the host as <code>vboxnet4</code> with a pre-configured IP (e.g. IP is set in <code>Vagrantfile</code> as part of definition of host-only network). This interface is linked to the <code>eth1</code> “physical interface” inside the VM and part of the same <em>ethernet</em> network. We create a <code>br0</code> interface which is a bridge: An interface that connects two or more interfaces by routing the packets to/from each of the bridged interfaces. In this case it connects the host-only interface (<code>eth1</code>) and the the virtual interfaces created for each domU kernel, in this case <code>vif1.1</code>. The latter is pair of a pair of virtual interfaces created by underlying hypervisor when the domU kernel boots up, the other member of the pair being the <code>tap0</code> interface on the domU side. Each packet going through either interface is made available to the other interface.</p>
<p>Another important is configuring and activating <a href="http://www.thekelleys.org.uk/dnsmasq/doc.html">dnsmasq</a> to ensure domU kernels will be able to get an IP address using DHCP. Here we configure it to be attached to <code>br0</code> interface - our bridge - and to serve IPs from 192.168.77.3 to 192.168.77.200.</p>
<p>Last but not least, one must not forget to enable <strong>promiscuous mode</strong> on the host-only NIC created for the VM: I spent a couple hours trying to understand why my packets could not reach the unikernel although I could see ARP frames being exchanged…</p>
<h2 id="building-mirageos-kernel-on-xen-enabled-vm">Building MirageOS kernel on Xen-enabled VM</h2>
<p>We are now ready to configure, build and run our unikernel on Xen VM. We assume code has been somehow uploaded to the VM:</p>
<pre><code>$ mirage configure --xen -vv --net direct --dhcp true --tls false --network=0
...
$ make</code></pre>
<p>This creates a bunch of new files in the project’s directory, the most important one being <code>auth_service.xl</code>:</p>
<pre><code># Generated by auth_service (Wed, 20 Apr 2016 13:53:27 GMT).

name = &#39;auth_service&#39;
kernel = &#39;/Users/arnaud/projects/unikernel/auth-service/mir-auth_service.xen&#39;
builder = &#39;linux&#39;
memory = 256
on_crash = &#39;preserve&#39;

disk = [ &#39;format=raw, vdev=xvdb, access=rw, target=/Users/arnaud/projects/unikernel/auth-service/tar_block1.img&#39;, &#39;format=raw, vdev=xvdc, access=rw, target=/Users/arnaud/projects/unikernel/auth-service/fat_block1.img&#39; ]

# if your system uses openvswitch then either edit /etc/xen/xl.conf and set
#     vif.default.script=&quot;vif-openvswitch&quot;
# or add &quot;script=vif-openvswitch,&quot; before the &quot;bridge=&quot; below:
vif = [ ]</code></pre>
<p>This is the descriptor that is passed to the Xen launcher to start the unikernel. We must also not forget to build the disk image that will be loaded in our unikernel and exposed to our program as a key/value store:</p>
<pre><code>$ ./make-fat_block1-image.sh
$ sudo xl -v create -c auth_service.xl</code></pre>
<p>The <code>-v</code> option asks <code>xl</code> to be verbose and the <code>-c</code> attaches a console to the launched kernel.</p>
<p>This does not work out of the box and I needed to manually edit the generated files to fix a couple of minor issues:</p>
<ul>
<li>The <code>disk</code> section of <code>auth_service.xl</code> contains 2 disks but we only generate one of them, the <code>fat_block1.img</code>: The <code>tar_block1.img</code> must be removed from the list,</li>
<li>The file <code>auth_service.xe</code> also contains some descriptor for the same image, which needs to be also removed,</li>
<li>The <code>vif = []</code> part should also be replaced by <code>vif = [ &quot;bridge=br0&quot; ]</code> to ensure network device for unikernel is attached to the bridge and can actually be assigned an IP through dnsmasq,</li>
<li><code>memory = 256</code> is also way too much: Replace with <code>memory = 32</code> which should be enough (16 does not work…),</li>
<li>There is a slight error in the <code>make-fat_block1-image.sh</code>: The block size used is made equal to the total size of the files to include in the image, which does not seem to make much sense. I set it to be 32Kb.</li>
</ul>
<p>With this modifications one should expect to see something like the following being printed to the console:</p>
<pre><code>MirageOS booting...
Initialising timer interface
Initialising console ... done.
getenv(OCAMLRUNPARAM) -&gt; null
getenv(CAMLRUNPARAM) -&gt; null
getenv(PATH) -&gt; null
Unsupported function lseek called in Mini-OS kernel
Unsupported function lseek called in Mini-OS kernel
Unsupported function lseek called in Mini-OS kernel
getenv(OCAMLRUNPARAM) -&gt; null
getenv(CAMLRUNPARAM) -&gt; null
getenv(TMPDIR) -&gt; null
getenv(TEMP) -&gt; null
Netif: add resume hook
Netif.connect 0
Netfront.create: id=0 domid=0
 sg:true gso_tcpv4:true rx_copy:true rx_flip:false smart_poll:false
MAC: 00:16:3e:2e:c2:ce
Attempt to open(/dev/urandom)!
Unsupported function getpid called in Mini-OS kernel
Unsupported function getppid called in Mini-OS kernel
Manager: connect
Manager: configuring
DHCP: start discovery

Sending DHCP broadcast (length 552)
DHCP response:
input ciaddr 0.0.0.0 yiaddr 192.168.77.157
siaddr 192.168.77.2 giaddr 0.0.0.0
chaddr 00163e2ec2ce00000000000000000000 sname  file 
DHCP: offer received: 192.168.77.157
DHCP options: Offer : DNS servers(192.168.77.2), Routers(192.168.77.2), Broadcast(192.168.77.255), Subnet mask(255.255.255.0), Unknown(59[4]), Unknown(58[4]), Lease time(3600), Server identifer(192.168.77.2)
Sending DHCP broadcast (length 552)
DHCP response:
input ciaddr 0.0.0.0 yiaddr 192.168.77.157
siaddr 192.168.77.2 giaddr 0.0.0.0
chaddr 00163e2ec2ce00000000000000000000 sname  file 
DHCP: offer received
                    IPv4: 192.168.77.157
                                        Netmask: 255.255.255.0
                                                              Gateways: [192.168.77.2]
ARP: sending gratuitous from 192.168.77.157
DHCP offer received and bound to 192.168.77.157 nm 255.255.255.0 gw [192.168.77.2]
Manager: configuration done</code></pre>
<p>And if now query our service from the host, it should reply:</p>
<pre><code>$ curl -v http://192.168.77.157:8088/foo/bar?user=john\&amp;password=password
*   Trying 192.168.77.157...
* Connected to 192.168.77.157 (192.168.77.157) port 8088 (#0)
&gt; GET /foo/bar?user=john&amp;password=password HTTP/1.1
&gt; Host: 192.168.77.157:8088
&gt; User-Agent: curl/7.43.0
&gt; Accept: */*
&gt; 
&lt; HTTP/1.1 200 OK
&lt; content-length: 12
&lt; 
hello john!
* Connection #0 to host 192.168.77.157 left intact</code></pre>
<p>With the corresponding trace on the server side being:</p>
<pre><code>ARP responding to: who-has 192.168.77.157?
ARP: transmitting probe -&gt; 192.168.77.1
ARP: updating 192.168.77.1 -&gt; 0a:00:27:00:00:04
Check password for &#39;john&#39; is &#39;password&#39;
Found password for &#39;john&#39;: &#39;password&#39;
ARP: timeout 192.168.77.1</code></pre>
<p>We have been running successfuly our first home-made unikernel on an hypervisor!</p>
<h1 id="conclusion">Conclusion</h1>
<h2 id="takeaways">Takeaways</h2>
<ul>
<li>MirageOS is quite well-packaged and thought out and mostly works out-of-the-box as advertised. The documentation is detailed and takes the newbie by the hand through the various steps one needs to build all the examples. All in all the “developer experience” is better than with <a href="https://github.com/GaloisInc/HaLVM">HaLVM</a>,</li>
<li>I was mostly frustrated by my lack of knowledge and understanding of Xen platform and virtual networking and I am indebted to people from the <a href="http://lists.xenproject.org/cgi-bin/mailman/listinfo/mirageos-devel">MirageOS mailing list</a> and <a href="http://freenode.net/">IRC Channel #mirage</a> for their help,</li>
<li>I was also limited by my lack of knowledge of OCaml, but working with MirageOS is a good incentive to learn the language which seems interesting and somehow <em>feels</em> different from Haskell while sharing a lot of concepts.. Finding documentation on OCaml is pretty straightforward and idioms are close enough to Haskell I was not too far off most of the time…</li>
</ul>
<h2 id="next-steps">Next steps</h2>
<p>I really think the unikernel paradigm could be as important a shift as containers and dockers have been in the last couple of years and as such I really want to keep investigating what MirageOS and HaLVM have to offer. To the best of my understanding there seems to be two different approaches to unikernels:</p>
<ul>
<li>A <em>bottom-up</em>, <em>language-agnostic</em> and <em>system-based</em> approach which produces unikernels for any or most kind of unix binaries by stripping down a stock OS and packing it along with adapted libs with the target process. This approach is merely an extension of the existing containers paradigm and is exemplified by <a href="http://rumpkernel.org/">Rump kernels</a> and <a href="http://osv.io/">OSv</a>,</li>
<li>A <em>top-down</em> and <em>language-centric</em> approach exemplified by Mirage and HaLVM where system-level components are actually written in the language thus providing all the benefits of tight integration and focus, and packed with a custom minimalistic OS.</li>
</ul>
<p>Obviously, the former approach definitely requires less effort and allows one to produce unikernels in a very short time span by simply repackaging existing applications and services. The latter approach is more demanding as it requires expertise in a specific language and building all the needed components, sometimes from scratch, to provide low-level services otherwise provided by standard system libraries. I don’t have much rational arguments, beyond those provided in Mirage’s own documentation, to back my personal preference for the latter: I might be biased by my interest in functional programming languages, especially strongly typed ones, and the somewhat childish desire to master every single part of the system stack.</p>
<p>What I want to do know is:</p>
<ul>
<li>Write a truly useful service that could be unikernelised in OCaml: To build on some previous experiments in the domain of distributed consensus, I think having a unikernel-based Raft implementation could be a challenging and interesting next step. Another potentially interesting use case would be to build unikernels for serverless tasks dispatched with something like <a href="http://aws.amazon.com/fr/documentation/lambda/">AWS Lambda</a> but this is not possible,</li>
<li>Experiment more with <a href="https://github.com/djwillia/solo5">solo5</a>, a companion project of Mirage whose goal is to allow running Mirage unikernels on top of non-Xen hypervisors, like qemu and VirtualBox,</li>
<li>Experiment with deployment of unikernels on cloud providers. There is some documentation and script already available to <a href="https://mirage.io/wiki/xen-boot">deploy to AWS</a> which I would like to try.</li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>On &quot;Cakes, Custard + Category Theory&quot;</title>
    <link href="http://abailly.github.io/posts/cake-custard-category.html" />
    <id>http://abailly.github.io/posts/cake-custard-category.html</id>
    <published>2016-04-18T00:00:00Z</published>
    <updated>2016-04-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>On &quot;Cakes, Custard + Category Theory&quot;</h1>
<div class="info">Posted on April 18, 2016</div>

<p>I am not a mathematician, and this is probably the only regret of my life. When I was young I was too lazy to work seriously enough in High School to be accepted at one of the “Grandes Écoles”. Or rather I was way too much interested by role-playing games to spend time doing homework. And I must say maths were quite boring in High School and Preparatory School, not even talking about Business school’s math which barely went beyond basic arithmetics…</p>
<p>Things would probably have been quite different had I been taught math by <a href="http://www.eugeniacheng.com/">Eugenia Cheng</a>, the author of <a href="http://www.amazon.co.uk/Cakes-Custard-Category-Theory-understanding/dp/1781252874/ref=sr_1_1?ie=UTF8&amp;qid=1422244697&amp;sr=8-1&amp;keywords=eugenia+cheng">Cakes, Custard + Category Theory</a> and one of the presenter of the famous <a href="https://www.youtube.com/watch?v=9fohXBj2UEI&amp;list=PL0E91279846EC843E">Catsters</a> series, among <a href="http://liederstube.wix.com/home">other talents</a>.</p>
<p>I have read, or more precisely tried to read, <a href="https://www.cambridge.org/catalogue/catalogue.asp?isbn=9780521719162">many</a> <a href="http://www.maths.ed.ac.uk/~aar/papers/maclanecat.pdf">books</a> <a href="http://www.math.mcgill.ca/triples/Barr-Wells-ctcs.pdf">about</a> <a href="http://www.mpi-sws.org/~dreyer/courses/catlogic/awodey.pdf">category</a> <a href="http://ebooks.library.cornell.edu/cgi/t/text/text-idx?c=math;cc=math;view=toc;subview=short;idno=Gold010">theory</a> but I know I still only have an intuition about very basic things, e.g. what is a category theory, composition of morphisms, units, simple limits… The more abstract - and important - concepts (adjunctions, Yoneda lemma, topoi, sheaves…) are still inaccessible to my understanding: To state it in Eugenia’s terms, I <em>know</em> them but I don’t <em>understand</em> them.</p>
<p><em>Cakes, Custard + Category Theory</em> is a math books for non-mathematicians, a book that tries and - to my humble opinion - somehow succeeds in giving lay people some ideas on why maths are important, interesting and fascinating. More importantly it also succeeds in giving <em>intuitions</em> on what <em>is</em> math and category theory and on connecting the dull, formal and painful external aspect of maths most people see with the deep, complex, beautiful and sophisticated ideas behind that rude shell.</p>
<p>The book is divided in two parts, <em>Mathematics</em> and <em>Category Theory</em> which shares a common underlying structure: Each small chapter is introduced by the <em>recipe</em> of some cake, some classical and some invented by the author, and each part ends with a tentative explanation of <em>what</em> is math or category theory. Through the various chapters, Eugenia threads mundane life examples, recipes, cooking metaphors with actual mathematical questions in order to convey to the reader intuitions on what things like monoids, groups, morphisms, associativity or equivalence are. Mathematical notations is mostly restricted to sidebars and does not clutter reading.</p>
<p>I am not usually a great fan of analogies which more often than not obscure rather than illuminate the thing they are supposed to explain. But this book is written in a such a way that it mostly avoids this pitfall<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>:</p>
<ul>
<li>Eugenia’s style is so lively and entertaining one cannot but avidly read the book and reach for the next chapter till the end,</li>
<li>She manages to <em>motivate</em> mathematics, not as a mere tool one uses to solve more or less complex problems, but as a way to ask profound questions about the way we think and the world we live in.</li>
</ul>
<p>The key question in maths and category theory is then not <em>how</em> but <em>why</em>.</p>
<blockquote>
<p>Proof has a sociological role ; illumination has a personal role. Proof is what convinces society ; illumination is what convinces us. In a way, mathematics is like an emotion, which can’t ever be described precisely in words - it’s something that happens inside an individual. What we write down is merely a language for communicating those ideas to others, in the hope they will be able to reconstruct the feeling in their own mind.</p>
</blockquote>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Although I myself enjoy cooking very much, I was not that much convinced about the whole recipe meme…<a href="#fnref1">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>A Personal Retrospective</title>
    <link href="http://abailly.github.io/posts/personal-retrospective.html" />
    <id>http://abailly.github.io/posts/personal-retrospective.html</id>
    <published>2016-04-12T00:00:00Z</published>
    <updated>2016-04-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>A Personal Retrospective</h1>
<div class="info">Posted on April 12, 2016</div>

<p>From August 2014 to April 2016 I have been working as CTO of a startup based in Singapore, developing a peer-to-peer lending platform using Haskell programming language and environment. This experience has now come to an end and this short blog post is a way for me to look back at those 20 months and reflect on the things I have learnt. I have some vague hopes this experience might be useful to others. But the main goal is for me to make explicit things that have stayed mostly implicit in order to ensure I can benefit from my own experience.</p>
<h1 id="haskell-rocks">Haskell Rocks</h1>
<p>Nothing new under the sun but working 120% of the time in Haskell over (nearly) the whole stack of our system really reinforced that belief. The point is, Haskell is not only awesome because of its own merits as a language and a platform. After all, Haskell is a language that is <a href="https://en.wikipedia.org/wiki/Haskell_%28programming_language%29#History">about 30 years old</a> and since its inception has mostly been confined in academic circles. This is apparent in some weaknesses in the build system, standard data types like Strings and numbers, lack of support for first-class modules…</p>
<p>Those deficiencies are compensated by a simple<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> yet powerful type-system, a vibrant eco-system of good to great libraries providing all the features one needs, a state-of-the-art compiler producing efficient programs, built-in support for powerful concurrency features… I think Gabriel Gonzalez’ <a href="http://www.haskellforall.com/2016/04/worst-practices-should-be-hard.html">Worst practices should be hard</a> offers some more solid arguments in favour of Haskell.</p>
<p>What sets Haskell apart is the fact that chosing to make it your core technology attracts interesting people. This is one of the effect mentionned by Paul Graham of using non-<a href="http://www.paulgraham.com/avg.html">Blub</a> languages: Not using a mainstream language attracts non-mainstream people. <a href="http://bos.github.io/strange-loop-2011/talk/talk.html">Bryan O’Sullivan</a> of<a href="http://book.realworldhaskell.org/">Real World Haskell</a> book fame also highlighted this point: In a world flooded by noise, Haskell acts as a signal.</p>
<p>This does not mean that there aren’t great people working in Java, Javascript or Php<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. And this does not mean I would like to work with any Haskeller just because she is a Haskeller. But from my experience hiring people, I found Haskell acted like an effective filter<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>: People who cared to answer job ads or reach out the company to enquire for job openings were more often than not <em>interesting</em>. They were more diverse<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> (different countries, different ages, different professional experiences…), more curious, more motivated and for those whom I had a chance to pair with, quite good at programming.</p>
<h1 id="tdd-rocks">TDD Rocks</h1>
<p>I have always been a strong proponent of <a href="/posts/tdd.html">Test Driven Development</a>. After all these years this practice is <a href="http://david.heinemeierhansson.com/2014/tdd-is-dead-long-live-testing.html">still</a> <a href="http://iansommerville.com/systems-software-and-technology/giving-up-on-test-first-development/">controversial</a> mostly because people conflate two different things: “writing regression tests” and “using tests to guide your design”, a confusion which is caused by the use of <em>Test</em> in Test-Driven Development. In a nutshell, one needs a very different mindset to jump from “I write tests to verify my program does what I intend it to do, now and in the future” to “I write executable specifications in order to ensure 1/ I understand the problem and 2/ my program does exactly what’s intended, no more, no less”.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> The former mindset usually leads to so-called white-box tests which are thorough but brittle and painful to maintain.</p>
<p>Even within the Haskell community TDD is not widely accepted as a standard practice of development. I personally think Haskell is a really great fit for TDD if you take it in a broad sense, that is if you include all the tools the language and platform provide as part of your TDD cycle. This means leveraging the interpreter, compiler, type-checker and test runner to shorten the feedback loop.</p>
<p>Maintaining tests require (a lot of) effort and discipline, and it is tempting when pressed to deliver to cut corners. And I sometimes have done it myself: Comment out an flaky test in order to stabilize build. But except in one occasion, I have always come back to it later and reinstate it. These efforts really pay off in the long run, when you start adding features upon features, when the complexity of the system becomes too important to “fit in your head”, when you need to modify existing features or extend them to cope with new behaviours. TDD gives you both a safety net - so that it breaks when you change your code and highlights other parts of the system that need to be adapted - and a guide on current behaviour of the code.</p>
<h1 id="remote-development-works">Remote Development Works</h1>
<p>Although the company’s business is exclusively located in Singapore I never lived there and we started working remotely, me in France and my partner in Singapore. The development team has been distributed for almost all of the past 20 months, with people in England, Portugal, India, Poland and Malaysia (not all at the same time). And we managed to develop a platform that handles a modest load but has been working reliably managing financial and personal data since March 2015, steadily adding features, fixing bugs, deploying new versions several times a week or even a day, building and maintaining build and production infrastructure…</p>
<p>We used some simple form of agile methodology with daily “standup” meetings that allowed us to talk to each other at least once a day, strict automated tests, continuous integration and frequent releases. This made it possible to have rapid feedback from business people even if I was not sitting in the same room most of the time. We exposed our work process through Trello, used communication tools like Slack, Hangout, Skype, and tried a few others, and we managed to build a consensus across the whole development team on what was going on and what we had to do. We even manage to <a href="https://pragprog.com/book/jkrp/remote-pairing">pair program</a> on a somewhat regular basis.</p>
<p>As already advocated in <a href="https://37signals.com/remote">Remote</a> book, working remotely works under some conditions:</p>
<ul>
<li><em>Distribute whole team</em>: Having most of the team colocated with one or two persons distributed does not work,</li>
<li><em>Trust the people</em>: You have to trust each other and assume everybody is doing his or her best,</li>
<li><em>Communicate constantly</em>: You have to be very explicit about what you are doing, even if working alone, and you have to constantly try to detect and solve potential conflicts, misinterpretations, misunderstandings that could quickly degenerate,</li>
<li><em>Use the right tools</em>: Emails are a useful tool but one which is often abused<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>, we need “hotter” media like chat, video/phone…</li>
</ul>
<p><a href="https://open.buffer.com/">Buffer</a> is a good example of a company that has chosen to be fully distributed and is very transparent on how it works on a daily basis.</p>
<h1 id="but-it-needs-energy">… But it needs energy</h1>
<p>While keeping in touch with development team was always easy, doing same on the business side quickly became very hard. This is of course related to the very localized nature of the business the company was doing, but also to different background and maturity with respect to remote working. Remote working is definitely a viable option for software development as the success of a lot of world-spanning open-source projects has demonstrated.</p>
<p>As I advocated above, working effectively as a remote team needs some requirements to be met. But even if those requirements are met, it still can fail if people are not trained and do not make the mental leap to make it work. It might be possible that developers, having to deal constantly with abstractions, networks, virtualities, are more prone to make that leap. Once you consider it normal to work on machines located in a data center 10000 kms away, it is a small feat to consider normal to work with another developer located 10000 kms away. The network becomes an extension to standard Earth geography and there is a form of excitement in the way modern technology allows us to break distance barriers<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>.</p>
<p>Unfortunately, this particular mindset is not widespread among people practicing other trades. “Business people” who don’t need to interact constantly with developers quickly lose grasp and stop putting energy in maintaining a communication link that’s not obvious to them. The whole zoo of tools we are using appears daunting when compared with the simplicity of Outlook and Excel. When one has a lot more face-to-face interactions than online ones, she or he is quite prone to drop the latter in favour of the former. Note that working as a distributed team is <em>not</em> to be equated with working <em>remotely</em>. Obviously, organizations have been distributed for a long time: Businesses are used to employ people like salespersons who largely work remotely or to have various business units all over the planet. But this is different from the kind of real-time cooperation and interactions one needs when developing software and working as a distributed team.</p>
<h1 id="takeaways">Takeaways</h1>
<p>You can’t summarize 20 months of your life in a couple of bullet points and I definitely think this experience was amazing and has changed my life and the way I envision my work in a very deep way:</p>
<ul>
<li>Working as team remotely can be both satisfying and efficient when done properly,</li>
<li>Working with people from diverse origins and nationalities in a foreign setting is exciting<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>, and travelling to work with those people occasionally is the best way to discover local culture,</li>
<li>Haskell is <em>really</em> practical for large-ish systems development.</li>
</ul>
<p><strong>Afterwords</strong>: Many thanks to Cédric and Éric for their feedback on this small piece.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Yes, simple when compared with something like Scala’s or C++ type system. Haskell’s type system only uses a few key concepts that can be rather easily understood and explained and which allow you to build powerful abstractions on top of it without resorting to syntax-directed tricks (e.g. macros).<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>I personally know quite a few of them…<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Of course, there is still the possibility this was just another way of selecting like minded people thus implicitly rejecting genuine <em>diversity</em><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>With the notable exception of gender diversity: Over the 50+ person I interviewed I have had a single woman.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>For a good rebutal of the previous arguments, see <a href="http://blog.cleancoder.com/uncle-bob/2016/03/19/GivingUpOnTDD.html">Uncle Bob</a>’s reply to the “Giving up on TDD” post.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Emails are terrible for discussions - exchanging and/or arguing over some more or less complex point - or task tracking - maintaining and updating status of some work in progress - yet they are unfortunately often used that way.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>As people dealing with technology we might also be keener to fall to its trap and seductive power.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Having to make yourself understood in a language (English) which is not the mother tongue of any of the people you work with is sometimes frustrating, but always interesting. In can provide some natural dampening of feelings and emotions that cannot fail to crop up in any collective endeavour.<a href="#fnref8">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>

</feed>
