<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Arnaud Bailly's  Blog</title>
    <link href="http://abailly.github.io/atom.xml" rel="self" />
    <link href="http://abailly.github.io" />
    <id>http://abailly.github.io/atom.xml</id>
    <author>
        <name>Arnaud Bailly</name>
        <email>arnaud@igitur.io</email>
    </author>
    <updated>2022-01-31T00:00:00Z</updated>
    <entry>
    <title>Mutation-Based TDD</title>
    <link href="http://abailly.github.io/posts/mutation-testing.html" />
    <id>http://abailly.github.io/posts/mutation-testing.html</id>
    <published>2022-01-31T00:00:00Z</published>
    <updated>2022-01-31T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Mutation-Based TDD</h1>

  <h2 class="subtitle">Developing Plutus contracts with QuickCheck</h2>

<div class="info">Posted on January 31, 2022</div>

<h1 id="smart-contracts-cardano">Smart Contracts &amp; Cardano</h1>
<p>I discovered the concept of <em>Smart Contracts</em> in 2016 in Singapore when I met the nice folks at <a href="https://legalese.com/">Legalese</a>, Meng Wong and Alexis Chun. This is what attracted me to blockchain much more than the cryptocurrency and speculation space: The fascinating idea of designing software that would run in a fully decentralised and distributed manner, representing evolving contractual obligations and rights over time, and reacting to consensual events added to the chain.</p>
<p>Since then I have worked on a private blockchain based platform at <a href="https://www.symbiont.io/">Symbiont</a>, designing and building a <a href="https://www.symbiont.io/mortgages">mortgage servicing system</a> using Symbiont’s <a href="https://www.symbiont.io/post/safety-and-ease-of-use-in-sympl-a-dsl-for-enterprise-smart-contracts">SymPL</a> ; and recently joined <a href="https://iohk.io/">IOG</a> which is the company developing the core technology of the <a href="https://cardano.org/">Cardano</a> blockchain and cryptocurrency.</p>
<p>In 2021 <a href="https://plutus.readthedocs.io/en/latest/">Plutus</a>, Cardano’s native smart contract language, was made available on mainchain. Plutus is basically a lambda-calculus, and thus a Turing-complete language, with which developers write <em>scripts</em> that can lock <a href="https://files.zotero.net/eyJleHBpcmVzIjoxNjQzNDY2MzE0LCJoYXNoIjoiYTVhYmY4NjdiY2E2YzdkNTNjODkwNWNmZDZhYmM5MjAiLCJjb250ZW50VHlwZSI6ImFwcGxpY2F0aW9uXC9wZGYiLCJjaGFyc2V0IjoiIiwiZmlsZW5hbWUiOiJDaGFrcmF2YXJ0eSBldCBhbC4gLSAyMDIwIC0gVGhlIEV4dGVuZGVkIFVUWE8gTW9kZWwucGRmIn0%3D/156852d95f236fc19bf9615579d71dd7857ba06556a4b867adef6bfe7e5c4e1a/Chakravarty%20et%20al.%20-%202020%20-%20The%20Extended%20UTXO%20Model.pdf">eUTxO</a>. The scripts are evaluated when a transaction <em>consumes</em> such a eUTxO and the transaction is considered valid iff each validator evaluates to <em>True</em> in the context of the given transaction.</p>
<p>Of course, the correctness of the validators’ code aka. <em>Smart Contracts</em> is of the utmost importance as they can control large amount of funds and coordinate complex processes involving a large number of parties. The Smart contracts space is infamous for quite a few exploits, some of them <a href="https://en.wikipedia.org/wiki/The_DAO_(organization)">famous</a> and having resulted in significant losses, hence the ability to test, verify, validate, audit Plutus code is critical. While we wait for proper formal verification tools to mature, we have to resort to standard practices like auomated testing and manual auditing, hence as <em>Smart Contracts Developers</em> we need to be extra-careful with this part of the code and put ourself in the shoes of potential “Attackers” that could try to harm users in various ways: Steal currencies, Denial-of-Service, lock funds…</p>
<h1 id="hydra-smart-contracts">Hydra Smart Contracts</h1>
<p>With my fellow colleagues working on the <a href="https://github.com/input-output-hk/hydra-poc">Hydra</a> Layer-2 protocol for Cardano, <a href="https://www.linkedin.com/in/matthias-benkort-47186a57">Mathias Benkort</a> and <a href="https://www.linkedin.com/in/sebastian-nagel-2bb43a1a/">Sebastian Nagel</a>, we decided in October 2021 to move away from PAB and Plutus Application Framework in the development of the Hydra on-chain validators and experiment with so-called <em>Direct Chain</em> interaction: Use the standard cardano-api protocols and data structures to interact with the blockchain, posting transactions and following the chain as new blocks get created and new transactions added.</p>
<p>After having spent some time setting up the needed infrastructure to build, post and observe Hydra-relevant transactions to and from a cardano-node, we went back to revisit our earlier work on Contracts and implement the full “Happy path” Hydra lifecycle, from initialising a Head to <em>Fan-out</em> and redistribution of UTxO created within the Head.</p>
<h2 id="test-driving-hydras-validators">Test-Driving Hydra’s Validators</h2>
<p>Being Test-Driven Development addicts the first question raised was then: How do you test-drive Plutus smart contracts? There’s a growing set of tools developers have at their disposal to test and test-drive Plutus contracts:</p>
<ol style="list-style-type: decimal">
<li>The “official” <a href="https://plutus-apps.readthedocs.io/en/latest/plutus/tutorials/contract-testing.html">Model-based testing</a> framework which is part of the plutus-apps repository
<ul>
<li>Scope is complete Plutus apps, which are tested at the level of the <code>Contract</code> monad, eg. including both on-chain and off-chain code,</li>
<li>Tests are generated based on a <em>state machine model</em> of the system,</li>
<li>It uses QuickCheck and <a href="https://github.com/input-output-hk/plutus-apps/tree/main/quickcheck-dynamic">quickcheck-dynamic</a> framework to explore state machine, generate traces and check correctness of implementation,</li>
<li>Tests are run within an <code>Emulator</code> that’s supposed to reproduce the behaviour of the blockchain.</li>
</ul></li>
<li><a href="https://github.com/tweag/plutus-libs/">plutus-libs</a> is another model-based testing approach also based on QuickCheck from <a href="https://www.tweag.io/blog/2022-01-26-property-based-testing-of-monadic-code/">Tweag</a>, called <code>cooked-validators</code>:
<ul>
<li>It provides own <code>MonadBlockChain</code> abstraction to represent off-chain interaction with the blockchain, which ultimately is based on Plutus’ representation of the ledger’s types,</li>
<li>Tests are written as properties over trace expressions written in a <code>GenT</code> monad allowing interleaving generators and chain interactions like posting transactions,</li>
<li><em>modalities</em> <code>somewhere</code> and <code>everywhere</code> provide a way to modify generated traces to produce more traces representing some arbitrary change over the set of traces. This is a powerful concept akin to <em>Temporal logic</em> modal operators, see <a href="https://github.com/tweag/plutus-libs/blob/main/examples/tests/PMultiSigStatefulSpec.hs#L272">this example</a> for a use of <code>somewhere</code>,</li>
</ul></li>
<li><a href="https://github.com/Liqwid-Labs/plutus-extra/tree/master/tasty-plutus">tasty-plutus</a> provides a unit and property testing framework integrated with <a href="https://hackage.haskell.org/package/tasty">Tasty</a>
<ul>
<li>It’s based on a DSL to build a <code>ScriptContext</code> that can then be used to run the validators directly,</li>
<li>Uses Plutus’ <code>Scripts.runScript</code> function to run the script,</li>
<li>The scripts are run in compiled form and passed to the CEK interpreter,</li>
</ul></li>
</ol>
<h2 id="mutation-based-property-driven-development">Mutation-based Property Driven Development</h2>
<p>We decided to explore another avenue, which we have called <em>Mutation-based Property Driven Development</em> and which is as one can guess, a combination of <em>Property-based Testing</em> with QuickCheck, <em>Test-Driven Development</em>, and <em>Mutation testing</em>. Traditional <a href="https://en.wikipedia.org/wiki/Mutation_testing">Mutation testing</a> is a testing technique that introduces small modifications like changing a comparison operator, or modifying constants, into a program and checks whether or not the existing tests “kill” the produced mutants, eg. fail. Mutation testing requires somewhat complex tooling because it needs to modify the source code, in limited and semantically meaningful ways in order to generate code that won’t be rejected by the compiler. A quick search lead me to <a href="https://hackage.haskell.org/package/MuCheck">MuCheck</a> which seems to be the only available tool in Haskell-land and is quite old already, and beside we did not want to rely on esoteric tooling.</p>
<p>Plutus eUTxO validators are boolean expressions of the form:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">validator <span class="fu">:</span> <span class="dt">Datum</span> <span class="ot">-&gt;</span> <span class="dt">Redeemer</span> <span class="ot">-&gt;</span> <span class="dt">ScriptContext</span> <span class="ot">-&gt;</span> <span class="dt">Bool</span></code></pre></div>
<p>All things being equal, “mutating” a <em>validator</em> so that it returns <code>False</code> instead of <code>True</code> can be done:</p>
<ul>
<li>Either by <em>mutating</em> the code of the <code>validator</code> implementation,</li>
<li>Or by <em>mutating</em> its arguments.</li>
</ul>
<p>This simple idea lead us to the following strategy to test-drive each of our validator scripts, <code>Head</code>, <code>Commit</code> and <code>Initial</code>:</p>
<ol style="list-style-type: decimal">
<li>Start with a validator that always return <code>True</code>,</li>
<li>Write a <em>positive</em> property test checking <em>valid</em> transactions are accepted by the validator(s),</li>
<li>Write a <em>negative</em> property test checking <em>invalid</em> transactions are rejected. This is where <em>mutations</em> are introduced, each different mutation type representing some possible “attack”,</li>
<li>Watch one or the other properties fail and enhance the validators code to make them pass,</li>
<li>Rinse and repeat.</li>
</ol>
<p>As this is really the most “novel” part here are some details about the <em>Mutations</em> and the <em>Adversarial</em> property we check.</p>
<h2 id="generic-property-and-mutations">Generic Property and Mutations</h2>
<p>The definition of the property is simple and completely generic way: Given a transaction with some UTxO context, and a function that generates <code>SomeMutation</code> from a valid transaction and context pair, this property checks applying any generated mutation makes the mutated (hence expectedly invalid) transaction fail the validation stage.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">propMutation ::</span> (<span class="dt">CardanoTx</span>, <span class="dt">Utxo</span>) <span class="ot">-&gt;</span> ((<span class="dt">CardanoTx</span>, <span class="dt">Utxo</span>) <span class="ot">-&gt;</span> <span class="dt">Gen</span> <span class="dt">SomeMutation</span>) <span class="ot">-&gt;</span> <span class="dt">Property</span>
propMutation (tx, utxo) genMutation <span class="fu">=</span>
  forAll <span class="fu">@</span>_ <span class="fu">@</span><span class="dt">Property</span> (genMutation (tx, utxo)) <span class="fu">$</span> \<span class="dt">SomeMutation</span>{label, mutation} <span class="ot">-&gt;</span>
    (tx, utxo)
      <span class="fu">&amp;</span> applyMutation mutation
      <span class="fu">&amp;</span> propTransactionDoesNotValidate
      <span class="fu">&amp;</span> genericCoverTable [label]
      <span class="fu">&amp;</span> checkCoverage</code></pre></div>
<p>To this basic property definition we add a <code>checkCoverage</code> that ensures the set of generated mutations covers a statistically significant share of each of the various possible mutations classified by their <code>label</code>.</p>
<p>The <code>SomeMutation</code> type is simply a wrapper that attaches a <code>label</code> to a proper <code>Mutation</code> which is the interesting bit here.</p>
<p>The <code>Mutation</code> type enumerates various possible “atomic” mutations which preserve the structural correctness of the transaction but should make a validator fail.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Mutation</span>
  <span class="fu">=</span> <span class="dt">ChangeHeadRedeemer</span> <span class="dt">Head.Input</span>
  <span class="fu">|</span> <span class="dt">ChangeHeadDatum</span> <span class="dt">Head.State</span>
  <span class="fu">|</span> <span class="dt">PrependOutput</span> (<span class="dt">TxOut</span> <span class="dt">CtxTx</span> <span class="dt">Era</span>)
  <span class="fu">|</span> <span class="dt">RemoveOutput</span> <span class="dt">Word</span>
  <span class="fu">|</span> <span class="dt">ChangeInput</span> <span class="dt">TxIn</span> (<span class="dt">TxOut</span> <span class="dt">CtxUTxO</span> <span class="dt">Era</span>)
  <span class="fu">|</span> <span class="dt">ChangeOutput</span> <span class="dt">Word</span> (<span class="dt">TxOut</span> <span class="dt">CtxTx</span> <span class="dt">Era</span>)
  <span class="fu">|</span> <span class="dt">Changes</span> [<span class="dt">Mutation</span>]</code></pre></div>
<p>The constructors should hopefully be self-explaining but for the last one. Some interesting mutations we want to make require more than one “atomic” change to represent a possible validator failure. For example, we wanted to check that the <code>Commit</code> validator, in the context of a <code>CollectCom</code> transaction, verifies the state (<code>Head.Input</code>) of the <code>Head</code> validator is correct. But to be interesting, this mutation needs to ensure the <em>transition</em> verified by the <code>Head</code> state machine is valid, which requires changing <em>both</em> the datum and the redeemer of the consumed head output.</p>
<h2 id="transaction-specific-mutations">Transaction-specific Mutations</h2>
<p>To be run the <code>propMutation</code> requires a starting “healthy” (valid) transaction and a specialised generating function. It is instantiated in the test runner by providing these two elements:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">describe <span class="st">&quot;CollectCom&quot;</span> <span class="fu">$</span> <span class="kw">do</span>
  prop <span class="st">&quot;does not survive random adversarial mutations&quot;</span> <span class="fu">$</span>
    propMutation healthyCollectComTx genCollectComMutation</code></pre></div>
<p>The interesting part is the <code>genCollectComMutation</code> (details of the <code>Mutation</code> generators are omitted):</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">genCollectComMutation ::</span> (<span class="dt">CardanoTx</span>, <span class="dt">Utxo</span>) <span class="ot">-&gt;</span> <span class="dt">Gen</span> <span class="dt">SomeMutation</span>
genCollectComMutation (tx, utxo) <span class="fu">=</span>
  oneof
    [ <span class="dt">SomeMutation</span> <span class="dt">MutateOpenOutputValue</span> <span class="fu">.</span> <span class="dt">ChangeOutput</span> <span class="fu">...</span>
    , <span class="dt">SomeMutation</span> <span class="dt">MutateOpenUtxoHash</span> <span class="fu">.</span> <span class="dt">ChangeOutput</span> <span class="fu">...</span>
    , <span class="dt">SomeMutation</span> <span class="dt">MutateHeadScriptInput</span> <span class="fu">.</span> <span class="dt">ChangeInput</span> <span class="fu">...</span>
    , <span class="dt">SomeMutation</span> <span class="dt">MutateHeadTransition</span> <span class="fu">&lt;$&gt;</span> <span class="kw">do</span>
        changeRedeemer <span class="ot">&lt;-</span> <span class="dt">ChangeHeadRedeemer</span> <span class="fu">&lt;$&gt;</span> <span class="fu">...</span>
        changeDatum <span class="ot">&lt;-</span> <span class="dt">ChangeHeadDatum</span> <span class="fu">&lt;$&gt;</span> <span class="fu">...</span>
        pure <span class="fu">$</span> <span class="dt">Changes</span> [changeRedeemer, changeDatum]
    ]</code></pre></div>
<p>Here we have defined four different type of mutations that are interesting for the <code>CollectCom</code> transaction and represent possible “attack vectors”:</p>
<ul>
<li>Changing the <code>Head</code> output’s value, which would imply some of the committed funds could be “stolen” by the party posting the transaction,</li>
<li>Tampering with the content of the UTxO committed to the Head,</li>
<li>Trying to collect commits without running the <code>Head</code> validator,</li>
<li>Trying to collect commits in another Head state machine transition.</li>
</ul>
<h2 id="running-properties">Running Properties</h2>
<p>When such a property test succeeds we get the following report which shows the distribution of the various mutations that were tested.</p>
<pre><code>Hydra.Chain.Direct.Contract
  CollectCom
    does not survive random adversarial mutations
      +++ OK, passed 200 tests.

      CollectComMutation (200 in total):
      30.5% MutateOpenUtxoHash
      27.0% MutateHeadTransition
      23.5% MutateOpenOutputValue
      19.0% MutateHeadScriptInput

Finished in 18.1146 seconds</code></pre>
<p>In the case of a failure we get a detailed report on the context of the failure:</p>
<pre><code> test/Hydra/Chain/Direct/ContractSpec.hs:96:5:
  2) Hydra.Chain.Direct.Contract.CollectCom does not survive random adversarial mutations
       Falsified (after 5 tests):</code></pre>
<p>With details about the <code>Mutation</code> that was attempted:</p>
<pre><code>         SomeMutation {label = MutateHeadTransition, mutation = Changes [ChangeHeadRedeemer (Close {snapshotNumber = 0, utxoHash = &quot;\EOT\ETX\STX&quot;, signature = [000003]}),ChangeHeadDatum (Open {parties = [1], utxoHash = &quot;\SOH\SOH\ETX\EOT\SOH\STX\NUL\STX\NUL\ETX\EOT\NUL\ETX\STX\ETX\SOH\SOH\NUL\ETX\EOT\ETX\ETX\ETX\SOH\EOT\EOT\ETX\SOH\STX\NUL\EOT\EOT&quot;})]}</code></pre>
<p>The failure itself:</p>
<pre><code>         Phase-2 validation should have failed
         Redeemer report: fromList [(RdmrPtr Spend 0,Right (WrapExUnits {unWrapExUnits = ExUnits&#39; {exUnitsMem&#39; = 831248, exUnitsSteps&#39; = 362274551}})),(RdmrPtr Spend 1,Right (WrapExUnits {unWrapExUnits = ExUnits&#39; {exUnitsMem&#39; = 1030658, exUnitsSteps&#39; = 424175713}})),(RdmrPtr Spend 2,Right (WrapExUnits {unWrapExUnits = ExUnits&#39; {exUnitsMem&#39; = 1030658, exUnitsSteps&#39; = 424175713}})),(RdmrPtr Spend 3,Right (WrapExUnits {unWrapExUnits = ExUnits&#39; {exUnitsMem&#39; = 1030658, exUnitsSteps&#39; = 424175713}}))]</code></pre>
<p>The UTxO that we used (possibly mutated):</p>
<pre><code>     Lookup utxo: {
             &quot;31237cdb79ae1dfa7ffb87cde7ea8a80352d300ee5ac758a6cddd19d671925ec#455&quot;: {
                 &quot;address&quot;: &quot;addr_test1wpjstex8ajlkn8sp5lr8dsfkn9v2m2pfudmn9kzy6epyegqk5664m&quot;,
                 &quot;datumhash&quot;: &quot;1f4e83d60d16d6bc976fa8d1d1a7a43f2fef540e643cc3c2cb5cd2d0d5052f06&quot;,
...</code></pre>
<p>And most importantly the details of the transaction that failed, including all the relevant pieces of data (inputs, outputs, scripts, datums, redeemers):</p>
<pre><code>         Tx: &quot;83ad5c518d4adacf84f5f8fb17e0f2d175a76ae88494966360cb2e96a939f260&quot;
           Input set (4)
             - 31237cdb79ae1dfa7ffb87cde7ea8a80352d300ee5ac758a6cddd19d671925ec#455
             - 96b5f154b0afc62c6a91d756ee31dfc219d76c08ebd30341c198e7b22533745e#179
             - d9c38f56d9147ba5ce4a0b52456ef4594c46992b74051e462ab8275845345e98#996
             - fb3d635c7cb573d1b9e9bff4a64ab4f25190d29b6fd8db94c605a218a23fa9ad#140
           Outputs (1)
             total number of assets: 0
             - 34.056295 ₳
           Scripts (2)
             total size (bytes):  12917
             - ScriptHash &quot;6505e4c7ecbf699e01a7c676c1369958ada829e37732d844d6424ca0&quot;
             - ScriptHash &quot;97b5cb76fd4dcccdfcff850abbe7bdc95d69f70b7eeb1a1c33135ebd&quot;
           Datums (6)
           ...
             - SafeHash &quot;59e610cce1fb1636a27bdc6e65c2bf373c829f6c726140dcedbffc5fc950af1c&quot; -&gt; DataConstr Constr 0 [Constr 0 [I (-13)],List [I 18446744073709551597,I 4,I 21]]
           Redeemers (4)
           ...
             - DataConstr Constr 0 []
             - DataConstr Constr 0 []
             - DataConstr Constr 0 []</code></pre>
<p>Note that this report could be made more friendly by trying to decode some of the <code>datums</code> and <code>redeemers</code> as we usually know what their actual type in code is, and making the association between redeemers and inputs more immediate. But even in this somewhat crude form it provides a wealth of information that makes it straightforward to manifest the shortcomings in the validators.</p>
<h1 id="conclusion">Conclusion</h1>
<p>We have applied this strategy to drive the development of the so-called “Happy Path” of the Hydra Head On-Chain Validation state machine, writing code for three different validators and five different transaction types. The early steps were a bit painful as applying mutations requires fiddling with the internals of a transaction in potentially complicated ways. It took us some time to define a good-enough set of “atomic” <code>Mutation</code>s and some good generators and helper functions, but we already had most of the API covered thanks to previous work on implementing <em>Direct</em> chain interaction, but as with any framework-like effort, we were able to observe increasing returns over time: Defining new mutations for new types of transactions has become easier.</p>
<p>Writing Plutus validators lends itself pretty well to this technique: * The “universe of discourse” is relatively complicated (Cardano transactions are large data structures with lot of moving parts) and can fail in subtle and/or surprising ways, especially because of indirect interactions between contracts, * It is somewhat self-contained and the validators’ code is in the end just a <em>predicate</em> over some more or less complex data types, * It benefits from adopting an “Adversarial” mindset, trying to find interesting changes that should not be disallowed.</p>
<p>More generally, test-driving code using both mutations and properties seems to improve the quality of the “triangulation process” which TDD rests upon: QuickCheck generated counterexamples pinpoint exactly what’s missing in the code, which can be fixed straightforwardly even using “fakes”, but next run will find more counterexamples until enough coverage is reached.</p>
<p>I think this approach, while particularly well-suited to Plutus validators, has broader applicability on every development platform where there’s support for Property-Based Testing.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Debord / Baudrillard</title>
    <link href="http://abailly.github.io/posts/debord-baudrillard.html" />
    <id>http://abailly.github.io/posts/debord-baudrillard.html</id>
    <published>2022-01-29T00:00:00Z</published>
    <updated>2022-01-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Debord / Baudrillard</h1>

  <h2 class="subtitle">Le situationnisme est un humanisme</h2>

<div class="info">Posted on January 29, 2022</div>

<p>La lecture récente de <a href="http://www.editions-galilee.fr/f/index.php?sp=liv&amp;livre_id=2631">Simulacres et simulations</a> de <a href="https://fr.wikipedia.org/wiki/Jean_Baudrillard">Jean Baudrillard</a> m’a laissée un peu perplexe. Si le livre est très bien écrit et s’il est indéniable que Baudrillard a été visionnaire dans sa critique de l’hypertrophie du sens et du discours qui noie le réel, son nihilisme assumé m’ennuie. J’ai eu envie dans ce court texte de confronter ce que j’ai compris de sa pensée à celle d’un autre grand contempteur de la société capitaliste, Guy Debord.</p>
<p>Pour Debord, le <em>spectacle</em> est la subversion du réel par la marchandise, la soumission d’une part de plus en plus croissante des rapports humains à la logique spectaculaire marchande. Cette critique part de l’art, muséifié, momifié, marchandisé, spectacularisé (le premier geste critique de Debord est une manifestation au festival de Cannes) puis passe à la moulinette tous les domaines de la vie : urbanisme, économie, architecture, relations internationales, écologie, éducation. Le situationnisme est une lutte contre le spectacle visant à remettre la vie et les rapports humains <em>immédiats</em> au centre de l’existence, en ce sens ce n’est pas tant une théorie qu’un foyer de pratiques concrètes visant à réinvestir, redonner du sens aux rapports humains.</p>
<p>La <em>construction de situations</em> ne vise pas autre chose qu’à produire <em>collectivement</em> des moments éphémères de haute intensité du réel qui échappent par essence à la logique spectaculaire Le jeu, la <em>dépense somptuaire</em> sans contrepartie, le sexe, l’alcool, le dérèglement de tous les sens, le rejet de toutes les conventions de la vie bourgeoise (travail, famille, patrie) sont les constantes de Debord.</p>
<p>L’auto-dissolution de l’IS et l’exclusion systématique de nombreux membres au cours de sa brève existence est l’illustration de cette stratégie du “<em>refus de parvenir</em>”, du rejet de toute postérité, de toute construction pérenne, de toute institution qui puisse capturer l’existence et la recycler dans du spectacle.</p>
<p>La vie de Debord lui même est une suite de situations culminant avec mai 68 et poursuivies jusqu’à sa mort dans le refus de jamais travailler, d’être en relation marchande avec qui que ce soit, la volonté d’être maître de son existence jusqu’au bout. Comme le dit Debord lui-même dans <em>Commentaires sur la société du spectacle</em> (je paraphrase et cite de mémoire) : “Toute mon existence aura été tournée vers ce seul objectif qui est de nuire à la société spectaculaire marchande.” En conséquence, il a toujours refusé et lutté contre toute forme de “publicité”, toute “vulgarisation” de sa pensée, toute comprimission avec l’univers médiatique, pour finir dans les années 80 par être parmi les intellectuels français les plus cités et les moins visibles.</p>
<p>Ce qui fait l’originalité et le force de Debord et de l’IS c’est qu’ils ont toujours été activement engagés dans la lutte contre cette société qu’ils critiquent avec force, proposant des actions et des formes de vies alternatives concrètes. Il ne s’agit jamais d’une pensée déconnectée de l’existence, d’une pensée qui ne serait que critique, mais il s’agit de lutter activement, par tous les moyens, sous tous les aspects, contre le spectacle.</p>
<p>Baudrillard approfondit la critique situationniste, explicitement citée dans <em>Simulacres &amp; simulations</em>, de la médiation et du spectacle mais il cherche à aller plus loin: là où les situs pensaient le spectacle comme un masque sur le réel destiné à maintenir et étendre l’emprise du capital, Baudrillard affirme qu’il n’y a même plus de réel, que le spectacle, les simulacres, ont “dévoré” le réel, que “la carte a remplacé le territoire.”</p>
<p>Les péripéties, les événements, le “réel” ne sont plus que les éléments d’une immense simulation destinée à maintenir l’illusion de l’existence d’un réel, d’enjeux de pouvoirs et de luttes idéologiques. Le Watergate, la détente russo puis sino-américaine, le Vietnam, l’accident nucléaire de Three Miles Island précédé de peu par le film <em>Le syndrôme chinois</em>, Beaubourg, les hypermarchés, Disneyland, la publicité… sont quelques uns des artefacts de la <em>post-modernité</em> qu’il convoque à l’appui de sa thèse. L’hypertrophie du sens et du discours, y compris “de gauche” sur la question sociale, masque ou tente de masquer le vide du réel.</p>
<p>La dissuasion - nucléaire, sécuritaire - maintien le réel comme en suspens, produit un glacis sur le réel en attente de l’inévitable catastrophe toujours repoussé à l’horizon. Le terrorisme est ambigü, car en tant que catastrophe authentique il réintroduit du réel dans la simulation, mais il vient aussi renforcer ce qu’il prétend détruire en réactivant la simulation de la normalité et du réel une fois la catastrophe passée.</p>
<p>Pour le dire autrement, dans le monde hyperréel <em>tout</em> fait sens, tout test saturé de sens et est récupérable et récupéré. Mais personne n’est dupe et ceux qui regardent de la téléréalité, par exemple, savent très bien qu’il s’agit d’un simulacre à moitié scénarisée, mais cela n’a aucune importance. Il n’y a plus <em>d’extérieur</em> ou d’alternative, et la seule option qui reste c’est le <em>nihilisme</em> dont se réclame explicitement Baudrillard dans le dernier chapitre de <em>Simulacres et simulations</em>.</p>
<p>Contrairement à Debord, Baudrillard a toujours fait partie du système qu’il dénoncait : il a été professeur de lycée et d’université, invité à donner des conférences et des séminaires aux quatre coins de la planète ; il a été marié (2 fois) et a eu des enfants ; il a exposé ses photographies dans des musées et des galeries d’art…</p>
<p>C’est à mon sens l’aporie principale de son post-modernisme : la critique, aussi percutante et visionnaire soit elle, se dissout <em>elle aussi</em> dans l’hyper-réel du fait de l’anomie qu’elle induit, se perd dans l’infini de la récupération et des jeux de miroirs de la <em>séduction</em> du spectacle, là où Debord et l’IS tracent un chemin d’existence concret, joyeux et bordélique.</p>
<p>Là où Baudrillard a tendance à “se taper des poses”, Debord agit et c’est en ce sens que le situationnisme est un humanisme pour reprendre une formule célèbre.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>On &quot;Work&quot;</title>
    <link href="http://abailly.github.io/posts/work.html" />
    <id>http://abailly.github.io/posts/work.html</id>
    <published>2022-01-14T00:00:00Z</published>
    <updated>2022-01-14T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>On &quot;Work&quot;</h1>

  <h2 class="subtitle">A History of How We Spend Our Time</h2>

<div class="info">Posted on January 14, 2022</div>

<p><a href="https://www.bloomsbury.com/uk/work-9781526604996/">Work</a> is a book by James Suzman which seems to be a popular version of his academic works.</p>
<h1 id="summary">Summary</h1>
<p>The book starts by exposing the relationship between <em>work</em> in the physical sense, eg. transformation of energy, and <em>work</em> in the human sense. Work appears to be something that is characteristic of all life forms: Life is about extracting energy from the environment in order to sustain an organism. More and more complex life forms evolved through more and more efficient energy extractions capabilities, from the primitive chemical absorption of unicellulars to photosynthesis, to parasites, to plant grazers, to meat eaters… Eating more evolved life forms that already have extracted and refined energy from other sources is more efficient. Omnivorous animals dominate the “ecosphere” as they are able to extract energy from a wider variety of sources, and humanity made a leap through the discovery of <em>fire</em> which allowed humans to become even more efficient energy harvester.</p>
<p>But life is also about <em>spending</em> energy. Most lifeforms spend 100% of their energy on basic needs: Looking for food, mating, reproducing, but it’s not always the case: Suzman gives one detailed example of a south african bird that spends a great deal of its time building intricate nests that are not used. Living in an bountiful environment from which it can easily feed itself gives it more “free time” to spend energy on “useless” matters. Other examples abound and testify for <a href="./origin-of-species.html">Darwin’s</a> <em>sexual selection</em> principle: It’s not enough to be the “fittest”, one has also to reproduce successfully and it’s perfectly possible that species evolve seemingly useless characters that provide an advantage for mating and reproduction.</p>
<p>Suzman spent lot of time living with and studying what is left of the Khoisan (aka. Bushmen). They are the closest approximation to how our ancestors would have been living, they have been around for 10s of 1000s of years and barely changed their way of life. Khoisan are hunter-gatherers that feed from a somewhat hostile, arid environment, yet it’s been estimated they “work” about 3-4 hours per day maximum, more often less. They do not accumulate food nor any kind of goods and their society is fiercely egalitarian: The rich are mocked and anyone can ask anyone else to give him or her something they own, which guarantees quick equalisation and distribution of any kind of riches</p>
<p>From the work of <a href="https://en.wikipedia.org/wiki/Original_affluent_society">Marshall Sahlins</a>, <a href="https://en.wikipedia.org/wiki/James_C._Scott">James C. Scott</a>, <a href="https://en.wikipedia.org/wiki/Pierre_Clastres">Pierre Clastres</a> and others, we now know “primitive” societies have been much more affluent than the Western narrative usually asserted it. There are a lot of archaelogical evidences from the early days of humanity showing that people were doing something else than gathering food, engaging into production of art, crafts, and probably a lot of purely social activities that leave no trace. Humans, like all living beings, don’t seem to like staying idle hence “work” has a natural tendency to fill time. We don’t even know what the omnipresent <a href="https://en.wikipedia.org/wiki/Hand_axe">Hand-axe</a> was used for, but we know it required training, time and skill to be done properly.</p>
<p>It’s not clear at what point society became unegalitarian, there are tombs showing differences in wealth before agriculture, but it’s clear agriculture raised significantly the amount of work people had to do to sustain themselves especially as in the early days, agriculture was inefficient, dangerous, bread epidemics… See <a href="https://yalebooks.yale.edu/book/9780300182910/against-grain">Against the grain</a> for more thorough discussion on the “Agriculture revolution” narrative. It’s not even clear that agriculture in and of itself breeds inequality as there are evidences of egalitarian farming societies, and even egalitarian city dwellers like in Çatalhöyük.</p>
<p>The second half of the book is devoted to how our urban, highly mechanised, energy hungry society came into being, from the early days of agriculture with archeologic findings in Palestine and fertile crescent. Agriculture was a revolution that took time to take off but fundamentally changed our relationship to work and our environment: Agriculture made the concept of <em>delayed returns</em> central to the life of the first farmers, whereas HG societies were built around <em>immediate returns</em>. Whereas in the latter case, man is <em>part</em> of an environment that profusely provides everything that’s needed for him to strive, and no more, in the former the environment becomes the <em>nature</em>, an external source of food, wealth, resources and energy that must be worked on, harvested, accumulated, invested.</p>
<p>Humanity’s relationship to its environment became more and more <em>instrumental</em>, nature was objectified and contrasted with <em>culture</em> whereas the hunter-gatherer societies had a symbiotic relationship with their environment.</p>
<p>Then Suzman draws from the work of Malthus, Keynes, Sahlins, Taylor to demonstrate how this fundamental shift turned <em>scarcity</em> as a central driver of our lives. Malthus “proved” that infinite growth was unsustainable because productivity of the land would grow linearly where population grows exponentially. Technical progress disproved his predictions for a couple of centuries, until the growth of fossile energy consumption has thrown the climate into a trajectory that could prove fatal to humanity.</p>
<p>During the XIXth century and the first half of the XXth, continuous improvement in productivity lead to a decrease in the amount of time people spent working, from 70-80 hours a week in the early days of industrial revolution, to about 40 hours. Keynes predicted this fall would continue thanks to increasing mechanisation but he was proven wrong: Since the 70s, work time has stagnated or even slightly increased again, esp. in the U.S and since the 1980s, inequalities in the distribution of wealth (and revenue) have also increased drastically as documented notably by <a href="https://www.seuil.com/ouvrage/le-capital-au-xxie-siecle-thomas-piketty/9782021082289">Piketty’s work</a>.</p>
<p>Work has become a central part of our lives to the point it mostly defines us (the first thing 2 strangers talk about when introduced to each other is the work they do), yet this should not be considered “normal” or a necessity: It’s a consequence of the industrial revolution, that was made possible by increasing yield of farming and increasingly energy efficient machines, which in turn created an increasingly complex economic system and society.</p>
<p>Durkheim founded sociology in order to better understand this complex system, which lead him to study the “malady of infinite aspiration” or <em>anomie</em>. Work has become something we do <em>in order to</em> do something else, a mean to an end, a way to earn money that we can spend consuming things we have been producing in the first place, but indirectly. Contrary to what classical economists like Smith, Malthus and others thought, scarcity might not be a consequence of the infinite desires of men and their growing numbers pitted against limited resources, but rather this “infinite aspiration” is a consequence of modern conditions of living.</p>
<p>Scarcity, greed and the absurd accumulation of wealth they generate, are then a by product of our civilisation, not its foundation.</p>
<h1 id="conclusion">Conclusion</h1>
<p>I’m having a hard time summarizing the core idea of this book, what really James Suzman is after. The second half of the book which delves into the more modern history of (Western) societies sounds somewhat like it adopts a moralist’s stance, a criticism of modernity’s appetite for work and unlimited growth that is all too easily contrasted with the ascetic yet joyful way of life of hunter-gatherer tribes like the Khoisan, or what we know from archaeological evidences. The first half, which exposes findings and evidences from still existing hunter-gatherers societies, is the most interesting one as it questions the narrative around primitives, the superiority of <em>Homo Sapiens</em>, and the take-off that agriculture permitted.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Il faut s&#39;adapter&quot;</title>
    <link href="http://abailly.github.io/posts/il-faut-s-adapter.html" />
    <id>http://abailly.github.io/posts/il-faut-s-adapter.html</id>
    <published>2021-11-05T00:00:00Z</published>
    <updated>2021-11-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Il faut s&#39;adapter&quot;</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on November  5, 2021</div>

<p>C’est à Fabien Lamarque et à sa <a href="https://fabien-lamarque.eu/Il-faut-s&#39;adapter/">recension</a> du livre de Barbara Stiegler que je dois l’impulsion de sa lecture. <a href="http://www.gallimard.fr/Catalogue/GALLIMARD/NRF-Essais/Il-faut-s-adapter#"><em>Il faut s’adapter</em></a> est une étude fouillée des écrits de <a href="https://en.wikipedia.org/wiki/Walter_Lippmann">Walter Lippmann</a> considéré comme le père du “néolibéralisme”, et sa confrontation avec les écrits de <a href="https://en.wikipedia.org/wiki/John_Dewey">John Dewey</a>, l’un des fondateurs du <em>pragmatisme</em>.</p>
<h2 id="le-néolibéralisme-de-lippmann">Le néolibéralisme de Lippmann</h2>
<p>En résumé, le <em>néolibéralisme</em> de Lippmann est la conjonction de:</p>
<ol style="list-style-type: decimal">
<li>la croyance en l’inéluctabilité de l’économie de marché globalisée ;</li>
<li>l’inadaptation congénitale du capital humain aux exigences du marché et de la compétition ;</li>
<li>et donc le besoin d’un gouvernement technocratique et interventionniste susceptible de mettre en oeuvre les politiques nécessaires à l’adaptation des masses aux besoins de l’économie.</li>
</ol>
<p>Lippmann part d’une critique du libéralisme classique, incarné sur le plan économique par la pensée d’Adam Smith et sa “main invisible du marché”, et sur le plan politique et sociétale par les Lumières et leur lutte pour la démocratie et contre les gouvernements autoritaires. Ce libéralisme a failli et n’est plus pertinent dans le contexte de la <em>Grande Société</em> qui est celle de la seconde révolution industrielle, mondialisée, comme le montrent les souffrances qu’elle génère pour les masses exploitées.</p>
<p>Contre Marx et les marxistes qui prônent le renversement du capitalisme et l’instauration du communisme, et s’inspirant de Darwin et de sa théorie de l’évolution, Lippmann considère que le problème est celui de l’inadaptation des être humains à ce nouvel environnement vu comme une force inéluctable. Il s’agit donc de promouvoir une meilleure adaptation du “matériau humain”, au travers des forces de la sélection naturelle, de la compétition et de la “Survie des plus aptes” (<em>Survival of the fittest</em>) qui sont les principes du darwinisme.</p>
<p>Mais là où Spencer et d’autres penseurs que l’on pourrait qualifier d’<em>ultra-libéraux</em> prônent un <em>darwinisme social</em> intégral et la restriction du champ d’action des gouvernements à quelques domaines régaliens, laissant libre cours aux forces du marché et de la concurrence pure et parfaite ; Lippmann considère que les masses et les individus sont incapables à eux seuls d’évoluer suffisamment rapidement et efficacement pour que cette adaptation se fasse sans d’immenses souffrances car ils sont structurellement englués dans les “stases” d’une culture déjà dépassée. Comme le montre l’histoire économique du XIXème siècle en particulier aux États-Unis, le libéralisme et la concurrence “parfaite” mènent à la création de nouvelles oligarchies et de rentes monopolistiques, soutenues par des régimes juridiques protégeant les situations acquises.</p>
<p>Il propose donc un modèle de gouvernement qui a pour fonction à la fois de soigner et éduquer les masses en vue de leur meilleure adaptation, et d’assurer à chacun une “égalité des chances” entendue comme la suppression de biais faussant la compétition entre individus. Ce gouvernement doit être essentiellement technocratique, formé d’experts neutres et bienveillants, et strictement encadré par le <em>droit</em> et plus précisèment la <em>Common Law</em>, un modèle juridique fondé sur la constante adaptation des règles par la jurisprudence.</p>
<p>Ce néolibéralisme dépasse ainsi l’opposition identifiée par Foucault entre la biopolitique du libéralisme classique visant à libérer les flux, et les techniques disciplinaires cherchant à contrôler et normaliser les corps.</p>
<h2 id="le-dewey-lippmann-debate">Le <em>Dewey-Lippmann Debate</em></h2>
<p>À la pensée de Lippmann s’oppose celle de John Dewey, l’un des pères fondateurs du <em>pragmatisme</em> américain avec William James, dont elle est pourtant issue : les premiers écrits de Lippmann sont clairement dans la lignée de la pensée pragmatiste fondée sur le primat de l’expérience concrète et vécue.</p>
<p>Dewey lui-aussi s’inspire des thèses de Darwin, mais il les retourne contre Lippmann et les darwinistes sociaux, mettant en avant le caractère profondèment <em>expérimental</em> de la théorie de l’évolution et l’absence de finalité. D’une part, les individus et les groupes sont en constante <em>interaction</em> avec leur environnement constitué pour une grande partie d’autres individus et d’autres groupes, et l’évolution peut tout autant passer par une adaptation des individus à l’environnement qu’une adaptation de l’environnement aux individus. Les exemples abondent dans <a href="/posts/origin-of-species.html">The Origin of Species</a> d’espèces en interaction les unes avec les autres et ayant co-évolué, par exemple les fleurs et les abeilles, ou les fourmis et les pucerons.</p>
<p>D’autre part, l’évolution n’a pas de fin déterminée, n’est tendue vers aucun but assignable si ce n’est la continuation de la vie. C’est d’autant plus vrai lorsqu’il s’agit de <em>faits sociaux</em> qui sont le produit des actions humaines, qu’il s’agisse d’innovation technologique, d’idées, d’institutions, de pratiques, de coutumes. En considérant que l’humanité doit s’adapter au “progrès” et à l’économie de marché globalisée, les néo-libéraux commettent un contresens sur la théorie de l’évolution et ce faisant reconstruise une métaphysique, une séparation stricte des moyens et des fins.</p>
<p>Pour Dewey, l’évolution est <em>expérimentation permanente</em> aussi bien dans la détermination des fins que dans celle des moyens, ce qu’il appelle <em>l’enquête</em>. Et cette expérimentation permanente doit passer par un débat démocratique. De fait, la démocratie est pour Dewey liée à cette expérimentation permanente : ne peut être dit démocratique qu’une société qui promeut parmi ses membres une confrontation des idées, des choix de vie, une discussion des fins et des moyens constamment renouvelée et à laquelle tous doivent participer.</p>
<p>Comme pour Lippmann, l’éducation est chez Dewey fondamentale afin d’assurer une “égalité des chances”, non pas dans l’optique d’une compétition de tous contre tous mais pour permettre à chacun d’exprimer au maximum ses potentialités, et la tâche essentielle de tout gouvernement démocratique est de fournir à chacun les conditions de possibilités de cette expression.</p>
<p>Le décalage perçu par Lippmann et Dewey entre les schèmes de pensées, la culture, et l’état du système de production et des évolutions technologiques, est interprété par l’un comme étant négatif, comme un retard d’évolution à rattraper, à corriger ; tandis que l’autre le perçoit comme une tension dynamique et créatrice.</p>
<p>Lippmann quoiqu’étant interventionniste, critique le <em>New deal</em> de Roosevelt parce qu’il cherche à corriger les méfaits de l’économie de marché, parce qu’il est une forme de collectivisation qui corrige les effets sans s’attaquer aux causes qui sont pour lui dans ce retard de la société. Il est pourtant tout aussi interventionniste et progressiste, et c’est pourquoi il peut apparaître aux yeux d’une certaine gauche - en gros social-démocrate - comme acceptable et même pertinent. En captant à son profit le concept de progrès vu comme une marche vers l’extension indéfinie de l’économie de marché et l’adaptation parfaite des travailleurs à celle-ci, le néolibéralisme enferme ainsi toute la gauche dans ce dilemme : ou bien se rallier à la vulgate néolibérale, ou bien apparaître comme conservatrice et réactionnaire.</p>
<h2 id="résonnances-contemporaines">Résonnances contemporaines</h2>
<p>Si je connaissais Dewey et le pragmatisme, je n’avais jamais entendu parler de Lippmann avant de lire ce livre. Et Barbara Stiegler avoue elle-même dans sa conclusion qu’il pourrait justement lui être reproché d’accorder trop d’importance à un auteur mineur quand d’autres formes d’ultra-libéralismes (Hayek, Friedman) semblent avoir un impact bien plus significatif.</p>
<p>Il assez clair que Barbara Stiegler attaque ici, sans le dire explicitement, l’évolution des partis de gauche, le <em>Parti Socialiste</em> en France et les partis sociaux-démocrates occidentaux, au cours du XXème siècle. Dans un glissement progressif sur plusieurs décennies ces partis, ayant abandonné tout horizon révolutionnaire pour le réformisme, la mise en place d’un <em>État providence</em> et une politique sociale favorisant “l’égalité des chances” se sont laissés coloniser par la pensée néolibérale au point de considérer l’économie de marché, la compétition mondialisée et le capitalisme comme naturels et indépassables.</p>
<p>D’une certaine manière l’étude <a href="https://www.seuil.com/ouvrage/clivages-politiques-et-inegalites-sociales-amory-gethin/9782021456479">Clivages politiques et inégalités sociales</a>, qui montre l’évolution des structures de votes de la plupart des démocraties au cours des 70 dernières années, confirme cette évolution : tandis que le vote des plus riches restait ancré à droite, le vote des plus éduqués basculait à gauche, et l’on peut penser que cette bascule a été correlée à l’acceptation par une partie de la gauche des thèses néolibérales dans la lignée de Lippmann.</p>
<h2 id="résonnances-personnelles">Résonnances personnelles</h2>
<p>Sur un plan plus personnel, comme le disait Fabien dans son article ce livre m’oblige à me poser des questions sur la manière dont moi-même je prends part à cette idéologie néolibérale en tant que pratiquant et promoteur de pratiques “agiles”, d’une approche adaptative et évolutioniste du développement logiciel.</p>
<p>Au centre de cette question se pose la question du “changement” et de la tension entre <em>stases</em> et <em>flux</em>. D’une certaine manière cette tension est d’ordre anthropologique, elle est au coeur de ce que c’est qu’être <em>humain</em>, doué d’une raison, de la capacité à échanger des idées avec d’autres êtres humains, à rêver, à raconter des histoires et échaffauder des plans, à craindre et espérer, à respecter la “tradition” ou vouloir renverser la table. Cette tension traverse toutes les sociétés, toutes les époques, tous les êtres humains, et elle même évolue.</p>
<p>La Renaissance européenne et les Lumières ont modifier des équilibres séculaires mais il y a toujours eu des progressistes et des conservateurs, des pionniers et des organisateurs, des moments de notre existence où nous souhaitons que rien ne change et d’autres où nous avons la “bougeotte”, des possédants attachés à conserver leurs biens et des démunis souhaitant sortir de la misère.</p>
<p>Le débat entre Lippmann et Dewey est intéressant et important parce qu’il permet de comprendre que l’opposition essentielle n’est pas entre “progressisme” et “conservatisme”, entre partisans des <em>flux</em> et partisans des <em>stases</em> : il est entre ceux qui pensent et assignent à l’humanité, ou à un groupe plus restreint, une fin nécessaire - le capitalisme - laissant éventuellement la discussion ouverte sur les moyens pour y parvenir ; et ceux pour qui la fin est toujours ouverte et elle même sujette à discussion et redéfinition.</p>
<p>Sur le plan de l’éthique personnelle et professionnelle, cette opposition se manifeste dans la question de <em>l’autonomie</em> et des règles de fonctionnement du collectif : qui et comment sont définies les <em>fins</em> ? Lorsque le <em>Lean</em>, l’agilité ou toute autre technique <em>adaptative</em> et <em>évolutionnaire</em> est mise au service d’une organisation dont les fins sontr définies selon d’autres modalités, par une autorité extérieure ; lorsque ceux qui définissent les fins et ceux qui définissent les moyens ne sont pas les mêmes personnes ou sont dans une relation de subordination ; lorsque les pratiques agiles sont au service d’une définition exogène de la productivité et des résultats attendus ; lorsque <em>ceux qui font</em> ne sont pas <em>ceux qui décident</em> ou <em>ceux qui savent</em>, qu’ils ne peuvent mettre en doute, interroger, modifier les fins qui leur sont assignées ; alors Lippmann et le néolibéralisme triomphent, produisant l’accéleration généralisée et ses symptômes - désengagement, stress, burn-out, rage incontrôlée, complotisme - dont notre société souffre.</p>
<p>Mais les mêmes outils peuvent aussi, suivant Dewey et les pragmatistes, être mis au service de la définition des fins. Une équipe autonome, agile, pratiquant le TDD, le <em>Pair-Programming</em>, l’appropriation collective du code, la proximité avec le client final, n’est vraiment fidèle à l’idée qui sous tend l’eXtreme Programming que si elle a toute latitude pour négocier et décider de ses propres fins.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Why mocking is a good idea</title>
    <link href="http://abailly.github.io/posts/mocking-good-idea.html" />
    <id>http://abailly.github.io/posts/mocking-good-idea.html</id>
    <published>2021-10-29T00:00:00Z</published>
    <updated>2021-10-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Why mocking is a good idea</h1>

  <h2 class="subtitle">... when done right</h2>

<div class="info">Posted on October 29, 2021</div>

<p>Someone wrote a <a href="https://cs-syd.eu/posts/2021-10-22-why-mocking-is-a-bad-idea">recent post</a> debunking what the author thinks are <em>Mocks</em>. I say “thinks” because actually, what the author describes are not what <em>Mock objects</em> really are or how they were thought to be used, as this post demonstrates.</p>
<h1 id="what-are-mock-objects-really">What are Mock Objects really?</h1>
<p>The history of the <em>Mock object pattern</em> for <em>Test-Driven Development</em> is explained by <a href="http://www.mockobjects.com/">Steve Freeman</a> its inventor. He wrotes, with Nat Pryce, the book <a href="http://www.growing-object-oriented-software.com/">Growing Object-Oriented Software Guided by Test</a> which is a must read even if one does only functional programming. There’s also a shorter <a href="http://jmock.org/oopsla2004.pdf">OOPSLA 2004 paper</a> and an <a href="https://web.tecgraf.puc-rio.br/~ismael/Cursos/Cidade_MA/aulas/downloads/mockobjects.pdf">XP 2000 paper</a>. The very same idea was also exposed in the context of refactoring legacy code by Michael Feathers in his seminal <a href="https://understandlegacycode.com/blog/key-points-of-working-effectively-with-legacy-code/">Working Effectively with Legacy Code book</a> which is another must read, even if one does functional programming.</p>
<p>The key insight about Mock objects dawned on me when I realised these were really <em>Design tools</em>, much like one harvests most of the benefits of TDD when she conceives tests as a force to drive software design and not merely as a safety net against regression. In other words, one <em>does not</em> use Mock objects, or mock <em>interfaces</em>, only to replace a cumbersome dependency, but rather mocks roles that emerge from the needs of some piece or component of the system, to express the expectations of this component regarding some dependency without having to depend on the implementation details. Mocks are used to design <em>interfaces</em> between moving parts of the system, or to let <em>seams</em> appear as M.Feathers names those.</p>
<h1 id="the-proof-is-in-the-pudding">The proof is in the pudding</h1>
<p>Here is a concrete example drawn from my current project, Hydra, implemented in Haskell. The Hydra node we are building needs to interact with a <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/hydra-node/src/Hydra/Chain.hs">Chain</a> component, both to submit transactions and to receive them. Instead of having to depend on the <a href="https://github.com/input-output-hk/cardano-node">somewhat complicated implementation details</a> of a real Cardano node, we instead defined an <em>interface</em> which expresses in a concise and implementation independent way the information we send and receive.</p>
<p>Because we are using a functional language, this interface is expressed as a function which itself takes other functions (callbacks), a recurring pattern we documented in an <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/docs/adr/0007-with-pattern-component-interfaces.md">Architectural Decision Record</a>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">ChainComponent</span> tx m a <span class="fu">=</span> <span class="dt">ChainCallback</span> tx m <span class="ot">-&gt;</span> (<span class="dt">Chain</span> tx m <span class="ot">-&gt;</span> m a) <span class="ot">-&gt;</span> m a</code></pre></div>
<p>where</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">ChainCallback</span> tx m <span class="fu">=</span> <span class="dt">OnChainTx</span> tx <span class="ot">-&gt;</span> m ()

<span class="kw">newtype</span> <span class="dt">Chain</span> tx m <span class="fu">=</span> <span class="dt">Chain</span>  {<span class="ot"> postTx ::</span> <span class="dt">MonadThrow</span> m <span class="ot">=&gt;</span> <span class="dt">PostChainTx</span> tx <span class="ot">-&gt;</span> m () }</code></pre></div>
<p>The details of the messages we are sending and receiving are defined as two separate data types, one representing outbound transactions, eg. transactions we’ll post to the chain:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">PostChainTx</span> tx
  <span class="fu">=</span> <span class="dt">InitTx</span> {<span class="ot">headParameters ::</span> <span class="dt">HeadParameters</span>}
  <span class="fu">|</span> <span class="dt">CommitTx</span> {<span class="ot">party ::</span> <span class="dt">Party</span>,<span class="ot"> committed ::</span> <span class="dt">Utxo</span> tx}
  <span class="fu">|</span> <span class="dt">AbortTx</span> {<span class="ot">utxo ::</span> <span class="dt">Utxo</span> tx}
  <span class="fu">|</span> <span class="dt">CollectComTx</span> {<span class="ot">utxo ::</span> <span class="dt">Utxo</span> tx}
  <span class="fu">|</span> <span class="dt">CloseTx</span> {<span class="ot">snapshot ::</span> <span class="dt">Snapshot</span> tx}
  <span class="fu">|</span> <span class="dt">ContestTx</span> {<span class="ot">snapshot ::</span> <span class="dt">Snapshot</span> tx}
  <span class="fu">|</span> <span class="dt">FanoutTx</span> {<span class="ot">utxo ::</span> <span class="dt">Utxo</span> tx}</code></pre></div>
<p>and the other representing inbound messages, eg. transactions and errors observed on the chain:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">OnChainTx</span> tx
  <span class="fu">=</span> <span class="dt">OnInitTx</span> {<span class="ot">contestationPeriod ::</span> <span class="dt">ContestationPeriod</span>,<span class="ot"> parties ::</span> [<span class="dt">Party</span>]}
  <span class="fu">|</span> <span class="dt">OnCommitTx</span> {<span class="ot">party ::</span> <span class="dt">Party</span>,<span class="ot"> committed ::</span> <span class="dt">Utxo</span> tx}
  <span class="fu">|</span> <span class="dt">OnAbortTx</span>
  <span class="fu">|</span> <span class="dt">OnCollectComTx</span>
  <span class="fu">|</span> <span class="dt">OnCloseTx</span> {<span class="ot">contestationDeadline ::</span> <span class="dt">UTCTime</span>,<span class="ot"> snapshotNumber ::</span> <span class="dt">SnapshotNumber</span>}
  <span class="fu">|</span> <span class="dt">OnContestTx</span>
  <span class="fu">|</span> <span class="dt">OnFanoutTx</span>
  <span class="fu">|</span> <span class="dt">PostTxFailed</span></code></pre></div>
<p>Had we coded in an Object-Oriented language, or used a <a href="https://peddie.github.io/encodings/encodings-text.html">final tagless encoding</a>, these would have been expressed as two separate interfaces with one method for each type. The important point here is that <em>we</em> are in control of this interface, <em>we</em> define the patterns of interactions with the external system we depend on and abstract away all the nitty-gritty details a dependency on a concrete implementation would entail. Our system is now <em>loosely coupled</em> to the other system as we have <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separated concerns</a>.</p>
<p>This has allowed us to focus on the core functionality of our software, to build a complete implementation of the <a href="https://iohk.io/en/research/library/papers/hydrafast-isomorphic-state-channels/">Hydra off-chain protocol</a>, <a href="https://www.youtube.com/watch?v=3D_SAC4nyVM">demonstrate a network of Hydra nodes</a> and have automated <a href="https://github.com/input-output-hk/hydra-poc/blob/master/local-cluster/test/Test/EndToEndSpec.hs#L99">end-to-end tests</a> all without the hassle of dealing with a full Cardano node implementation. Instead, we have several <em>Mock</em> implementations of the <code>Chain</code> interface described above suitable for various use cases: - A very fast <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/hydra-node/test/Hydra/BehaviorSpec.hs#L380">in-process</a> mock for Behaviour-driven testing of Hydra cluster, - A <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/hydra-node/src/Hydra/Chain/ZeroMQ.hs">0MQ-based</a> implementation that allows us to spin-up a cluster of Hydra nodes, completely mocking an <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/hydra-node/exe/mock-chain/Main.hs">external chain</a>.</p>
<p>Note that: - We are not side-stepping the integration problem as demonstrated by the fact we are also testing <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/local-cluster/test/Test/LocalClusterSpec.hs#L51">interaction with Cardano node</a>, and we definitely will enhance our End-to-End tests to “Close the loop” once the <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/local-cluster/test/Test/DirectChainSpec.hs#L30">Chain tests</a> demonstrate the <em>concrete implementation</em> of our abstract transactions work correctly on a real Cardano network, - We have been careful to <a href="https://testing.googleblog.com/2020/07/testing-on-toilet-dont-mock-types-you.html">Mock types we own</a> in order to not fall into the trap of relying on a dumbed down and probably wrong implementation of some system we depend on.</p>
<h1 id="there-is-more-to-it">There is more to it</h1>
<p>This whole idea has been applied in a couple other areas of the system, most notably the <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/hydra-node/src/Hydra/Network.hs">Network</a> interface: Here again we express some requirements from the point of view of the Hydra node, letting those emerge from tests we write.</p>
<p>While it does not respect the <em>Mock types you own</em> mantra, we have also used this technique to great profit leveraging the <a href="https://github.com/input-output-hk/ouroboros-network/tree/3f16f617f8ada5e0e8f560b5b2d9635ec0d803f3/io-sim">io-sim</a> and <a href="https://github.com/input-output-hk/ouroboros-network/tree/3f16f617f8ada5e0e8f560b5b2d9635ec0d803f3/io-classes">io-classes</a>, as exposed in <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/docs/adr/0005-use-io-sim-classes.md">another ADR</a>. This has allowed us to test-drive the development of the protocol in an outside-in way, expressing expected <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/hydra-node/test/Hydra/BehaviorSpec.hs#L123">observable behaviour</a> in a cluster of nodes, in a safe and fast way, as pure functions.</p>
<p>Of course, this is a dangerous path to tread and we need to also run tests with the real <em>Multi-threaded Runtime System</em> to ensure proper coverage, like the End-to-end tests I already talked about and <a href="https://github.com/input-output-hk/hydra-poc/tree/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/local-cluster/bench">load testing</a>.</p>
<h1 id="conclusion">Conclusion</h1>
<p>I hope this post managed to convince the reader that using <em>Mock objects</em> is actually a good idea as soon as one embraces it the way it’s been intended to be used, namely as a <em>Test-driving technique</em> also called <em>London School TDD</em>, and not as a mere technical artifact to ease testing <em>after the fact</em>. As I already advocated a while ago TDD has a <a href="https://abailly.github.io/posts/tdd.html">fractal dimension</a>: It can, and in my opinion must, be applied at all stages of a system’s development and at all level of abstractions.</p>
<p>“Mock objects” is just a name for the technique that lets one work outside-in, precisely and formally (in code) expressing and testing each component first in isolation, but within a broader context: As soon as a concrete, production-ready implementation of an interface is ready, it should be integrated in the higher level tests. This is also something we wrote down in an <a href="https://github.com/input-output-hk/hydra-poc/blob/2056b8c9ba441aebc396a4fe0f50a419d6ee7be3/docs/adr/0012-testing-strategy.md">ADR on Testing strategy</a> as it deeply impacts the architecture of the system.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;L&#39;invention du quotidien&quot;</title>
    <link href="http://abailly.github.io/posts/invention-du-quotidien.html" />
    <id>http://abailly.github.io/posts/invention-du-quotidien.html</id>
    <published>2021-09-26T00:00:00Z</published>
    <updated>2021-09-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;L&#39;invention du quotidien&quot;</h1>

  <h2 class="subtitle">Peut-on faire une théorie de la pratique ?</h2>

<div class="info">Posted on September 26, 2021</div>

<p>J’ai lu <em>L’invention du quotidien</em>, vol.1, de <a href="https://en.wikipedia.org/wiki/Michel_de_Certeau">Michel de Certeau</a>, fréquemment cité par Tim Ingold dans <em>Une histoire des lignes</em>. Il me semble aussi que James C. Scott et, de manière allusive, Bourdieu dans ses cours au Collège de France, le citent. Il fait partie de cette famille de penseurs critiques que mai 68 a cristallisée, qui s’est plus tard exportée aux USA sous le nom de “French Theory”, produisant les <em>Cultural studies</em> et plus récemment toute la famille des théories critiques de la société moderne : <em>Gender studies</em>, <em>Critical Race Theory</em>,…</p>
<p>Michel de Certeau a par ailleurs une formation de théologien et d’historien et a contribué au développement d’une école que l’on appelle <em>micro-histoire</em>, dont l’objectif est de faire l’histoire de ceux qui n’ont pas d’histoire : les “petites gens”, les marginaux, les faits anecdotiques et la vie quotidienne, les pratiques anciennes. Bref c’est un auteur que l’on peut définitivement classer à “gauche”.</p>
<p>Ce premier volume est issu d’une étude sur les pratiques culturelles s’étalant sur plusieurs années, et fût suivi d’un second volume rédigé par d’autres auteurs centrés sur les pratiques culinaires et la vie domestique (pas encore lu).</p>
<h2 id="synthèse">Synthèse</h2>
<p>Dans ce livre, Michel de Certeau cherche à réhabiliter la position de <em>consommateur</em>, notamment du consommateur de “biens culturels”, systématiquement méprisée et dévalorisée par rapport à celle de <em>producteur</em>. En quelque sorte, il cherche à théoriser ce qui échappe à la théorie, les pratiques concrètes des “vrais gens”, qui sont soit ignorées des savants, soient classées, catégorisées et systématisées par les théoriciens des pratiques sociales.</p>
<p>La théorie est par essence un processus d’abstraction du concret, par lequel un théoricien se pose en <em>surplomb</em> du réel, de la myriade de faits concrets observables et impossible à suivre dans leur intégralité. De même le créateur, le producteur et l’ensemble du système de diffusion de biens de consommation, se pensent comme un <em>centre</em> alimentant une périphérie, la masse des consommateurs, considérés comme passifs. Ce que veut montrer l’auteur c’est que cette vision, qu’incarne par exemple Michel Foucault quand il fait la généalogie du développement de la société du contrôle au travers du développement des techniques de surveillance et d’encadrement - école, hopitaux, prisons, casernes - est faussée par ses propres présupposés : le théoricien se positionne implicitement au centre du panoptique lorsqu’il construit une certaine représentation du réel, une théorie.</p>
<blockquote>
<p>Les institutions scientifiques appartiennent au système dont elles font l’étude : en l’examinant elle se conforme au genre bien connu de l’histoire de famille (un dialogue critique ne change rien à son fonctionnement, la critique créant l’apparence d’une distance à l’intérieur de l’appartenance). p .66</p>
</blockquote>
<p>Les Lumières ont posé ce postulat de la passivité du consommateur, du lecteur qui est modelé par ce qui lit ouvrant ainsi la possibilité d’une éducation des masses par la diffusion de la culture (sous-entendue, la culture légitime).</p>
<blockquote>
<p>Effet d’une idéologie de classe et d’un aveuglement technique, cette légende est nécessaire au système qui distingue et privilégie les auteurs, les pédagogues, en un mot les producteurs par rapport à ceux qui ne le sont pas. p242</p>
</blockquote>
<p>Mais les “gens ordinaires”, dans leur <em>vie quotidienne</em> de consommateur, ne sont passifs que si on les observe de très loin, si on ne s’intéresse pas aux détails concrets de leurs pratiques. En réalité, placés dans une position de subordination par l’autorité des producteurs et des penseurs, ils rusent, détournent, braconnent, bricolent pour s’approprier les biens qui leurs sont proposés ou imposés, ou les ignorer. M.de Certeau met l’accent en particulier sur la pratique de la “perruque”, le fait de détourner du temps de travail, du matériel, des outils, des machines de l’organisation dans laquelle on travaille, à ses propres fins. Non pas pour voler ou en tirer un bénéfice pécuniaire, mais comme un moyen d’échapper à la routine, d’inventer ses propres usages qui ne soient pas prescrits d’en-haut. Soit l’exact contraire du <em>management scientifique</em>, même dans ses formes plus modernes telles que le <em>Lean</em> ou le TPS.</p>
<p>À la stratégie qui est l’arme des forts, qui vise au meilleur emploi de la force en vue de fins précises, qui s’appuie sur un <em>lieu</em> et distingue un intérieur ou un <em>propre</em> - nous - d’un extérieur - les autres ; M. de Certeau oppose la <em>tactique</em> de ceux qui n’ont pas de force, qui doivent ruser pour parvenir à leurs fins, qui n’ont pas de lieu en <em>propre</em> mais sont placés dans des circonstances qu’ils ne maîtrisent pas et dont ils doivent tenter de tirer avantage, qui sont <em>contraints</em> par les situations. Plus la technologie libère des forces incontrôlables, plus les stratégies sont élaborées loin du quotidien, plus elles laissent d’espace à la tactique et à la ruse, au détournement : le <em>quotidien</em> s’insinue dans les mailles du réseau qui se multiplient à mesure que celui-ci s’étend<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p>
<p>L’auteur n’hésite pas à convoquer pour les critiquer deux figures tutélaires de la critique sociale : Michel Foucault et Pierre Bourdieu. S’il loue la force de leur pensée et la pertinence de leurs analyses, ils n’en restent pas moins à ses yeux des théoriciens imposant à leur sujet <em>leur</em> propre vision des choses. En voulant montrer par une analyse “généalogique” que le développement du <em>biopouvoir</em> et des technologies est un processus souterrain qui prend appui sur les <em>Lumières</em>, Foucault sélectionne parmi l’immensité des faits ceux qui servent sa théorie. Quant à Bourdieu, sa théorie de l’<em>habitus</em> comme liant dans une <em>docte ignorance</em> des contraints structurelles, des dispositions et des pratiques, quelque mérite qu’elle puisse avoir pour montrer la persistance et l’intériorisation des situations de dominations, réitère toutefois le geste du savant théorisant son objet et ce faisant le mettant à distance, présupposant que les structures qu’il met au jour sont ignorées des groupes observés.</p>
<p>Le scientifique, l’ethnologue, l’anthropologue qui collectent, classent, analysent, modélisent des pratiques et des discours, simultanément les vident de leur sens.</p>
<p>Comment donc relier théorie et pratique ? Une manière de ce faire est celle de <em>l’ingénieur</em> qui lie théorie et pratique dans la <em>machine</em> et par ce geste vide de sens le discours sur les <em>arts de faire</em> : quel sens peut avoir la maîtrise de tel ou tel métier, telle ou telle pratique quand ils sont incarnés dans des machines de plus en plus précises et sophistiquées ? Pour Kant dans <em>Critique de la faculté de juger</em>, c’est proprement le jugement qui relie théorie et pratique au travers du goût, du tact.</p>
<blockquote>
<p>Le manque de jugement est proprement ce qu’on appelle stupidité et à ce vice il n’y a pas de remède.</p>
</blockquote>
<p>La narration et le récit sont le pendant dans l’ordre du discours de ces <em>arts de faire</em>. Raconter une histoire, narrer, discourir, déclamer, convaincre par la parole nécessitent l’usage de ces ruses, sont tributaires du <em>Kairos</em>, de l’instant propice où tout se joue. De cela il n’est pas de théorie possible.</p>
<p>La ville est encore un autre exemple de cette distance entre théorie et pratique et de l’effet de domination de la première sur la seconde. La vision “aérienne” de l’urbaniste, de l’architecte, du planificateur, s’oppose à la vision “au ras du bitume” de l’habitant<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> : d’un côté une vision ordonnée, synoptique, de l’autre un labyrinthe. D’un côté un <em>lieu</em>, que l’on peut représenter sous la forme d’une <em>carte</em>, distribuant les éléments les uns par rapport aux autres (au nord le commissariat, à l’ouest le supermarché), de l’autre un <em>espace</em> défini par les mouvements que l’on peut y faire, par des <em>parcours</em>, décrits en termes d’opérations (tourner à gauche, traverser la rue…). D’un côté <em>voir</em> et décrire dans un langage scientifique, de l’autre <em>faire</em> et raconter dans le langage commun.</p>
<p>On retrouve cette opposition dans la distinction entre la <em>voix</em> et <em>l’écrit</em>, source et paradigme de la modernité. Le mythe de la <em>page blanche</em> et de l’auteur maîtrisant le monde par l’écrit, tel Robinson Crusoë entamant la colonisation de son île par l’écriture d’un journal, est central dans l’Occident moderne depuis la Renaissance et la Réforme. Prenant modèle sur la Bible, les premiers penseurs humanistes visent à refonder l’histoire, la société et le monde non plus en <em>interprétant</em> les secrets de Dieu tels qu’ils se dissimulent dans l’ordonnancement de la création et les Écritures, mais en produisant un <em>ordre</em> nouveau au moyen de la <em>Raison universelle</em><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. L’écriture s’inscrira désormais non plus seulement sur des monuments, mais sur des corps au travers la Loi, des contrats, de la médecine et des sciences, d’une constitution explicitement écrite.</p>
<p>La voix devient le domaine du <em>peuple</em> et de la masse, la <em>voix du peuple</em> est cette chose crainte et mythifiée parce que non écrite que l’ont va chercher à réduire à de l’écrit, à collecter, classer, analyser, et qui parfois revient dans la pratique comme imitation. Ainsi de la diffusion des argots et dialectes qui, une fois devenus inoffensifs et proprement analysés, s’incrustent dans la langue commune. Plus encore que la voix le <em>cri</em>, de colère, de jouissance, de peur, de souffrance est ce qui échappe à toutes les contraintes du corps imposées par la société, au contrôle par les institutions et les multiples réseaux de pouvoir.</p>
<blockquote>
<p>Peut-être toute l’expérience qui n’est pas cri de jouissance our de douleur est elle collectée par l’institution p.219</p>
</blockquote>
<p>In fine, Michel de Certeau en bon catholique qu’il est s’interroge sur la persistence de “ces croyances du passé qui n’organisent plus des pratiques” que ce soit dans le domain de la religion ou de la politique. Il y aurait une usure des croyances qui sape l’autorité politique, fondée selon Hobbes justement sur la croyance. Ou plutôt qu’une usure, un transfert, la croyance n’étant pas attachée à son objet, passant de mythes en mythes.</p>
<h2 id="analyse">Analyse</h2>
<p><em>L’invention du quotidien</em> est un livre un peu ardu à lire, au style parfois très universitaire caractéristique des penseurs des années 60-70, et dont la succession des chapitres ne semble pas toujours suivre un enchaînement logiquement évident. Mais c’est un livre qui résonne avec un certain nombre d’autres livres qui tournent autour de la question des rapports de domination, à travers l’histoire, dans notre société en général et dans le monde du travail en particulier, rapports de dominations qui se retrouvent plus précisèment dans les rapports entre la théorie et la pratique, entre les savoirs pratiques et théoriques, entre ceux qui <em>font</em> et ceux qui <em>savent quoi faire</em>.</p>
<blockquote>
<p>Toute notre civilisation est fondée sur la spécialisation, laquelle implique l’asservissement de ceux qui exécutent à ceux qui coordonnent. <em>Réflexions sur les causes de la liberté et de l’oppression sociale</em>, Simone Weil</p>
</blockquote>
<p>Mais rejetant un déterminisme social facile, Michel de Certeau essaye de démontrer que les “dominés”, en particulier les dominés dans le domaine culturel, ou pour le dire en termes bourdieusiens les personnes peu dotées en capital social, ne prennent pas la domination dont ils font l’objet pour argent comptant, ne sont pas ignorants de cette domination quand bien même ils n’occupent pas des rond-points ni ne font la révolution. Qu’il existe une créativité du quotidien, qui n’est pas la créativité de “l’artiste” ou du “chercheur” mais qui est faite de ruses, de détournements et de détours, de “perruque”, de braconnage. Là où les producteurs donnent le sens, les consommateurs se l’approprient et le détournent.</p>
<p>Cette créativité, c’est celle du lecteur qui, tel le Pierre Ménard de Borgès, recrée l’oeuvre qu’il lit indifférent aux intentions et désirs de l’auteur, ou bien encore <em>La culture des individus</em> interrogés par Bernard Lahire qui avouent être <em>à la fois</em> fans de concerts de heavy metal et de la peinture de Renoir. C’est aussi celle de tous ceux qui détournent les usages des logiciels que nous écrivons, parfois de manière surprenante, ou même dangereuse. Et c’est bien pourquoi il est si important lorsque l’on souhaite faire oeuvre utile d’impliquer les utilisateurs le plus tôt possible dans le processus de développement, afin de profiter de ce <em>feedback</em> que nous apportent ceux qui font.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>La manière dont les réseaux sociaux, pensés et “marketés” comme des outils du progrès de la tolérance et de la communication, sont détournés, investis et fragmentés par de multiples groupes, se transforment en une fabrique de chambre d’échos offre une image assez saisissante de ce qu’avait imaginé M. de Certeau avant même la naissance d’Internet.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Guy Debord et les Situationnistes ont théorisé (sic !) la pratique de la <em>dérive</em>, marche aléatoire dans les rues d’une ville pour en découvrir ou construire les diverses ambiances, conçue comme un antidote aux projets d’urbanismes des Trente Glorieuses qui ont notamment fortement transformé Paris (.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>C’est très proche de l’analyse que fait Foucault dans <em>Les mots et les choses</em> quand il décrit les transformations que la connaissance subit entre la Renaissance et l’Âge classique, puis entre ce dernier et la période moderne qui comment à la Révolution française.<a href="#fnref3">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Misère de l&#39;historicisme&quot;</title>
    <link href="http://abailly.github.io/posts/misere-historicisme.html" />
    <id>http://abailly.github.io/posts/misere-historicisme.html</id>
    <published>2021-09-05T00:00:00Z</published>
    <updated>2021-09-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Misère de l&#39;historicisme&quot;</h1>

  <h2 class="subtitle">Quelle méthode pour les sciences sociales ?</h2>

<div class="info">Posted on September  5, 2021</div>

<p><a href="https://www.babelio.com/livres/Popper-Misere-de-lhistoricisme/153793">Misère de l’historicisme</a> est un livre de <a href="https://fr.wikipedia.org/wiki/Karl_Popper">Karl Popper</a>, un des plus important philosophe du XXème siècle en particulier dans le domaine de l’épistémologie et de la philosophie des sciences. Popper est célèbre pour son <em>principe de réfutabilité</em> permettant de distinguer les théories scientifiques des autres : une théorie ne peut être scientifique que si elle est est réfutable, c’est à dire s’il est possible de concevoir une <em>expérience</em> permettant de la <em>tester</em>. La conséquence principale de ce principe épistémologique est que toute théorie scientifique est “en sursis”, elle conserve toujours le statut d’une hypothèse que des faits futurs pourraient invalider en tout ou partie. C’est arrivé régulièrement au cours de l’histoire, par exemple dans le domaine de la physique avec l’invalidation de la théorie du <a href="https://fr.wikipedia.org/wiki/Phlogistique">phlogistique</a>, en astronomie avec la réfutation de l’astronomie Ptoléméenne par Galilée et Copernic, en biologie avec la <a href="https://fr.wikipedia.org/wiki/Th%C3%A9orie_des_humeurs">théorie des humeurs</a>.</p>
<h1 id="synthèse">Synthèse</h1>
<p><em>Misère de l’historicisme</em> est un livre de “combat”, écrit par Popper en 1945 explicitement pour lutter contre les idéologies fascistes et surtout communistes. En premier page du livre on trouve ainsi cette épigraphe :</p>
<blockquote>
<p>En mémoire des innombrables hommes, femmes et enfants qui succombèrent, victimes de la croyance fasciste et communiste en des lois inexorables de la destinée historique.</p>
</blockquote>
<p>Le programme du livre est donc clair : réfuter logiquement les courants de pensées <em>historicistes</em> soit essentiellement le marxisme, mais aussi toutes les formes de systèmes de type hégeliens, ou même platoniciens, et prouver leur totale absence de scientificité. La critique de Popper va donc porter sur des questions de méthodes en sciences sociales puisque l’historicisme tel qu’il le présente vise à produire des théories <em>prédictives</em> à partir de méthodes <em>fondamentalement</em> différentes de celle utilisées dans les sciences naturelles et physiques.</p>
<p>En filigrane, on voit bien que Popper s’attaque à la théorie marxiste de la lutte des classes devant conduire inexorablement à l’effondrement du capitalisme sous le poids de ses contradictions internes et à la dictature du prolétariat. Popper est un social-démocrate mais ce n’est pas un ultra-libéral, même s’il est proche de <a href="https://fr.wikipedia.org/wiki/Friedrich_Hayek">Friedrich von Hayek</a> qu’il cite abondamment dans son livre en tant que modèle de scientificité pour les sciences humaines, seule l’économie et un peu la psychologie trouvant grâce à ses yeux. Il est connu par ailleurs pour défendre l’intervention de l’État et la nécessité d’un progrès social pour tous et il reconnait à Marx le grand mérite d’avoir défendu la cause des ouvriers opprimés.</p>
<h2 id="lhistoricisme">L’historicisme</h2>
<p>Schématiquement, l’historicisme est cette idée en apparence logique que, puisqu’un état donné des sociétés humaines est la conséquence de multiples décisions, choix, ou événements passés, la seule possibilité de découvrir des lois régissant les comportements humains individuels et sociaux est d’analyser ce passé et d’en déduire des tendances, des règles, des <em>motifs</em> à partir desquels réaliser des prédictions. L’historicisme est souvent - mais pas toujours - couplé à un certain nombre d’autres principes épistémologiques :</p>
<ul>
<li>le <em>totalisme</em> ou <em>holisme</em>, soit l’idée que les phénomènes sociaux ne peuvent se comprendre et s’analyser que globalement, au niveau de la société toute entière voire de l’humanité, car ils sont dépendants de multiples facteurs et d’une infinité de boucles de rétroactions ;</li>
<li>la <em>compréhension intuitive</em> : les phénomènes sociaux ne peuvent faire l’objet d’hypothèses ou de déductions, mais doivent être saisis <em>intuitivement</em> ;</li>
<li>l’impossibilité de <em>l’expérimentation</em> du fait de la complexité des interactions sociales, de la réflexivité dont sont dotés les acteurs sociaux et de l’intrication de l’observateur dans le processus expérimental ;</li>
<li>le rejet de <em>méthodes quantitatives</em>.</li>
</ul>
<p>Le <em>totalisme</em> est particulièrement ciblé par la critique de Popper car il conduit, lorsque l’on souhaite passer de la théorie à la pratique, au <em>totalitarisme</em> : les changements sociaux impliqués par la théorie ne peuvent être mis en oeuvre qu’à l’échelle de la société toute entière, ce qui implique une <em>révolution</em>.</p>
<h2 id="sa-critique">Sa critique</h2>
<p>La première critique de Popper s’attaque au fondement même de l’historicisme soit la possibilité de <em>prédire</em> les développements futurs. Cette critique est d’ordre logique et se résume assez simplement :</p>
<ol style="list-style-type: decimal">
<li>Le futur des sociétés humaines dépend essentiellement de l’état de ses connaissances ;</li>
<li>Il est logiquement impossible de prédire l’état des connaissances futur puisque par définition, ces connaissances ne sont pas connues ;</li>
<li>par conséquent il est impossible de prédire le futur des sociétés humaines. ■</li>
</ol>
<p>Cette erreur sur le caractère prédictif des “lois historiques” provient selon Popper, d’une part de l’incompréhension de ce que sont les lois scientifiques de la part des historicistes, d’autre part de l’aveuglement sur les conditions de possibilités de toute connaissance, scientifique ou non.</p>
<p>Les lois scientifiques ne sont pas des lois “absolues”, au sens où elles seraient vraies en tous temps et tous lieux, ce sont des <em>fonctions</em> ou des <em>relations</em> liant des conditions initiales à des observations et des comportements prévisibles. L’historicisme et son “Sens de l’histoire” postulent des lois indépendantes des conditions initiales, en fait des <em>tendances</em> observées dans un flux d’événements mais qui n’ont pas du tout le caractère de lois scientifiques, en particulier parce qu’elles ne sont pas falsifiables.</p>
<p>Par ailleurs, ces “lois” ou “tendances” inférées par l’observateur le sont <em>a posteriori</em> depuis un certain point dans le temps, donc par application des principes historicistes sont aussi le produit des conditions historiques de leur énonciation, de la situation particulière de l’énonciateur, et surtout de ses biais personnels. L’histoire humaine est un flux infini d’événements et de faits sur lequel on en prélève certains, considérés comme plus importants que d’autres, que l’on réinterprète depuis le futur donc avec de grandes chances de glisser vers une argumentation <em>téléologique</em>, ie. considérer que ce qui est arrivé et que l’on vit dans le présent était nécessairement ce qui devait arriver en vertu de “lois” donc.</p>
<p>Sur le problème de l’expérimentation, Popper fait remarquer que la situation des sciences sociales est similaire à celle des sciences du vivant : il est impossible de disséquer un organisme vivant sans le tuer, ce qui n’empêche pas les sciences naturelles d’expérimenter et de produire des connaissances théoriques empiriquement vérifiées. Et depuis les développements de la mécanique quantique, la physique elle-même, reine des sciences dures, est confrontée à ce problème de l’interaction entre l’expérimentateur et l’expérimentation.</p>
<p>S’il est certain que les faits sociaux sont extrêmement complexes du fait de multiples interactions et bouccles de rétroaction, c’est aussi le cas des faits physiques <em>concrets</em> toujours bruités, parasités par de multiples phénomènes dont il appartient au chercheur de séparé ce qui est pertinent pour son problème de ce qui ne l’est pas. D’une certain manière les faits physiques peuvent être beaucoup plus complexes que les faits sociaux car les êtres humains se comportent dans l’immense majorité des circonstances de manière rationnelle, donc compréhensible et prévisible, ce qui n’est pas le cas des phénomènes physiques.</p>
<p>Popper se situe résolumment du côté de Kant : le but de la science n’est pas de connaître ce que <em>sont</em> les choses, mais de décrire et comprendre comment elles se <em>comportent</em>, et l’approche scientifique ne peut faire abstraction du sujet connaissant : les lois de la science sont des modèles que <em>nous</em> élaborons, les expériences sont toujours porteuses d’un point de vue. C’est en vertu de ce <em>nominalisme</em> méthodologique que Popper critique ce qu’il appelle <em>l’essentialisme</em> dont est affecté l’historicisme, soit la propension à vouloir définir ce que <em>sont</em> les fait sociaux par leur histoire, plutôt que comment ces faits sociaux fonctionnent pour nous.</p>
<p>Et c’est ce qui conduit Popper à promouvoir ce qu’il appelle une <em>sociologie technologique</em>, une approche <em>fragmentaire</em>, locale et expérimentale des sciences sociales qui rejette toute méthode globale et toute vision surplombante du savant. Les institutions humaines constituant le monde social doivent être considérées comme des mécanismes sur le fonctionnement desquels on peut émettre des hypothèses, que l’on peut valider ou réfuter expérimentalement, et à améliorer par “petites touches”, par essais et erreurs.</p>
<p>Pour lui, au delà des différences évidentes de domaine de recherche, les sciences partagent une <em>méthode</em> unique, la méthode hypothético-déductive, basée sur la formulation d’hypothèses expérimentalement <em>réfutables</em>. Les sciences sont en fait <em>caractérisées</em> par cette méthode : une science est un corpus de connaissances construit par cette méthode.</p>
<h1 id="analyse">Analyse</h1>
<p><em>Misère de l’historicisme</em> est un livre clair et limpide, à l’argumentation logique imparable, et il explicite quelque chose qui m’a toujours gêné dans la rhétorique marxiste, cette croyance en une inéluctabilité de l’histoire qui n’est pas sans emprunter ses accents eschatologiques au christianisme.</p>
<p>Popper est un auteur souvent classé plutôt à droite : il est indubitablement libéral c’est à dire attaché aux libertés individuelles, à une société ouverte (c’est d’ailleurs le titre de l’un de ses ouvrages), à un gouvernement démocratique et à l’économie de marché. Et son livre est aussi un livre de circonstances, comme toute pensée humaine ancrée dans une histoire et un moment particulier. Il parait à un moment où les anciens alliés contre l’Allemagne nazie deviennent rivaux et ennemis, où la “Guerre froide” remplace la “Guerre chaude”, où Churchill évoque le “Rideau de fer” tombé sur l’Europe. On peut lui reprocher sa vision partiale et partielle de la pensée de Marx influencée à son époque par les dévoiements de l’Union soviétique, du léninisme et du stalinisme, sa propension à “jeter le bébé avec l’eau du bain”.</p>
<p>Mais son approche résolumment empirique des sciences sociales et sa vision d’une unicité fondamentale des sciences, d’un grand “manteau sans couture” qui unit dans une même méthode les sciences physiques, naturelles et sociales, résonnent avec mon expérience et mes réflexions personnelles dans le petit domaine qui est le mien, le développement en équipe de logiciels. <em>eXtreme Programming</em> en particulier, est évidemment ancré dans cette méthode scientifique que défend Popper, dans l’expérimentation à partir d’hypothèses, l’observation et l’analyse des résultats observés, l’ajustement permanent des hypothèses.</p>
<p>De toute évidence, Popper n’aime pas les révolutionnaires, et une critique facile (et historiciste) qui peut lui être faite est de ne pas critiquer ses propres biais, de ne pas analyser la position “d’où il parle”, de prendre pour acquises la certitude d’être dans le vrai. Mais ce à quoi il nous invite, ce n’est pas non plus à une vision statique des choses ou conservatrices des sociétés, c’est à plus de modestie dans notre prétention à savoir ce qui est “bon” ou “mauvais” à l’échelle d’une société ou même des individus, à plus de rigueur dans notre prétention à toute démarche scientifique, à mettre en oeuvre une démarche expérimentale rigoureuse et précise y compris dans les domaines qui touchent à l’humain.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>On &quot;On the Origin of Species&quot;</title>
    <link href="http://abailly.github.io/posts/origin-of-species.html" />
    <id>http://abailly.github.io/posts/origin-of-species.html</id>
    <published>2021-06-16T00:00:00Z</published>
    <updated>2021-06-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>On &quot;On the Origin of Species&quot;</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on June 16, 2021</div>

<p>I am indebted to Adèle van Reeth’s <a href="https://www.franceculture.fr/emissions/les-chemins-de-la-philosophie/les-chemins-de-la-philosophie-emission-du-lundi-08-fevrier-2021">Les chemins de la philotophie</a> for enthusing me in reading Darwin’s controversial masterpiece <a href="https://global.oup.com/academic/product/on-the-origin-of-species-9780199219223">On the Origin of Species</a>. We live in a time when creationism under the guise of so-called <em>Intelligent design</em> is again on the rise, when more and more people from developed countries, including highly-educated people, can believe <a href="https://physicsworld.com/a/fighting-flat-earth-theory/">Earth is flat</a>, when <em>post-truth</em> is a thing, and people can attract and retain the attention of millions with any kind of <a href="http://journal.sjdm.org/15/15923a/jdm15923a.html">bullshit</a>. Darwin published his book in the middle of the XIXth century, at a time when creationism was still dominant, and the religious dogma considered relevant on the matter of truth of natural sciences’ theories, especially ones dependent on pre-historical and geological times facts. So it seemed important to me to understand <em>how</em> Darwin exposed his theory, how he actually practiced science and conveyed scientific truth.</p>
<h2 id="book-structure">Book Structure</h2>
<p>The book is structured in three unequal parts. The first part introduces the concept of <em>variations</em> in the morphology, habits, behaviours, and structure of living beings, and explains how even seasoned naturalists have a hard time defining the boundary of species or varieties precisely. It exposes the central problem Darwin is trying to solve, namely why those variations happen and how species and varieties are shaped.</p>
<p>The second part defines Darwin’s <em>Natural selection</em> theory, its various constitutive principles -<em>Survival of the fittest</em>, random variations, sexual selection - and how this theory explains the formation and <em>evolution</em> of all living beings.</p>
<p>The third and longest part is a careful and systematic analysis of facts that potentially contradict the <em>Natural selection</em> principle, from the question of how instinctual behavior of neutered individuals could possibly be inherited, to the question of geographical distribution of related species, through difficulties stemming from findings in fossils and geological records. The conclusion summarises Darwin’s findings, theory and arguments that support it.</p>
<h2 id="natural-selection">Natural Selection</h2>
<p>Darwin’s theory, namely <em>Natural selection</em>, is thus named by analogy with how humans select domestic animals and plants for their greater benefits. Its principles can be summarised by the following “laws”:</p>
<ul>
<li>Living organisms, through reproduction, tend to <em>proliferate</em> and grow in numbers which, when left unopposed, leads to population explosion,</li>
<li>This tendency is counterbalanced by <em>high mortality rate</em> stemming from intense competition for resources within an ecosystem, both within species and among species, with an infinite variation of complex relationships from the simple prey/predator to symbiosis, parasitism or even relations involving several species,</li>
<li>This intense competition leads to <em>survival of the fittest</em>, whereby individuals use the slightest advantage they have “acquired” that can provide them an edge and higher survival rate,</li>
<li>Such <em>variations</em> appear constantly within species (we would call them <em>mutations</em>), sometimes minute, sometimes spectacular, in a random and unpredictable way,</li>
<li>Variations appear more often in less specialised or useful features or organs, or highly “exotic” ones like the peacock’s tail, the rooster crest or other “ornaments”,</li>
<li>Furthermore, if a feature has varied, it is more likely to vary,</li>
<li>“Survival of the fittest” principle will thus preserve variations which provide an edge in the competition, and reproduction, under normal circumstances, allow passing those variations to descendants of survivors,</li>
<li><em>Sexual selection</em> is a secondary principle that ensures individuals carrying beneficial variations will have a higher reproduction rate, increasing the likelihood of preserving an advantage over the next generations.</li>
</ul>
<p><em>Natural selection</em> is a term that summarizes those complex interactions occurring within a specific biotope between all the living beings, leading to <em>evolution</em> of species towards better <em>adaptation</em> to the milieu and to other species, which species in return affect the milieu through their constant evolution (think for example of how plants evolve in reaction to changes in the diet of animals and the increase in herbivorous population).</p>
<p>The key aspect of <em>Darwinism</em> and the one that sparked and still sparks most controversy is the fundamentally random nature of the <em>variations</em>. We now know those variations mostly result from gene mutations but those mutations are still mostly random, or at least unpredictable, and <em>Nature</em> acts much like a farmer does by selecting the best variations, the ones providing a competitive advantage, over the others. The appearance of “intelligent design” or “masterplan” comes from our very narrow view and the difficulties we are having intellecting the unfathomable spans of time which <em>Nature</em> has at its disposal to act: When we contemplate the beauty of the interaction of bees and flowers, the intricacies of ants’ social life, or the perfection of the jaguar, we forget they are the result of tens or hundreds of millions of years of constant minute variations and selection, accumulated over millions of generations.</p>
<h2 id="why-we-must-read-darwin">Why we must read Darwin</h2>
<p>This book is a great read for many reasons which can be condensed by saying it’s the epitome of scientific writing. For the detail-inclined among us, here is what I put behind those vague words:</p>
<ul>
<li>It’s written without much jargon, or at least a jargon that has become mainstream over the past 150 years. Darwin does not make use of footnotes, or any kind of notes for that matter, even though he provides a bibliography at the end of the book albeit structured somewhat informally and without exact references, which from the point of view of the reader avoids constant back and forth between body and appendices one is forced to go through when reading modern scholarly texts,</li>
<li>It’s filled with abundance of concrete examples illustrating various points of the theory or thorny problems it is facing, from the innumerable variations of the pigeons to the sophisticated behaviour of ants, through the problems posed by the dissemination of terrestrial species, both plants and animals across large bodies of water,</li>
<li>A lot of examples come from personal observations and concrete experiences run by Darwin himself over the 20 or 25 years preceding the publication of his book, as well as from the wealth of publications and personal communications from other scholars all around the world, which demonstrates Darwin was not only a brilliant mind but first and foremost an empiricist who spent his life collecting facts and observations, and a scientist embedded in a complex web of relations, discussions, controversy with his peers,</li>
<li>Darwin always adopts a humble stance when presenting his ideas and the facts supporting it. He never says “This is the truth and you must believe” but instead repeats “those facts appear to me to support my theory” or “No other theory (fixism) can explain all the facts consistently”,</li>
</ul>
<p>Most importantly, he spends about two-third of his book exposing, analysing every possible problem arising from facts and theories of the sciences of his time, geology, anatomy, botanics, zoology, geography, putting in practice what would be theorised seventy years later by <a href="https://en.wikipedia.org/wiki/Karl_Popper">Karl Popper</a> as <em>empirical falsification</em>: What makes a theory <em>scientific</em> is that it can potentially be disproven by facts, through empirical research and experiments. Hence the emphasis Darwin puts on examining facts that could contradict his theory.</p>
<p>A common rebuttal of evolutionism is the fact we have very little evidence or sequence of variations of a species from fossils, something which has been used by creationist as a “proof” that species were actually created once and for all. But Darwin demonstrates that when it comes to geological evidences, we are like the drunkard who looks for his keys under the gaslight: We infer theories from a very narrow view of the world, not taking into account the thousands or millions of years that can separate fossiliferous layers, the very peculiar conditions that are needed for fossils to accumulate (sedimentation of material, shallow and slowly receding bodies of water, climatic conditions in arctic lands…), in other words how spotty and sketchy our evidence are. But from those few and far between pieces of evidence, we can still detect the effect of natural selection and continuous variations which supports the “simplest” explanation.</p>
<p>At least, next time Jehovah’s Witnesses ring at my door and want to discuss why Darwinism is wrong, and how God created the Earth and all the living beings populating it around 6000 BC, I will feel armed and prepared to counter every argument, given they are basically unchanged since Darwin’s time, more than 150 years ago.</p>
<p><strong>NOTE</strong>: Being a developer, I have tried to encode Darwin’s theory into a simple <a href="https://gitlab.com/abailly/origin-of-species">command-line application</a> showing the evolution of species on a “planet” with varying biotopes.</p>
<p><strong>NOTE 2</strong>: Many thanks to <a href="https://www.linkedin.com/in/anna-savarin/?originalSubdomain=fr">Anna Savarin</a> for the proofreading!</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Une histoire des inégalités&quot;</title>
    <link href="http://abailly.github.io/posts/histoire-des-inegalites.html" />
    <id>http://abailly.github.io/posts/histoire-des-inegalites.html</id>
    <published>2021-06-08T00:00:00Z</published>
    <updated>2021-06-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Une histoire des inégalités&quot;</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on June  8, 2021</div>

<p>Le succès du <a href="https://www.seuil.com/ouvrage/le-capital-au-xxie-siecle-thomas-piketty/9782021082289">Capital au XXIème siècle</a> de Thomas Piketty a remis à l’ordre du jour la question des inégalités économiques, de leur justification, de leur évolution, et de la manière de lutter contre leur extension voire de les réduire. <a href="https://www.seuil.com/ouvrage/capital-et-ideologie-thomas-piketty/9782021338041">Capital et idéologie</a> du même auteur, s’intéresse d’ailleurs plus précisèment à la manière dont différentes sociétés justifient, ou pas, les inégalités et leurs trajectoires dans différents pays au cours du siècle précédent.</p>
<p>Au delà du débat entre intellectuel·le·s, la question des inégalités provoque secousses politiques, tensions sociales et violences dans de nombreux pays, parfois de manière apparemment paradoxale. Tandis qu’en France, société relativement égalitaire comme la plupart des pays d’Europe continentale, les <em>Gilets Jaunes</em> ont porté pendant de longs mois la revendication d’une société plus égalitaire et plus juste ; aux USA, pays développé le plus inégalitaire, l’épisode <em>trumpiste</em> s’est achevé (temporairement ?) par la prise d’assaut du Capitole. Il peut paraître étrange de rapprocher ces deux mouvements, mais il me semble qu’ils sont les archétypes de deux réactions possibles du corps social face à des inégalités de capital et de revenu croissantes considérées comme illégitimes, comme issues de <em>captation de la rente</em> par des élites dont plus rien ne justifie la domination.</p>
<p>Le livre de Walter Scheidel, <a href="https://www.actes-sud.fr/catalogue/une-histoire-des-inegalites">Une histoire des inégalités</a>, sous-titré <em>de l’âge de pierre au XXIème siècle</em>, semble tomber à point pour essayer de comprendre d’où viennent ces inégalités et comment, historiquement, elles ont évolué. Plus précisèment, W.Scheidel étudie les différentes causes de réduction des inégalités observées au cours de l’histoire sur le <em>temps long</em>, comme le sous-titre l’indique. Disons le d’emblée : ce n’est guère réjouissant ! La thèse principale du livre, étayée par des années de recherche et une bibliographie de <em>67</em> pages, est que les inégalités économiques n’ont pu être sensiblement et durablement réduites que par l’effet d’un ou plusieurs des <em>quatre cavaliers</em> comme les nomme Scheidel : la guerre de masse, les révolutions transformatrices, l’effondrement des états et les pandémies. Les périodes de paix et de stabilité institutionnelles prolongées ont toutes eu pour effet d’accroître les inégalités, parfois jusqu’à des niveaux stratosphériques.</p>
<h2 id="le-livre">Le livre</h2>
<p>Le livre est divisé en sept parties : une histoire des inégalités, puis quatre parties consacrées chacune à l’un des “cavaliers”, la guerre, la révolution, l’effondrement et la pandémie, une sixième partie consacrée aux “autres solutions” pour réduire les inégalités, enfin une dernière partie pour l’état des lieux actuels et un exercice de prospective. Un appendice est dévolu à une analyse théorique des limites de l’inégalité et, partant, des possibilités de comparaisons entre époques.</p>
<p>Le contenu est typique des livres grands publics issus de travaux universitaires : bien écrits, denses, parfois un peu répétitifs dans l’égrénage des statistiques et des différents cas étudiés, et bourrés de notes de bas de pages renvoyant à la copieuse bibliographie, le tout sur un peu plus de 750 pages. Les chapitres sont découpés en sections dont les titres sont systématiquement des citations d’origines, comme celle-ci</p>
<blockquote>
<p>Ainsi furent-ils tous détruits</p>
</blockquote>
<p>qui est tirée de la <a href="https://gallica.bnf.fr/ark:/12148/bpt6k1121746.texteImage">Chronique des quatre premiers Valois</a> et parle de la jacquerie de 1358.</p>
<h3 id="la-guerre">La guerre</h3>
<p>La partie sur la guerre est la plus longue, sans doute parce que les événements relatés sont proches de nous et nous en ressentons encore les effets, et aussi parce que l’impact des deux guerres mondiales sur les inégalités a certainement été l’un des plus massifs qui se soit jamais observé dans toute l’histoire humaine, au point que la période 1914-1950 soit nommée <em>La grande compression</em>.</p>
<p>Seules les guerres totales du XXème siècle ont réduit les inégalités de manière significative. À elle seule, la guerre n’est pas un vecteur d’égalisation et aurait même tendance à renforcer les inégalités comme le montrent les conséquences des innombrables guerres de conquêtes de l’histoire. Ceci vaut y compris pour des guerres civiles, même de grande ampleur comme le fût la guerre de Sécession américaine : la libération des esclaves sans indemnités a certes constitué une forme de “destruction de capital” importante mais n’a pas vraiment eu d’impact à long terme sur les inégalités, les esclaves libérés se transformant en ouvriers agricoles mal payés.</p>
<p>Si les guerres du XXème sont parvenues à un tel résultat, ce n’est pas uniquement du fait des destructions massives de capital et des immenses pertes humaines qu’elles ont causées. La guerre de masse implique une mobilisation de masse qui n’est possible et acceptable, en particulier dans les régimes démocratiques, que si les gouvernements et les dominants sont prêts à faire des concessions aux dominés. Par ailleurs, les immenses besoin en main d’oeuvre et capital impliquent un contrôle étroit de l’État, une mobilisation des capitaux et de toutes les ressources qui nécessairement impactent beaucoup plus les riches que les pauvres.</p>
<p>L’effet égalisateur de la mobilisation en masse et de la conscription universelle ne se retrouve, en dehors du XXème siècle, que dans une société connue : la Grèce classique dex Vème-IVème siècles avant l’ère chrétienne. Bien sûr, l’égalité ne concernait que les citoyens et donc pas les esclaves ni les femmes, mais dans cette catégorie l’égalité était réelle et a perduré à Athènes sur deux siècles environ, quand elle a périclité assez vite à Sparte.</p>
<p>J’ajouterai, bien que l’auteur n’en parle pas, qu’Israël au moins à ses débuts pourrait constituer un autre exemple d’une société dont l’égalitarisme est le produit de la guerre, conçu comme un état permanent et impliquant l’ensemble des citoyens.</p>
<p>Les effets égalisateurs de la guerre de masse ont été observés y compris dans des pays qui n’étaient pas belligérants comme la Suède, la Suisse ou la péninsule espagnole. Il n’y a que dans des pays éloignés du conflit, en Amérique du Sud, que la déségalisation s’est poursuivie .</p>
<p>Le cas du Japon est étudié en détail par Scheidel, et permet d’apprendre que l’égalisation déjà à l’oeuvre du fait de l’effort de guerre a été amplifiée par les politiques redistributives - distribution des terres, sécurité sociale, compression des salaires, impôt extrêmement progressif - mises en oeuvre sous l’impulsion des vainqueurs, autrement dit les américains qui eux-mêmes à l’époque ont mis en place de telles mesures.</p>
<h3 id="la-révolution">La révolution</h3>
<p>Les révolutions communistes du XXème siècle, russes, chinoises, vietnamiennes et autres, ont été elles aussi très efficaces pour égaliser revenus et patrimoines : en URSS et dans la Chine communiste quelques années après la prise de pouvoir, le <a href="https://en.wikipedia.org/wiki/Gini_coefficient">coefficient de Gini</a> des revenus utilisé par l’auteur comme principal outil de mesure des inégalités, était tombé autour de 20% soit parmi les taux les plus bas jamais observés.</p>
<p>Il est certain que la <em>Grande compression</em> d’après-guerre dans les pays occidentaux et la mise en place de mesures sociales sans précédent est aussi le résultat de la <em>Guerre froide</em>, un moyen de lutter contre la contagion révolutionnaire.</p>
<p>Comme pour a guerre, en dehors du XXème siècle, les révoltes et révolutions n’ont jamais produit d’effet significative et durable sur les inégalités. Curieusement, ce constat est vrai même pour la <em>Révolution française</em> qui a été “timorée” et n’a jamais remis en cause la propriété privée comme l’ont fait les révolutions communistes, ce qui a eu pour conséquence de ne modifier les inégalités qu’à la marge.</p>
<p>Et comme le souligne la citation ci-dessus, toutes les autres révoltes, jacqueries, guerre des pauvres, émeutes connues ont échouées à changer quoi que ce soit ayant été la plupart du temps écrasées dans le sang, y compris en Asie où la <a href="https://fr.wikipedia.org/wiki/R%C3%A9volte_des_Taiping">révolte des Taiping</a>, qui a pourtant causé la mort de 30 à 50 millions de personnes.</p>
<h3 id="leffondrement">L’effondrement</h3>
<p>De nombreux effondrements d’États ont eu lieu au cours de l’histoire dont on sait qu’ils ont produit une diminution des inégalités: Cités-États et royaumes mésopotamiens (Ur, Akkad, Sumer), royaumes mycéniens et crétois, empires mayas, empire romain sont quelques exemples détaillés par Scheidel. Mais les exemples modernes et contemporains sont beaucoup plus rares, voire presqu’absents. Seules la Somalie après la chute du dictateur Siyad Barre semble présenter les caractéristiques d’un effondrement total ayant engendré une diminution des inégalités du fait de l’éviction d’une élite prédatrice.</p>
<p>Ce lien entre inégalité et État, ou entre égalité et absence de pouvoir central, a aussi été mis en avant par les travaux de James C. Scott notamment dans <a href="https://yalebooks.yale.edu/book/9780300182910/against-grain">Against the Grain</a> qui montre l’extraordinaire faiblesse des premiers états agricoles du Croissant fertile. Les élites militaires de ces États ne disposaient pas des moyens dont disposeraient leurs descendants pour imposer sur le long terme leur pouvoir à des populations toujours enclines à fuir le pouvoir central, l’exploitation, sujettes à des épidémies meurtrières et à des guerres de conquêtes destructrices.</p>
<h3 id="lépidémie">L’épidémie</h3>
<p>L’humanité et les civilisations ont été confrontées très tôt aux épidémies, en fait dès les débuts de l’agriculture et de la domestication d’animaux. Dans <a href="https://en.wikipedia.org/wiki/Guns,_Germs,_and_Steel">Guns, Germs and Steel</a> J.Diamond émet l’hypothèse que l’exposition à des maladies plus sérieuses, plus vite, à plus grande échelle a été l’une des raisons principale de l’émergence précoce d’États plus structurés, plus puissants, bref de la civilisation sur le continent euriasiatique.</p>
<p>La plupart des épidémies ayant eu un impact significatif sur les inégalités ont eu lieu dans la haute antiquité, mais il en est néanmoins quelques unes plus récentes auxquelles W.Scheidel a pu attribuer un impact considérable, essentiellement des épidémies de <em>peste</em> : la peste antonienne au IIème siècle, la peste justinienne au VIème qui a causé la division par 2 ou 3 de la population de Byzance, et surtout la <a href="https://fr.wikipedia.org/wiki/Peste_noire">Peste Noire</a> qui a démarré au XIVème siècle et a connu des répliques de moindre ampleur jusqu’au XVIIème.</p>
<p>Cette pandémie qui a aussi sévi dans une moindre mesure en Asie a causé la mort de 30 à 50% selon les pays de la population européenne et méditerranéenne. Ses effets sur les inégalités sont assez bien documentés notamment en Angleterre, ont été massifs mais n’ont duré qu’environ 1 siècle : du fait de la disparition de la main d’oeuvre dans une société essentiellement agricole les salaires ont augmenté, parfois considérablement, au point que certains gouvernements ont voulu légiférer et limiter les salaires des journaliers et artisans ; des produits qui étaient auparavant réservés à une élite (viande, fourrures, animaux) se sont diffusés dans une plus large fraction de la population ; le commerce international s’est effondré ce qui a particulièrement touché les fractions les plus riches de la population.</p>
<h3 id="mesurer-les-inégalités">Mesurer les inégalités</h3>
<p>Dans ses livres, aussi bien <a href="">Le capital au XXIème siècle</a> qu’<a href="">Idéologie et capital</a> T.Piketty critique l’usage trop exclusif du coefficient de Gini comme mesure des inégalités et lui préfère un instrument plus précis : la distribution des richesses, revenus ou patrimoine, par décile ou par centile. Un même coefficient de Gini peut en effet être produit par des distributions différentes des inégalités relatives.</p>
<p>C’est pourtant cette mesure que W.Scheidel retient, essentiellement parce qu’il est très difficile de reconstruire pour des sociétés anciennes, et même pour certaines sociétés modernes, ces distributions de revenus.</p>
<p>Mais il introduit aussi une autre mesure, très intéressante, qu’il appele le <em>taux d’extraction</em> soit le pourcentage du maximum d’inégalité possible dans un contexte économique donné. Ce taux est <em>relatif</em> à un niveau de revenu par habitant donné : intuitivement, plus une économie est riche, plus le potentiel d’inégalité est élevé, les dominants ayant la possibilité de capter de plus grandes richesses à leur profit. La limite basse est constituée par le seuil de subsistance : même dans les société les plus inégalitaires, les pauvres doivent survivre pour continuer d’être exploités par les riches.</p>
<p>La relation entre maximum d’inégalité et revenu par habitant définit une frontière des inégalités : une société sera d’autant plus inégalitaire qu’elle sera proche de cette frontière. Toutes les sociétés modernes issues de la <em>Grande compression</em> sont loin de cette frontière.</p>
<p>Les choses deviennent moins nettes lorsqu’on prend comme base non plus le revenu de subsistance absolu, soit 300$ de 1990, mais un niveau relatif par exemple le seuil de pauvreté. Mécaniquement, le taux d’inégalité maximal diminue et le <em>Taux d’extraction</em> augmente rapprochant les économies modernes les plus égalitaires comme les USA ou le Royaume-uni de sociétés anciennes très inégalitaires comme l’angleterre victorienne, la Florence du quattrocento ou même l’empire romain.</p>
<h3 id="les-égalisateurs-pacifiques">Les égalisateurs “pacifiques”</h3>
<p>La dernière partie du livre consacrée à l’analyse des moyens “non-violents” de réduire les inégalités dont on a pu mesurer les effets est assez déprimante et se résume aisément : il n’y a aucun exemple d’une société ayant réussi à réduire significativement et durablement les inégalités par des réformes pacifiques. Tous les cas cités par l’auteur, notamment ceux de réformes agraires dans des sociétés post-coloniales, sont toujours sous-tendus par la <em>menace de la violence</em> interne ou externe.</p>
<p>Malicieusement, W.Scheidel ne manque de faire remarquer que les innombrables propositions de sommités intellectuelles mondiales, y compris T.Piketty, pour réduire massivement les inégalités sont pour la plupart d’entre elles concrètement inapplicables.</p>
<p>Ce qui pose bien sûr la question de l’avenir des inégalités que nous connaissons actuellement et dont on sait qu’elles ont cru depuis 30 ou 40 ans. Et poser la question c’est déjà d’une certaine manière y répondre…</p>
<h2 id="conclusion">Conclusion</h2>
<p>Ce type de livre est toujours impressionant et passionnant par sa capacité à brasser les millénaires, les chiffres, les études savantes, les civilisations les plus diverses et à les intégrer dans un grand récit au service d’une thèse. N’ayant ni la capacité ni les moyens de critiquer les données sur lesquelles il s’appuie, et encore moins de reproduire l’analyse comme devrait le faire tout scientifique, je ne peux qu’essayer de comprendre et analyser l’argumentation produite qui, il faut le bien le dire est assez convaincante.</p>
<p>Le grand mérite de ce livre est qu’il pose directement ou indirectement plein de questions, telles que :</p>
<ul>
<li>la croissances des inégalités dans des sociétés stables et en paix est elle consubstantielle à la condition humaine ?</li>
<li>quel prix sommes nous prêts à payer pour réduire durablement et significativement les inégalités ?</li>
<li>accepter sereinement que des centaines de millions de personnes meurent pour réduire les inégalités de revenus ne relève-t’il pas de la sociopathie ?</li>
<li>si l’État centralisé est de toute évidence la source de laquelle naissent les inégalités, pourquoi parvient il toujours à renaître de ses cendres ?</li>
<li>la capitalisme n’a ni inventé, ni modifié significativement la structure globale des inégalités : les USA de 2020 ne sont pas loin d’être aussi inégalitaires que, disons, l’Angleterre médiévale, la Chine des Tang ou l’empire romain. Vaut il mieux accepter une société (très) inégalitaire, mais riche, ou une société plus égalitaire, mais pauvre ?</li>
</ul>
<p>Si le retour de l’un des “quatre cavaliers” paraît peu probable à court terme, il est un <em>cinquième cavalier</em> qui parait tout aussi redoutable aujourd’hui, c’est le risque d’effondrement induit par la destruction de la biosphère. Scheidel identifie des épisodes climatiques exceptionnels comme cause d’effondrement de certaines sociétés (la sécheresse pour les mayas), mais n’évoque pas le <em>changement climatique</em> proprement dit.</p>
<p>Immédiatement après l’avoir fini, j’ai commencé de lire <a href="https://www.raisonsdagir-editions.org/catalogue/sengager-dans-la-guerre-des-classes/">S’engager dans la lutte des classes</a> de L.Denave, un récit de l’intérieur autant qu’un essai sur le mouvement des Gilets Jaunes. L’auteur évoque notamment le refus viscérale de la plupart des GJ de “s’organiser”, de “structurer” le mouvement, d’avoir des représentants ou une hiérarchie. À la lumière d’<em>Une histoire des inégalités</em> je ne peux m’empêcher de penser que tout mouvement prétendant lutter sérieusement contre les inégalités n’a que deux options à sa disposition : fuir pour vider le pouvoir de sa substance, ou prendre le pouvoir par la force ; et doit accepter d’en payer le prix : <em>There Will be Blood</em>.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Haskell + Emacs + Nix</title>
    <link href="http://abailly.github.io/posts/haskell-emacs-nix.html" />
    <id>http://abailly.github.io/posts/haskell-emacs-nix.html</id>
    <published>2021-02-02T00:00:00Z</published>
    <updated>2021-02-02T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Haskell + Emacs + Nix</h1>

  <h2 class="subtitle">Making of sense of Nix for Haskell development</h2>

<div class="info">Posted on February  2, 2021</div>

<p>In a <a href="a-modern-haskell-env.html">previous post</a> I detailed how to set up a LSP server for Haskell using Emacs as client. Now, despite my good friend Sam Halliday’s <a href="https://levelup.gitconnected.com/delivering-with-haskell-a347d8359597">advice</a>, I wanted to add Nix in the mix. Both <a href="common-dev-environment.html">standardized and shared development environment</a> and reproducibility of such environments are relevant and important. But I could argue that the wealth of virtualization tools available nowadays, from the humble <code>chroot</code> to full-blown virtual machines through containers of all kind, makes it much easier to produce and reproduce identical environments than when nix was started 15 years ago.</p>
<p>There are <a href="https://www.tweag.io/blog/2020-08-20-how-nix-grew-a-marketing-team/">teams</a> and people in the Haskell community that support and use nix, and I wanted to get my feet wet and taste the water, to see how it feels to develop using nix. This short essay reports on my experience so far trying to:</p>
<ul>
<li>Set up a development environment for Haskell code based on Nix, Emacs and LSP,</li>
<li>Nixify a cabal-based Haskell project.</li>
</ul>
<p>I wouldn’t have succeeded in this endeavor but for the support of fine people from the <a href="https://fpchat-invite.herokuapp.com/">Functional Programming Slack</a> community, the <a href="https://funprog.srid.ca/">FP Zulip</a> community, and online documentation:</p>
<ul>
<li>IOHK’s <a href="https://input-output-hk.github.io/haskell.nix">Haskell &amp; Nix Tutorial</a> which covers the <a href="https://github.com/input-output-hk/haskell.nix/">haskell.nix</a> infrastructure,</li>
<li>nixpkgs <a href="https://haskell4nix.readthedocs.io/">Haskell infrastructure</a> guides, although they are somewhat conflicting with the former,</li>
<li><a href="https://nixos.org/guides/nix-pills">Nix Pills</a> which are invaluable to better understand how nix is working.</li>
</ul>
<p>Please note the source code for provisioning a virtual machine with such an environment is available on <a href="https://github.com/abailly/nix-haskell-dev-vm">GitHub</a>.</p>
<h1 id="configure-emacs-and-lsp">Configure Emacs and LSP</h1>
<p>The tricky bits for me was to configure Emacs in such a way that when it opens a <code>*.hs</code> file it automatically fires up <code>lsp-mode</code> and connects to the <em>right version</em> of the <a href="https://github.com/haskell/haskell-language-server">Haskell Language Server</a>. As explained on HLS’s GitHub page, the LSP client must connect to a LSP server that’s compiled with the correct GHC version and uses the correct dependencies. In Emacs’ <code>lsp-mode</code> this is normally done through the use of the binary program <code>haskell-language-server-wrapper</code> which will itself spawn the correct version of <code>haskell-language-server</code> binary depending on the project’s configuration which can be given by a <code>stack.yaml</code> file or a <code>xxx.cabal</code> file.</p>
<p>The Nix way of providing such a configuration is to set the dependencies in a context-specific way, using a <code>default.nix</code> which will be picked up by all nix tools when we don’t provide them a specific file containing a nix expression to evaluate. Then a <code>shell.nix</code> file references the <code>default.nix</code> as its sources for packages and gives the user a customized shell updated with whatever packages it exposes. Note that in this case, there is no need to provide a wrapper over <code>haskell-language-server</code> because, by virtue of Nix providing a customised environment through a fixed set of packages, the “correct” HLS version will be installed, as explained in this <a href="https://github.com/input-output-hk/haskell.nix/pull/1015#issuecomment-768160999">PR Comment</a>. There is a section on <a href="https://input-output-hk.github.io/haskell.nix/tutorials/development/#emacs-ide-support">configuring Emacs</a> in haskell.nix doc but it applies to Dante and not LSP.</p>
<p>So we need to configure Emacs to:</p>
<ol style="list-style-type: decimal">
<li>Use <code>haskell-language-server</code> as the name of the executable for Haskell LSP server,</li>
<li>And more importantly, use the environment provided by <code>nix-shell</code>.</li>
</ol>
<p>The latter could be achieved by wrapping the HLS invocation in <code>nix-shell</code> but <a href="https://direnv.net/">direnv</a> seems to be the way to go as it provides a declarative way of setting up Nix on a per-directory basis. In my case, it amounts to:</p>
<ul>
<li>Write a <code>.envrc</code> file containing a single line, <code>use nix</code>, at the top level of the project’s directory,</li>
<li>Configure Emacs to use <code>direnv-mode</code>: <code>(use-package direnv :ensure t :config (direnv-mode))</code></li>
</ul>
<p>When emacs now visits a file located in the project’s directory or one of its sub-directories, <code>direnv-mode</code> will kick in and set the current environment, and most notably the <code>exec-path</code> according to the instructions given in <code>.envrc</code> which here means executing <code>nix-shell</code>. However, this did not work out-of-the-box and took me some time to understand why. The LSP client that <code>lsp-mode</code> runs kept saying it could not find an LSP server implementation for my language, even though I could assert that:</p>
<ol style="list-style-type: decimal">
<li><code>direnv</code> was working and ran nix-shell to setup the environment,</li>
<li><code>haskell-language-server</code> was installed in the shell and available from the ambient <code>PATH</code>.</li>
</ol>
<p>It turned out the problem seemed to be caused by a <em>race condition</em> between the LSP client and the <code>direnv</code> setup: The LSP client tries to connect to the server before the environment is properly setup which happens because entering <code>nix-shell</code> takes a few seconds. <em>Deferring</em> the connection attempt until the point where the file is properly loaded fixed this issue, leading to this LSP configuration:</p>
<pre><code>(use-package lsp-mode
  :ensure t
  :hook ((haskell-mode . lsp-deferred))
  :commands (lsp lsp-deferred))

(use-package lsp-haskell
  :ensure t)</code></pre>
<h1 id="speed-up-nix">Speed-up Nix</h1>
<p>So I have a nice and working Nix/Haskell/Emacs/LSP configuration setup for my project, but there’s a major issue: <code>haskell.nix</code> does not provide a cache of the packages it exposes derivation for, which means everything must be rebuilt from scratch every time I destroy and recreate the VM. And as the <code>default.nix</code> configuration retrieves its packages from the <code>master</code>, every time we enter <code>nix-shell</code> we run the risk of having to update some depedencies which might take ages.</p>
<p><a href="https://input-output-hk.github.io/haskell.nix/tutorials/getting-started/#pinning-the-haskellnix-version">Pinning down</a> the version of the packages used remediates the second problem, so we are left with the question of caching the binaries built by Nix in such a way as to be able to share them across different VMs. Enters <a href="https://cachix.org/">cachix</a> which is a hosted service with a free 10GB (!) tier specifically built to cache Nix derivations’ output. After having created an account and a cache instance called <code>hydra-sim</code>, I installed and configured <code>cachix</code> on the development environment, and then could push/pull binaries produced.</p>
<p>Local configuration requires the following steps:</p>
<p>Install cachix which is most easily done through nix:</p>
<pre><code>nix-env -iA cachix -f https://cachix.org/api/v1/install</code></pre>
<p>Assuming nix is installed globally and runs as a daemon, the user running <code>cachix</code> must be authorized to create and manipulate caches. This is defined in <code>/etc/nix/nix/.conf</code> which looks like:</p>
<pre><code>max-jobs = 6
cores = 0
trusted-users = root curry
substituters = https://cache.nixos.org https://hydra.iohk.io https://iohk.cachix.org
trusted-public-keys = iohk.cachix.org-1:DpRUyj7h7V830dp/i6Nti+NEO2/nhblbov/8MW7Rqoo= hydra.iohk.io:f/Ea+s+dFdN+3Y/G+FDgSq+a5NEWhJGzdjvKNGv0/EQ= cache.nixos.org-1:6NCHdD59X431o0gWypbMrAURkbJ16ZPMQFGspcDShjY=</code></pre>
<p>Retrieve an authentication token for the <code>hydra-sim</code> cache from cachix and configure local environment to use it:</p>
<pre><code>cachix authtoken &lt;the token&gt;</code></pre>
<p>Finally, use the cache</p>
<pre><code>cachix use hydra-sim</code></pre>
<p>Pushing to the cache can be done from the output of the project’s build</p>
<pre><code>$ nix-build -A hydra-sim | cachix push hydra-sim</code></pre>
<p>and using the <a href="https://fzakaria.com/2020/08/11/caching-your-nix-shell.html">nix-shell configuration</a>. This is important as it means the tools, and most notably <code>haskell-language-server</code>, will be part of the cache:</p>
<pre><code>nix-store --query --references $(nix-instantiate shell.nix) | \
     xargs nix-store --realise | \
     xargs nix-store --query --requisites | \
     cachix push hydra-sim</code></pre>
<h1 id="conclusion">Conclusion</h1>
<p>This is the beginning of my journey in Nix-land and it’s a bit early to say whether I like the tool or not. Right now, it seems like a bit of time-waste as I have spent several hours scattered over a week to get my environment “right” using Nix on a dedicated VM, where doing this using the standard tools provided by Haskell to install packages and utilities, namely <a href="https://www.haskell.org/ghcup/">ghcup</a> and <a href="https://cabal.readthedocs.io/en/3.4/index.html">cabal</a>, took me approximately twenty minutes.</p>
<p>As is often the case with non-mainstream open source tools, there is a lot of information “out there” written by enthusiastic people like tutorials, guides, and blog entries. This information is often fragmentary, dependent on a specific environment, operating system, component of the stack, or specific flavor of the tools. Hence one has to invest time to recombine those fragments in a way that suits his or her needs and taste. This implies investing time in understanding <em>how</em> those tools work in order to be able to tweak configuration and parameters, which might gives one that <a href="https://www.urbandictionary.com/define.php?term=yak%20shaving">yak shaving</a> feeling.</p>
<p>Yet when I compare that experience with my past year working mostly with proprietary or semi-proprietary language and tools (C#, Windows, Visual Studio, Citrix, <a href="https://www.appeon.com/products/powerbuilder">Powerbuilder</a>), I wouldn’t want to go back at any price. When something is wrong in proprietary land, you don’t even get a chance to understand <em>what</em> is wrong, you are dependent on the whims of a software publisher. The time that’s gained in shrinkwrapped tooling and environments, pre-packaged components, guided processes, is valuable only in the short-term at the onset of a project. As soon as <em>essential complexity</em> of the business domain creeps in, the abstraction barriers the proprietary tooling carefully built to hide implementation details breaks, leaving the hapless developer struggling with patches, workarounds, opaque procedures to get things done.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>

</feed>
