<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Arnaud Bailly's  Blog</title>
    <link href="http://abailly.github.io/atom.xml" rel="self" />
    <link href="http://abailly.github.io" />
    <id>http://abailly.github.io/atom.xml</id>
    <author>
        <name>Arnaud Bailly</name>
        <email>arnaud@igitur.io</email>
    </author>
    <updated>2017-04-02T00:00:00Z</updated>
    <entry>
    <title>Weekly Review - Week 13</title>
    <link href="http://abailly.github.io/posts/weekly-review-13.html" />
    <id>http://abailly.github.io/posts/weekly-review-13.html</id>
    <published>2017-04-02T00:00:00Z</published>
    <updated>2017-04-02T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Weekly Review - Week 13</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on April  2, 2017</div>

<dl>
<dt><a href="https://blog.acolyer.org/2017/03/27/ethically-aligned-design/">Ethically aligned design | the morning paper</a></dt>
<dd><p>Another interesting post from <em>The Morning Paper</em>, this time about ethics and software. This resonates with some discussions we have had at latest Software Craft(wo)manship. Reading the paper I was attracted to ….</p>
</dd>
<dt><a href="https://www.amazon.com/Moral-Machines-Teaching-Robots-Right/dp/0199737975">Moral Machines: Teaching Robots Right from Wrong: Wendell Wallach, Colin Allen</a></dt>
<dd><p>… but some reviews I read dettered me from buying it. I will try to dig into the subject a little bit more and look for some relevant texts (beside Kant, of course)</p>
</dd>
<dt><a href="/posts/simone-responsabilite.html">Celui qui appuie sur le bouton est-il le seul coupable ?</a></dt>
<dd><p>My notes on the afternoon spent under the wise guidance of <a href="http://peggyavez.com/">Peggy Penet-Avez</a> (aka. <a href="http://simoneetlesphilosophes.fr/">Simone</a>) thinking my way across the concepts of intention, action, responsibilit, guilt…</p>
</dd>
<dt><a href="http://dev.null.org/dadaengine/">The Dada Engine</a></dt>
<dd><p>A well known post-modern articles generator. Stemmed from a discussion on the obscurity of Lacan which is the basis of <a href="https://s3-us-west-2.amazonaws.com/vulk-blog/ThePervertsGuidetoComputerProgramming-ThePaper.pdf">The Perverts’ guide to computer programming</a>.</p>
</dd>
<dt><a href="https://blog.acolyer.org/2017/03/29/deepcoder-learning-to-write-programs/">DeepCoder: Learning to write programs</a></dt>
<dd><p>Recurrent/Convolution neural networks that “learn” to write programs from input/output samples. Interestingly, the program generated are pure functional expressions…</p>
</dd>
<dt><a href="https://github.com/donnemartin/system-design-primer">donnemartin/system-design-primer: Learn how to design large-scale systems</a></dt>
<dd><p>A huge set of links on system design</p>
</dd>
<dt><a href="https://github.com/idris-lang/Idris-dev/blob/master/docs/st/introduction.rst">Idris-dev/introduction.rst at master</a></dt>
<dd><p>A new Idris tutorial on the use of ST, a type for modelling state-machines.</p>
</dd>
<dt><a href="https://hexdocs.pm/ex_unit/ExUnit.Case.html#describe/2">ExUnit v1.4.2</a></dt>
<dd><p>Had to understand Elixir’s unit testing framework while we were pairing with Bernard on a barrel-db demo.</p>
</dd>
<dt><a href="http://2013.ruleml.org/presentations/UniLFS-DumitruRoman.pdf">PowerPoint-Präsentation - UniLFS-DumitruRoman.pdf</a></dt>
<dd><p>A deck on RuleML, a language to model business process rules</p>
</dd>
<dt><a href="https://nim-lang.org/">Nim Programming Language</a></dt>
<dd><p>Another link stemming from a discussion on the <em>Artisans du logiciel</em> Slack. An statically typed imperative language (formerly known as Nimrod)</p>
</dd>
<dt><a href="https://www.reddit.com/r/spacemacs/comments/4a62la/magit_tutorial/">Magit tutorial? : spacemacs</a></dt>
<dd><p>Not only did I have to program in Elixir (a dynamically typed language…), but I had to do it in Spacemacs! We found the experience to be somewhat painful because of some lag in pressing the <code>Esc</code> key, an issue which is solved by <a href="https://github.com/syl20bnr/spacemacs/issues/5413">this post</a>. Here is the final tmux configuration we use:</p>
<pre><code> set -g prefix C-a
 set -g default-terminal &quot;screen-256color&quot;
 set -g mode-mouse on
 set -g mouse-resize-pane on
 set -g mouse-select-pane on
 set -g mouse-select-window on
 set -s escape-time 0
 set-option -g default-shell /bin/zsh</code></pre>
</dd>
<dt><a href="http://stackoverflow.com/questions/10753073/whats-the-theoretical-basis-for-existential-types">Theory of existential types</a></dt>
<dd><p>While preparing a short post on <a href="/posts/existential-types.html">Existential types</a> I stumbled upon this SO answer which provides deeper theoretical insights.</p>
</dd>
<dt><a href="http://web.engr.oregonstate.edu/~erwig/cs582/slides/2.Idris.key.pdf">Understanding Idris</a></dt>
<dd><p>Interesting slide deck on Idris</p>
</dd>
<dt><a href="https://speakerdeck.com/kdaniels/building-bridges-with-effective-devops-1">Building Bridges with Effective Devops</a></dt>
<dd><p>A deck drawn from this weeks’ <a href="http://www.devopsweekly.com/">Devops weekly</a> newsletter on how to build “bridges” across cultures and teams. I was ready to buy the book but the book has mixed reviews on O’Reilly’s site. Insights welcomed.</p>
</dd>
</dl>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Understanding Existential Types</title>
    <link href="http://abailly.github.io/posts/existential-types.html" />
    <id>http://abailly.github.io/posts/existential-types.html</id>
    <published>2017-03-31T00:00:00Z</published>
    <updated>2017-03-31T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Understanding Existential Types</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on March 31, 2017</div>

<p>Existential types are a less well-known extension to Haskell’s type system and Damas-Hindley-Milner type theory, although they are a logical consequence of the identification of type theory with predicate logic: If type variables can be universally quantified then it seems logical they can also be existentially quantified. I have used existential types in Haskell on several occasions but my brain always struggled to really understand what was going on and how to fix the dreaded error messages I got back from the compiler.</p>
<p>While working on <a href="/slides/xxi-century-typed.html">my talk</a> on type-driven development I used existentials to model one of the evolution step of the quizz program I was working on and had some sort of epiphany. This short post is an attempt to capture the insights I gathered in the hope it might be useful for other people.</p>
<h1 id="the-problem">The Problem</h1>
<p>The problem is pretty simple and quite common. A quizz is made up from different <em>types</em> of questions which are part of a quizz, say open questions, multiple choice questions, rating questions. Each question expects a different type of answer: A free text for open questions, selected option for MCQ, a number for rating questions, but the answer is always initially given by the user as a text which must be converted to the right form.</p>
<p>So we have the following (abridged) types of questions:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">OpenQuestion</span> 
<span class="kw">data</span> <span class="dt">MCQuestion</span>
<span class="kw">data</span> <span class="dt">RatingQuestion</span></code></pre></div>
<p>We expose the API of questions as a <em>typeclass</em> in order to be future-proof (we would like to make it easy to introduce new types of questions):</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">class</span> <span class="dt">Questionable</span> q <span class="kw">where</span>
    <span class="kw">type</span> <span class="dt">Answer</span><span class="ot"> q ::</span> <span class="fu">*</span>
    <span class="co">-- other methods omitted....</span>
<span class="ot">    isCorrectAnswer ::</span> <span class="dt">Answer</span> q <span class="ot">-&gt;</span> q <span class="ot">-&gt;</span> <span class="dt">Bool</span></code></pre></div>
<p>and then we need to define a <code>Quizz</code> as a sequence of questions and some functions to compute the answers to the questions and assess the user’s result. The <code>User</code> is simply modelled as a function that provides an answer (or no answer) as a string, given any question.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">User</span> <span class="fu">=</span> <span class="dt">Text</span> <span class="ot">-&gt;</span> <span class="dt">Maybe</span> <span class="dt">Text</span>

<span class="kw">data</span> <span class="dt">Quizz</span> <span class="fu">=</span> <span class="dt">Quizz</span> {<span class="ot"> questions ::</span> [ <span class="dt">Question</span> ] }

<span class="ot">answerQuestion ::</span> <span class="dt">User</span> <span class="ot">-&gt;</span> <span class="dt">Question</span> <span class="ot">-&gt;</span> <span class="dt">Quizz</span> <span class="ot">-&gt;</span> <span class="dt">Quizz</span>
answerQuestion user question quizz <span class="fu">=</span> <span class="fu">...</span>

<span class="ot">answers ::</span> <span class="dt">User</span> <span class="ot">-&gt;</span> <span class="dt">Quizz</span> <span class="ot">-&gt;</span> <span class="dt">Quizz</span>
answers user quizz <span class="fu">=</span>
 foldr (answerQuestion user) quizz (questions quizz)</code></pre></div>
<p>The key issue is then to define <code>Question</code> in such a way that it allows us to work with current (and future) question’s types in a uniform way.</p>
<h1 id="using-existential-type">Using Existential type</h1>
<p>A very simple solution would be to wrap each possible type in a specialized constructor, which in essence amounts to <em>tag</em> each possible <code>Question</code> with its type:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Question</span> <span class="fu">=</span> 
    <span class="dt">MCQ</span> <span class="dt">MCQuestion</span>
  <span class="fu">|</span> <span class="dt">Open</span> <span class="dt">OpenQuestion</span>
  <span class="fu">|</span> <span class="dt">Rating</span> <span class="dt">RatingQuestion</span></code></pre></div>
<p>This solution, while simple to use as it is amenable to direct pattern-matching, suffers from an obvious drawback: It closes the range of available types of questions, or rather makes it difficult to add a new one.</p>
<p>Given that each type of question is assumed to be an instance of the <code>Questionnable</code> interface, we can wrap them using existential quantification in the type <code>Question</code>, using one of the two available syntaxes. The classic data type declaration syntax:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Question</span> <span class="fu">=</span>
  forall q <span class="fu">.</span> <span class="dt">Questionable</span> q <span class="ot">=&gt;</span> <span class="dt">Question</span> q</code></pre></div>
<p>or the GADT-style syntax which explicitly exposes the constructor <code>Question</code> as a function</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Question</span> <span class="kw">where</span>
  <span class="dt">Question</span><span class="ot"> ::</span> <span class="dt">Questionable</span> q <span class="ot">=&gt;</span> q <span class="ot">-&gt;</span> <span class="dt">Question</span></code></pre></div>
<p>The effect of an existential type construction is to limit the scope of the type variable <code>q</code> appearing in the constructor, thus in effect ensuring the question itself, whatever its type, must stay within the scope of its appearance. For example, while it is possible to pattern match on <code>Question</code> to get whatever <code>q</code> is packed inside it, this <code>q</code> cannot be returned. Writing</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">getQ (<span class="dt">Question</span> question _) <span class="fu">=</span> question</code></pre></div>
<p>yields the following, somewhat dreadful, compiler error:</p>
<pre><code>error:
    • Couldn&#39;t match expected type ‘t’ with actual type ‘q’
        because type variable ‘q’ would escape its scope
      This (rigid, skolem) type variable is bound by
        a pattern with constructor:
          Question :: forall q.
                      Questionable q =&gt;
                      q -&gt; Question,
        in an equation for ‘getQ’
        at /Users/arnaud/projects/xxi-typed/haskell/.stack-work/intero/intero2342CZJ.hs:11:7-18
    • In the expression: question
      In an equation for ‘getQ’: getQ (Question question) = question
    • Relevant bindings include
        question :: q
          (bound at /Users/arnaud/projects/xxi-typed/haskell/.stack-work/intero/intero2342CZJ.hs:11:16)
        getQ :: Question -&gt; t
          (bound at /Users/arnaud/projects/xxi-typed/haskell/.stack-work/intero/intero2342CZJ.hs:11:1)</code></pre>
<p>This is so because the type of the result <code>question</code> being <code>question :: q</code> implies that the type variable <code>q</code> becomes <em>free</em> in any context where <code>getQ</code> is used: It escapes the scope of the constructor.</p>
<p>Interestingly, the <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#lexically-scoped-type-variables">ScopedTypeVariables</a> GHC extension gives us the capability to use that <code>q</code>. We can write the following (somewhat contrived) function:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">slug (<span class="dt">Question</span> (<span class="ot">quest ::</span> q) _) <span class="fu">=</span> slugify quest
  <span class="kw">where</span>
<span class="ot">    slugify ::</span> q <span class="ot">-&gt;</span> <span class="dt">Text</span>
    slugify <span class="fu">=</span> T.take <span class="dv">3</span> <span class="fu">.</span> question</code></pre></div>
<p>In the type of <code>slugify</code> we are not forced to expose the constraint <code>Questionable q</code> because the type variable <code>q</code> at this point is the one brought in scope with the expression <code>q :: q</code>.</p>
<h1 id="understanding-existential-types">Understanding Existential Types</h1>
<p>What’s somewhat confusing for the average programmer who has not had a PhD in type theory is: Why are those types called <em>existential</em>? Especially given the fact they are introduced by <code>forall</code> keyword? <a href="http://stackoverflow.com/questions/10753073/whats-the-theoretical-basis-for-existential-types">This StackOverflow</a> does a great job at explaining how (intuitionistic) logic rules relate <span class="math inline">∀</span> and <span class="math inline">∃</span> quantifiers in the case of type constructors.</p>
<p>In short, it comes from the fact that <br /><span class="math display">∀<em>x</em>.<em>Q</em>(<em>x</em>)⟹<em>P</em> = (∃<em>x</em>.<em>Q</em>(<em>x</em>)) ⟹ <em>P</em>.</span><br /></p>
<h1 id="references">References</h1>
<p>There are already a number of resources on the topic:</p>
<ul>
<li>Roman Cheplyaka’s <a href="https://ocharles.org.uk/blog/guest-posts/2014-12-19-existential-quantification.html">24 Days of GHC Extensions</a> does a great job at explaining how existentials work in Haskell</li>
<li>Benjamin Pierce’s <a href="http://www.cis.upenn.edu/~bcpierce/tapl/">Types and Programming Languages</a> has chapter 24 dedicated to the subject of existential types, whose main application is the modelling of object-oriented programming</li>
<li><a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#existentially-quantified-data-constructors">GHC manual</a> of course, gives the fine prints</li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Weekly Review - Week 12</title>
    <link href="http://abailly.github.io/posts/weekly-review-12.html" />
    <id>http://abailly.github.io/posts/weekly-review-12.html</id>
    <published>2017-03-28T00:00:00Z</published>
    <updated>2017-03-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Weekly Review - Week 12</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on March 28, 2017</div>

<p>This post is a summary of my activities related to coding and software in the past week. Its purpose is both to serve as a high-level personal log and as a potential source of interesting (or not so interesting) links. Entries are provided in no particular order with minimal comments…</p>
<dl>
<dt><a href="http://www.grammaticalframework.org/">Grammatical Framework</a></dt>
<dd><p>A fascinating piece of work whose purpose is to provide a way to define unified grammars that can be “linearized” into different languages for the purpose of both parsing and text generation.</p>
</dd>
<dt><a href="https://korewanetadesu.com/emacs-on-os-x.html">Emacs Daemon on Mac OS X</a></dt>
<dd><p>Configuration for running Emacs in server mode which is useful for fast editing of files from the command-line: Run <code>emacsclient foo.txt&amp;</code> and the file’s content is displayed in a buffer in emacs.</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Axel_Honneth">La lutte pour la reconnaissance</a></dt>
<dd><p>Finished reading this book from Axel Honneth, a German philosopher heir to the Frankfurt School. Worthy of some extended blog post…</p>
</dd>
<dt><a href="https://addons.mozilla.org/fr/firefox/addon/org-mode-capture/">Capture org-mode links in Firefox</a></dt>
<dd><p>A nice utility to quickly capture links in Firefox and add them to Emacs’ org-mode</p>
</dd>
<dt><a href="https://github.com/cantino/huginn">Huggin</a></dt>
<dd><p>A tool in Rails to create and manage agents on a personal server, something I have been thinking to setup for a while.</p>
</dd>
<dt><a href="https://syncthing.net/">Syncthing</a></dt>
<dd><p>Open-source system to synchronize several devices</p>
</dd>
<dt><a href="https://vimeo.com/162036084">Types + Properties = Software - Mark Seemann on Vimeo</a></dt>
<dd><p>While working on my talk for <a href="https://www.meetup.com/fr-FR/Crafting-Software/events/238241119/">Crafting Software</a> meetup, I discovered previous work from Mark Seeman in the same vein. There is a whole blog post series on <a href="http://blog.ploeh.dk/2016/02/10/types-properties-software/">Types + Properties = Software</a> which is definitely interesting. Inspired <a href="http://mirrors.link/posts/the-polyglot-approach-to-modeling-state-and-property-tests-in-elm">The Polyglot Approach to Getting Better at Modeling the State and Writing Property Tests in Elm · Exceptional Mirrors</a> written in Elm.</p>
</dd>
<dt><a href="https://www.stackbuilders.com/news/reverse-reverse-theorem-proving-with-idris">Reverse, Reverse: Theorem Proving with Idris</a></dt>
<dd><p>A blog post on how theorem proving works in Elm, detailing the classical vector reversal function’s derivation.</p>
</dd>
<dt><a href="https://www.cs.ox.ac.uk/projects/utgp/school/idris-tutorial.pdf">idris-tutorial.pdf</a></dt>
<dd><p>A short tutorial on Idris by Edwin Brady. Not sure how relevant it is to the newest versions of the language, but provides a compact overview of Idris’ features.</p>
</dd>
<dt><a href="http://www.cse.chalmers.se/~ulfn/papers/afp08/tutorial.pdf">Agda Tutorial</a></dt>
<dd><p>Working on Idris led me to <a href="http://wiki.portal.chalmers.se/agda/pmwiki.php">Agda</a> which is a predecessor of Idris with an emphasis on theorem proving.</p>
</dd>
<dt><a href="http://stackoverflow.com/questions/42974540/how-can-i-express-range-validity-in-idris">How can I express range validity in Idris?</a></dt>
<dd><p>As I was struggling on writing some Idris code for my talk, I posted this question on SO which leads to a Ah!Ah! moment thanks to the answer it received: The slogan is <em>Add more information to your types</em>!</p>
</dd>
<dt><a href="https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/ttfp.pdf">Type Theory and Functional Programming</a></dt>
<dd><p>An out-of-print book by Simon Thompson (author of one of the first Haskell books) that seems to provide a lot of insights on top of Pierce’s classical textbook.</p>
</dd>
<dt><a href="http://oxij.org/note/BrutalDepTypes/">Brutal {Meta}Introduction to Dependent Types in Agda</a></dt>
<dd><p>A page full of resources on dependent types, not only in Agda. Lead me to <a href="http://augustss.blogspot.fr/2007/10/simpler-easier-in-recent-paper-simply.html">this post</a> from Lennart Augustsson which gives an implementation of a depedently-typed lambda calculus in Haskell.</p>
</dd>
<dt><a href="https://medium.com/wardleymaps/finding-a-path-cdb1249078c0#.32oohi27s">Wardley Maps</a></dt>
<dd><p>I have started again to read Simon Wardley’s book-in-progress on how to draw maps for strategic thinking.</p>
</dd>
</dl>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Les après-midi de Simone</title>
    <link href="http://abailly.github.io/posts/simone-responsabilite.html" />
    <id>http://abailly.github.io/posts/simone-responsabilite.html</id>
    <published>2017-03-27T00:00:00Z</published>
    <updated>2017-03-27T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Les après-midi de Simone</h1>

  <h2 class="subtitle">Celui qui appuie sur le bouton est-il le seul coupable ?</h2>

<div class="info">Posted on March 27, 2017</div>

<p>Cette question des après-midi de Simone fait partie du <em>fil vert</em> soit des séances permettant d’articuler des questions philosophiques avec le context professionnel des participants, majoritairement programmeur/euse/s. Elle conjoint deux problèmes philosophiques, celui de <strong>l’action</strong> et celui de la <strong>culpabilité</strong> ou <strong>responsabilité</strong>. La séance s’organise en:</p>
<ul>
<li>une introduction pour décortiquer la question, en extraire son suc et sa moelle ;</li>
<li>une première séquence consacrée au thème de l’action ;</li>
<li>une deuxième pour la culpabilité et la responsabilité ;</li>
<li>une troisième pour inviter à actualiser ces thèmes dans notre vie ;</li>
<li>enfin, bien sûr une clôture du cercle par l’écoute.</li>
</ul>
<p>Ce texte faiblement structuré est une reprise des notes prises au cours de cet après-midi.</p>
<h1 id="introduction">Introduction</h1>
<ul>
<li>La première partie de la question renvoit à la notion d’<em>agent</em> ou de <em>sujet</em>, à la condition de responsabilité d’un <em>geste</em> dont les effets sont <em>imputables</em></li>
<li>Elle suscite des images liées à la bombe nucléaire, à un acte technologiquement médiatisé qui est le dernier terme d’une chaîne causale <em>avant</em> que ne se produisent des effets</li>
<li>L’agent n’est-il qu’un <em>rouage</em> dans un ensemble dont le geste extrêmement simple produit de grands effets ?</li>
<li>Se pose la question de <em>l’intentionalité</em> de l’action : qu’est ce qu’une action intentionelle ?</li>
<li>“seul” pose la question de l’existence (ou non) d’une action collective, de la multiplicité des agents dans une action</li>
<li>“coupable” enfin: y-a-t’il une faute et est-elle attribuable au sujet ? De quoi est-il coupable ? Devant quel tribunal ? Et qui est coupable ?</li>
</ul>
<h1 id="laction">L’action</h1>
<h2 id="exercice">Exercice</h2>
<p>Essayer de s’approcher au plus près du sens d’un terme en:</p>
<ol style="list-style-type: decimal">
<li>énumérant des adjectifs et adverbes pouvant s’appliquer à ce terme</li>
<li>pour chaque item de l’énumération identifier son contraire</li>
<li>produire une définition à partir des items dont un seul pôle est applicable</li>
</ol>
<ul>
<li>collective <span class="math inline">≠</span> individuelle</li>
<li>concertée <span class="math inline">≠</span> spontanée</li>
<li>rapide, qui <span class="math inline">≠</span> dure lente</li>
<li>dangereuse <span class="math inline">≠</span> inoffensive</li>
<li>en mouvement <span class="math inline">≠</span> immobile</li>
<li>continue <span class="math inline">≠</span> discrète</li>
<li>sans conséquence <span class="math inline">≠</span> importante</li>
<li>consomme de l’énergie <span class="math inline">≠</span> inerte</li>
<li>délibérée <span class="math inline">≠</span> involontaire</li>
<li>matérielle <span class="math inline">≠</span> immatérielle, spirituelle</li>
<li>observable <span class="math inline">≠</span> invisible</li>
<li>qui a un début, initiée</li>
<li>qui laisse des traces <span class="math inline">≠</span> sans effet</li>
<li>irréversible <span class="math inline">≠</span> réversible</li>
<li>qui a un sujet <span class="math inline">≠</span> sans agent</li>
<li>raisonnable <span class="math inline">≠</span> déraisonnable</li>
<li>concrète <span class="math inline">≠</span> abstraite, virtuelle</li>
<li>directe <span class="math inline">≠</span> médiatisée</li>
<li>impure <span class="math inline">≠</span> pure</li>
<li>positive <span class="math inline">≠</span> négative</li>
<li>insaissable <span class="math inline">≠</span> saisissable</li>
<li>possible <span class="math inline">≠</span> impossible</li>
<li>subie <span class="math inline">≠</span> acceptée</li>
<li>orientée vers une fin <span class="math inline">≠</span> sans objectif, gratuite</li>
<li>revendiquée <span class="math inline">≠</span> déniée, cachée, anonyme</li>
</ul>
<blockquote>
<p>Une action est un mouvement initié par un sujet qui produit des traces dans le réel</p>
</blockquote>
<h2 id="textes">Textes</h2>
<h3 id="aristote">Aristote</h3>
<ul>
<li>Dans <a href="https://fr.wikipedia.org/wiki/%C3%89thique_%C3%A0_Nicomaque">L’éthique à Nicomaque</a>, Aristote distingue parmi l’ensemble des activités humaines la <em>poein</em> de la <em>praxein</em>. Ces activités s’opposent à la <em>contemplation</em>, à la <em>théorie</em></li>
<li><em>poein</em> regroupe les activités de production de l’homme dont notamment les arts et la technique, des activités qui ont une <em>fin en dehors d’elle même</em>. Je peins pour produire une oeuvre d’art, j’écris pour produire un livre ou un article, je coud pour réaliser une vêtement…</li>
<li>a contrario, <em>praxein</em> groupe les activités et actions humaines qui <em>sont à elles mêmes leurs propres fins</em><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, parmi lesquelles on distingue les actions
<ul>
<li>intentionnelles</li>
<li>non intentionnelles</li>
</ul></li>
<li>cette distinction permet à Aristote de définir le souverain Bien commme l’accomplissement par l’hômme <em>d’actions vertueuses</em><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></li>
</ul>
<h3 id="wittgenstein">Wittgenstein</h3>
<ul>
<li><p>Dans les <a href="https://fr.wikipedia.org/wiki/Investigations_philosophiques">Recherches philosophiques</a>, §621, Wittgenstein dit:<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<blockquote>
<p>N’oublions pas ceci: lorsque “je lève mon bras”, mon bras se lève. Et le problème surgit : que reste-t-il si je soustrais le fait que mon bras se lève du fait que je lève le bras ?</p>
</blockquote></li>
<li>Il critique l’idée que l’action est le produit d’une décision et pose donc la question “qu’est ce que l’intention ?” Y-a-t’il quelque chose comme un processus par lequel “je lève le bras” serait une décision qui se transforme en une action de “mon bras qui se lève” ?</li>
<li>Il n’y a pas d’intention extérieure à l’action ou en d’autres termes il n’y a pas <em>d’intériorité</em> ou <em>d’antériorité</em> de quelque chose qui serait la volonté : l’intention <strong>c’est</strong> l’action</li>
<li>C’est tout le propos de la philosophie analytique qui nait avec Wittgenstein<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> que de chercher des critères qui soient uniquement linguistiques dans la compréhension du sens de nos énoncés</li>
<li>Elle s’appuie et réactualise Aristote qui distingue<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> les actions volontaires des actions volontaires:
<ul>
<li>les premières, dites aussi intentionnelles, ont leur principe dans l’agent qui connait les circonstances de son action. Elles sont issues d’une délibération, d’une pensée mais ne postulent pas l’existence d’un centre de la volonté <em>dans</em> l’agent. La décision, c’est l’action</li>
<li>les secondes sont toutes les actions faites par <em>ignorance</em> (des circonstances…) ou par une contrainte extérieure</li>
<li>il y a une distinction entre appuyer sur le bouton avec mon doigt <em>intentionnellement</em> et appuyer sur le bouton parce que je suis désequilibré et tombe dessus</li>
</ul></li>
<li><p>Elle s’oppose à une tradition classique qui à partir de Saint Augustin (entre autres) pose le <em>libre arbitre</em> comme un concept central de l’esprit : une action volontaire est issue d’une libre décision de ma <strong>volonté</strong> qui a une existence propre, qui est interne : c’est le résultat extérieur d’une délibération intérieure. Spinoza, Hume, Hobbes et Nietszche sont les principaux champions de l’absence de libre arbitre</p></li>
</ul>
<h3 id="anscombe">Anscombe</h3>
<ul>
<li>Nous travaillons à partir d’une texte d’<a href="https://en.wikipedia.org/wiki/Elizabeth_Anscombe">Anscombe</a> qui propose plusieurs descriptions d’une même situation (et de ses conséquences) afin d’élucider la question de l’intentionnalité de l’action : un hômme pompe de l’eau contenant du poison pour alimenter une citerne qui dessert une maison dans laquelle sont réunis des dirigeants politiques tyranniques et dont l’élimination ménerait à une société meilleure.</li>
<li>Peut-on décrire son action comme “le geste d’un bras faisant levier”, “l’alimentation en eau”, “un empoisonnement par l’eau” ou “la lutte contre la tyrannie” ?</li>
<li>Anscombe propose ce critère pour caractériser l’intentionnalité d’une action:
<ol style="list-style-type: decimal">
<li>la description de l’action est conforme à la totalité des faits ;</li>
<li>l’agent peut répondre à la question “pourquoi ?” étant donnée cette description des faits.</li>
</ol></li>
<li>Dans le cas décrit, “un empoisonnement par l’eau” répond à ces deux critères mais pas “la lutte contre la tyrannie”<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></li>
<li>S’inscrivant dans la tradition analytique, Anscombe propose un critère qui soit exclusivement linguistique pour caractériser l’intentionnalité et donc l’assignation en responsabilité pour des actions puisqu’on ne saurait dire qu’un agent est <em>coupable</em> pour une action non intentionnelle</li>
</ul>
<h1 id="la-culpabilité">La culpabilité</h1>
<h2 id="arendt">Arendt</h2>
<ul>
<li><a href="https://fr.wikipedia.org/wiki/Hannah_Arendt">Arendt</a> dans <em>La responsabilité collective</em> distingue très nettement la <em>culpabilité</em> de la <em>responsabilité</em></li>
<li>La culpabilité est nécessairement <em>individuelle</em> et identifie une action (ou un ensemble d’actions liéeS) qui est <em>jugée</em> comme <em>faute</em>. La culpabilité est de l’ordre du juridique, de la loi</li>
<li>La responsabilité peut être <em>collective</em> car elle est politique, de l’ordre de la morale (nous pouvons collectivement “répondre de”). Elle renvoit à l’identification que fait Kant de la morale et de la liberté : je suis moral parce libre, et libre parce que capable d’un jugement moral universel. Même des menaces de mort ne peuvent me libérer de mon devoir moral !</li>
<li>Dire que “nous sommes tous coupables” c’est donc confondre - volontairement ou non - ces deux notions et disculper les vrais coupables, ceux qui ont effectivement agis : diluer la faute juridique et la sanction dans le confort de la morale</li>
</ul>
<h2 id="lhomme-coupable">L’homme coupable</h2>
<ul>
<li><p>Nous distinguons quatre “courants” dans la notion de culpabilité:</p>
<dl>
<dt>Juridique (et morale ?)</dt>
<dd><p>l’on est coupable de ce que l’on <em>fait</em>, de ses <em>actes</em> en fonction d’un ensemble de règles en vigueur à une époque donnée<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
</dd>
<dt>Anthropologique</dt>
<dd><p>l’homme est ontologiquement coupable, parce qu’il est un homme. Cette définition est centrale dans la tradition chrétienne<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> : l’homme a fait une faute et a été chassé du paradis, il est imparfait et pécheur par nature et seul Dieu qui lui est parfait, par sa grâce, peut le racheter. La volonté (le libre-arbitre) nous a été donnée par Dieu mais elle se heurte à la finitude des choses ce qui provoque le Mal, l’erreur et le péché.<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> Pour <a href="https://plato.stanford.edu/entries/rousseau/">Rousseau</a>, il y a aussi péché originel mais il survient lorsque l’homme sort de l’état de Nature où aucune culpabilité n’a de sens pour entrer dans la société et la propriété</p>
</dd>
<dt>Sociale</dt>
<dd><p>Cette culpabilité Rousseauiste est reprise par <a href="https://plato.stanford.edu/entries/nietzsche/">Nietszche</a> (<em>Généalogie de la morale</em>) dans un sens plus social, lorsqu’il fait le lien entre la <em>dette</em> et le <em>devoir</em> qui mène à la faute et à la culpabilité. La culpabilité est ainsi une spiritualisation d’une situation de dépendance économique, la transformation d’une dépendance contingente résultant d’un rapport de force ou d’une condition sociale en une dépendance nécessaire envers un principe moral</p>
</dd>
<dt>Monstrueuse</dt>
<dd><p>Cette quatrième forme de culpabilité est définie par <a href="https://fr.wikipedia.org/wiki/G%C3%BCnther_Anders">Anders</a> et résulte de sa réflexion sur ce qu’on appelle désormais l’anthropocène et l’accélération vertigineuse des capacités techniques de l’homme.</p>
</dd>
</dl></li>
</ul>
<h2 id="anders">Anders</h2>
<ul>
<li>Pour Anders dans <a href="http://www.payot-rivages.net/livre_Nous-fils-d-Eichmann-Gunther-Anders_ean13_9782743611095.html">Nous, fils d’Eichmann</a>, la culpabilité moderne provient de:
<ol style="list-style-type: decimal">
<li>notre incapacité à nous représenter les effets de nos actions dans le monde : lorsque j’appuie sur le bouton qui largue Little Boy au dessus d’Hiroshima je ne suis pas capable de me représenter les effets dévastateurs d’une bombe nucléaire et ses centaines de milliers de victimes touchées sur des dizaines d’années</li>
<li>la médiatisation infinie née de la division du travail et de la complexité des processus de production et de décision</li>
</ol></li>
<li>Ces deux causes produisent du <em>monstrueux</em> : des hommes ayant perdu tout sentiment de responsabilité, incapable de se représenter les effets de leurs actions et totalement coupés d’iceux par la parcellisation des actes en viennent à faire des choses monstrueuses : faire rouler des trains remplis de juifs, construire des fours crématoires pour brûler leurs corps, construires des missiles balistiques intercontinentaux<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a>…</li>
<li>Certains hommes ayant participé à cette monstruosité perçoivent leur culpabilité profondément mais la société leur dénie tout jugement parce qu’elle ne peut l’accepter sans se remettre en cause : c’est le cas de Claude Eatherly qui pilotait l’avion au dessus d’Hiroshima et avec lequel Anders a correspondu. C’est une forme de culpabilité “saine”, une réaction normale à une situation anormale.</li>
<li>A contrario, la plupart des hommes fuient cette culpabilité dans le déni, l’ignorance volontaire, l’impuissance ou même la dépression existentielle</li>
<li><p>Anders propose une “procédure” simple et éclairante pour identifier des situations de type “eichmanniennes”:</p>
<blockquote>
<p>Je ne peux imaginer l’effet de cette action Donc, c’est un effet monstrueux Donc, je ne peux pas l’assumer Donc, je dois réexaminer l’action projetée, ou bien la refuser, ou bien la combattre</p>
</blockquote></li>
</ul>
<h1 id="cultiver-le-sentiment-de-responsabilité">Cultiver le sentiment de responsabilité</h1>
<ul>
<li>La dernière étape du voyage prend la forme d’un exercice nous permettant d’ancrer les réflexions de l’après-midi dans la pratique et le “quotidien” : proposer un critère de démarcation entre la <em>peur salutaire</em>, celle qui représente un atout essentiel à notre survie ; et la <em>peur aliénante</em>, celle qui est agitée par les démagogues, nous paralyse ou nous enclin à des actions monstrueuses.</li>
<li>Plusieurs critères sont proposés:
<ul>
<li>la peur de perdre quelque chose (aliénante) <span class="math inline">≠</span> la peur d’être jugé (libératrice)</li>
<li>la fréquence et/ou la proximité de la source de peurs</li>
<li>les peurs primaires, régressives (aliénantes) <span class="math inline">≠</span> les peurs causées par des valeurs morales</li>
<li>le degré de médiatisation entre nous et la source de notre peur (aliénant quand il augmente)</li>
<li>la connaissance et la compréhension de la cause de notre peur<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a></li>
</ul></li>
<li><p>Pour une fin elliptique, une citation de Wittgenstein:</p>
<blockquote>
<p>Je provoque la volonté de nager en me jettant à l’eau</p>
<p>Recherches Philosophiques, §613</p>
</blockquote></li>
</ul>
<h1 id="conclusion">Conclusion</h1>
<ul>
<li>L’après-midi se conclut par un tour de parole</li>
<li>J’ai pour ma part vécu une expérience très riche et en suis content. J’ai apprécié le rythme, soutenu, l’érudition de Peggy Avez, les exercices nous invitant à réfléchir et puiser dans notre pratique et notre propre réflexion, les perspectives ouvertes sur des auteurs connus mais mal compris (Wittgenstein, Anders), peu connus (Aristote, Arendt) ou nouveaux (Anscombe).</li>
<li>Sur le plan pratique, je retiens la “procédure d’Anders” comme une nouvelle heuristique puissante pour s’orienter dans un monde de plus en plus complexe</li>
</ul>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>J’ai plus de mal à produire des exemples qui soient à mes yeux convaincants, cette distinction me paraissant assez largement artificielle et dépassée<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Ceci semble entrer en contradiction avec d’autres parties de l’oeuvre du stagirite pour lesquelles le souverain bien est dans la contemplation, la théorie…<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>On notera le contraste entre la simplicité de l’énonciation et la complexité des questions qu’elle soulève<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Plus précisèment avec le <em>second</em> Wittgenstein, celui des <em>Recherches philosophiques</em> et pas celui du <em>Tractatus logico-philosophicus</em><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>L’éthique à Nicomaque, livre 3<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>J’avoue ma perplexité en relisant ces notes…<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Il me semble que l’on passe là un peu vite sur la distinction entre droit et morale : un planteur de Louisiane est-il coupable de tuer un esclave en 1840 ? Et un romain en -50 ? Que dire du frère d’une jeune fille qui la tue parce qu’elle a “fauté” avec un garçon ?<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Plus largement, juive et musulmane aussi ?<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Dans cette tradition, la culpabilité à pour vocation d’expliquer le Mal en disculpant Dieu<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>Des centrales nucléaires ?<a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>voir ce que dit Spinoza des affects et en particulier du traitement de la <a href="http://spinoza.fr/lecture-des-propositions-xxxix-a-xliv-du-de-affectibus/">peur</a> comme commencement de la raison<a href="#fnref11">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Les Blancs, les Juifs et nous&quot;</title>
    <link href="http://abailly.github.io/posts/bouteldja.html" />
    <id>http://abailly.github.io/posts/bouteldja.html</id>
    <published>2016-06-21T00:00:00Z</published>
    <updated>2016-06-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Les Blancs, les Juifs et nous&quot;</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on June 21, 2016</div>

<p>J’ai lu récemment <a href="http://www.lafabrique.fr/catalogue.php?idArt=952">Les Blancs, les Juifs et nous</a> de <a href="https://fr.wikipedia.org/wiki/Houria_Bouteldja">Houria Bouteldja</a>, fondatrice du Mouvement puis Parti des <a href="http://indigenes-republique.fr/">Indigènes de la République</a>. Les temps que nous vivons sont, comme le dit une fameuse malédiction, intéressants et la question des migrations, des frontières et des nations se repose avec une acuïté renouvellée. Nous croyions les nationalismes et racismes dépassés, au moins en Europe, vestiges d’un ancien monde qui aurait plongé dans l’abyme en 1945, quand ils n’étaient qu’assoupis. Et ces vieux démons nous reviennent en partie sous les mêmes oripeaux - stigmatisation de l’étranger, de l’immigré, peur de l’avenir et du déclassement, exaltation de la grandeur du passé - en partie sous de nouvelles hardes - crise écologique, hyper-technologie, libéralisme dévorant. Essayer de comprendre les alternatives qui s’offrent à nous, les “nouvelles” idéologies qu’il nous faudra fabriquer, diffuser, intégrer pour espérer survivre me semble être un impératif pressant.</p>
<p>Pour ceux qui liraient ces lignes et que ces questions intéresseraient, internet est comme souvent une mine inépuisable de textes, d’information et de désinformation sur ces questions et sur le sujet du <em>décolonialisme</em> dont je n’ai fait qu’égratigner la surface, et qui est le sujet du livre de Houria Bouteldja. Je n’en parlerai donc pas plus et me concentrerai sur ce que j’ai compris de ce livre et ce qu’il m’inspire.</p>
<h2 id="brève-synthèse">Brève synthèse</h2>
<p>Le livre est court, divisé en 6 chapitres traitant respectivement de Sartre et de la génèse du mouvement décolonial, des Blancs et de leur domination sur toutes les autres “races”, des Juifs et de leur soumission aux Blancs, des femmes décolonisées et de leur relation aux hommes décolonisés et aux femmes en général, de tous les décolonisés et enfin de Dieu et plus particulièrement de l’Islam.</p>
<p>Il est aussi très bien écrit. La langue d’Houria Bouteldja est fluide, percutante, poétique parfois, polémique toujours. Elle me rappelle, si ce n’est par le style du moins par le ton et le sens de la formule, certains écrits de Debord, ou bien sûr les textes du <a href="http://www.lafabrique.fr/spip/IMG/pdf_Insurrection.pdf">Comité invisible</a>. Cela n’a rien d’étonnant compte-tenu de la proximité entre toutes les luttes de l’ultra-gauche: le décolonialisme est l’allié “naturel” du féminisme, de l’anti-capitalisme, des luttes trans-genres, de l’écologie radicale…</p>
<p>Allié ou plutôt <em>avant-garde</em> au sens bolchévique, marxiste, révolutionnaire du terme : la pointe la plus avancée de la contestation, le groupe le plus en phase avec le <em>sens de l’histoire</em>, celui sur lequel toutes les autres luttes doivent s’aligner, qui a la responsabilité historique d’être révolutionnaire. C’est d’ailleurs le point essentiel du livre : démontrer en quoi les décolonisés sont la nouvelle <em>classe révolutionnaire</em> et subsument toutes les autres luttes ; autrement dit transformer la dialectique prolétaires/capitalistes en dialectique (dé)colonisés/colonisateurs : les décolonisés sont les nouveaux <em>damnés de la Terre</em>, les ultimes prolétaires.</p>
<p>Et ce pour une bonne raison : le concept de race, la <em>blanchitude</em> et donc la <em>non-blanchitude</em>, est une invention de l’Occident destinée à enfoncer un coin entre le prolétariat “blanc” occidental et les colonisés. Ce sont les dominants Blancs qui ont inventé le racisme pour construire leur hégémonie et s’assurer de la docilité de leurs prolétaires en inventant un sous-prolétaire : le <em>non-blanc</em>, le <em>colonisé</em>. Tactique classique de tous les pouvoirs pour lutter contre les critiques internes : créer de toute pièce un ennemi “extérieur” qui deviendra ennemi commun, puis en appeler à la solidarité de la communauté.</p>
<p>Ce principe, au sens le plus “principiel” d’origine première d’une chose, doit donc informer toutes les luttes “autres”:</p>
<ul>
<li>Les mouvemements ouvriers et de luttes sociales sont invités à se rallier à sa bannière car “l’Arabe est le prolétaire du prolétaire” et leurs luttes convergent ;</li>
<li>les luttes homosexuelles, de genre et plus largement LGBTQ sont considérées comme secondaires et surtout purement blanches : “il n’y a pas d’homosexuels en Iran” dit Ahmadinejjad lors d’un colloque à Columbia ;</li>
<li>le féminisme est lui aussi un produit de la blanchitude et l’auteure en appele à une solidarité communautaire avec les mâles décolonisés dans un délicat équilibre entre des revendications d’émancipation et l’impératif du combat principal contre la colonisation blanche. Le corps de la femme décolonisée, en tout cas celui d’Houria Bouteldja, ne lui appartient pas, il appartient à son clan, sa communauté, sa race, à la révolution qui vient, et la violence machiste des hommes colonisés est une réaction exacerbée par la domination subie, donc <em>in fine</em> une violence d’origine coloniale.</li>
</ul>
<p>Le cas des Juifs est particulier : les Juifs sont des non-blancs, des colonisés, mais en adoptant le sionisme ils se sont blanchis. L’auteure utilise d’ailleurs le terme très percutant et provocant de <em>dhimmis<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> de la République</em>. L’antisémitisme, comme toute forme de racisme, est un pur produit Occidental né de la modernité, une autre forme de la domination coloniale qui a trouvée son point culminant dans la destruction des juifs d’Europe. En universalisant l’antisémitismes, les Blancs réussissent à “faire d’une pierre deux coups : justifier le hold-up de la Palestine et justifier la répression des indigènes en Europe”.</p>
<p>L’Islam, socle culturel authentiquement décolonisé et indigène, est la seule force capable de lutter contre la modernité occidentale incarnée par la figure tutélaire de Descartes, d’où le titre du dernier chapitre du livre : <em>Allahou Akbar</em>. En posant tous les hommes également égaux car soumis à Dieu, l’Islam renverserait la profession de foi occidentalo-centrée en “l’homme maître et possesseur de la Nature”.</p>
<h2 id="quelques-remarques-pêle-mêles">Quelques remarques pêle-mêles</h2>
<p>J’ai aimé ce livre pour sa force provocatrice, son ton radical, son engagement en faveur des exploités et dominés. Il m’a donné des clés pour lire certains événements contemporains, certains prises de position, certaines luttes, par exemple pourquoi le port du voile peut être pensé comme révolutionnaire et libérateur (et ce en dehors de toute question morale). Comme tous les pamphlets bien écrits, il ne peut laisser indifférent et provoque des sentiments mêlés d’admiration, d’enthousiasme, de peur. C’est aussi sa limite.</p>
<p>Comme tous les pamphlets, il est plein d’amalgames, de raccourcis, de formules chocs dont le sens est interprétable à l’infini, d’appels à l’Histoire dans lesquels se télescopent les situations, les époques, les peuples, les civilisations. Plein de mauvaise foi aussi, jugée nécessaire pour les besoins de l’argumentation. Et d’ambiguïtés : citer dans un même livre Sartre, Genet, Césaire, Malcolm X, James Baldwin, Mahmoud Ahmadinejjad et Dieudonné. Et parfois aussi tout simplement d’erreurs et d’omissions, volontaires ou non. Sur le plan historique, les relations entre Occident et Orient me semblent un peu plus complexes que ce qu’en dit l’auteure : l’Islam n’a pas attendu l’invention de la modernité pour être impérial, si ce n’est colonial. Et mettre dans le même plan toutes les colonisations européennes, depuis 1492 jusqu’au vingtième siècle est un court-circuit historique qui me semble abusif<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. Cela n’enlève rien à la responsabilité historique de l’Occident et de l’Europe dans la tragédie coloniale et post-coloniale.</p>
<p>Est-ce que ce livre s’adresse à moi ? Moi, homme blanc, petit-bourgeois, non engagé dans les luttes sociales, rationnel et raisonnable ou tentant de l’être ; moi qui n’ai pas eu des parents ouvriers, qui n’ai jamais vécu dans une cité, qui suit un “souchien” n’ayant pas à souffrir du racisme ? Il parait difficile de le croire mais en tout cas il m’a touché. Et d’une certaine manière, Houria Bouteldja, en glorifiant le particularisme et sa “race” opprimée, atteint à l’universel de la lutte des dominés pour plus de justice sociale.</p>
<p>Nous sentons tous confusément que notre vieux monde se meurt, lentement mais sûrement ; que si l’Occident n’a plus de colonies il détient un part du capital mondial telle qu’il capte à son profit l’essentiel des richesses produites ; que Gaïa est en train de réagir aux mauvais traitements que nous lui infligeons ; que le modèle consumériste et la logique d’accumulation qui le sous-tend sont à bout de souffle. La question est, pour paraphraser Lénine : “Que faire ?”</p>
<p>Je n’ai pas de leçons à donner et m’en abstiendrai donc, mais je crois plus aux petits matins qu’aux grands soirs. Même si les seconds sont plus exaltants que les premiers.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Dans l’espace musulman, les dhimmis sont les non-musulmans, Juifs, Chrétiens, Zoroastriens (pas sûr pour ceux-là…) auxquels est accordé un statut spécial. Ils sont tolérés et protégés par le calife ou le sultan, ils ont l’autorisation de pratiquer leurs cultes en contrepartie d’une taxe et, si mes souvenirs sont bons, de l’obligation du port d’un signe distinctif.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Les anciens colonisateurs espagnols et portugais qui ont dominé et même exterminé les peuples indigènes d’Amérique sont devenus eux-mêmes colonisés et solidaires des luttes tiers-mondistes arabes, africaines et asiatiques.<a href="#fnref2">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>The Dungeon Master</title>
    <link href="http://abailly.github.io/posts/dungeon-master.html" />
    <id>http://abailly.github.io/posts/dungeon-master.html</id>
    <published>2016-06-03T00:00:00Z</published>
    <updated>2016-06-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>The Dungeon Master</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on June  3, 2016</div>

<p>This post was triggered by a <a href="https://twitter.com/ziobrando/status/737619202538758145">tweet from Alberto Brandolini</a> on <a href="https://medium.com/@ziobrando/the-rise-and-fall-of-the-dungeon-master-c2d511eed12f#.erkso3y88">The rise and fall of the Dungeon Master</a>. This revived old memories from my youth and the desire to share this part of my story, in the hope that it might shed some light on what a “Dungeon Master” role actually should be and what team work is all about. My life revolved around Role Playing Games between the the age of fifteen to about twenty-eight and this experience shaped my way of thinking probably more than anything else.</p>
<h1 id="kill-maim-mutilate">Kill, Maim, Mutilate!</h1>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/en/3/32/D%26D_Basic_Rules_1981.jpg" class="floating" width="200" />

</div>
<p>In the beginning, there was Dungeons &amp; Dragons, the ancestor of all modern <em>Role Playing Games</em>. I bought a mysterious box containing all kind of booklets, sheets and dices when I was fourteen. I have already been exposed to wargaming thanks to <a href="https://fr.wikipedia.org/wiki/Jeux_et_Strat%C3%A9gie">Jeux et Stratégies</a>, a specialized newspaper that died somewhere in the 90s, and D&amp;D was a kind of logical follow-up to wargames. My proficiency level in English at that time was barely sufficient to allow me to understand what I was reading and the whole concept sounded at first quite alien. It took me several months of frustrating reading and discussions with friends to finally understand what it was all about: Sitting around a table, throwing dices and killing monsters inside a “dungeon” designed by an evil <em>Dungeon Master</em>.</p>
<p>I dived into D&amp;D with the full passion of a shy and sexually frustrated teenager who discovers he can actually <em>be</em> anybody: A fierce warrior dreaded by his ennemies, a cunning wizard, a nimble thief, a wise priest… I wrote programs to generate characters on an old IBM at school, I spent nights writing “scenarios”, mapping dungeons on 5mm x 5mm grid paper, inventing new monsters, reading hundreds of pages of arcane rules, reading sci-fi and fantasy books to get inspiration from and of course playing, playing, playing…</p>
<p>At that time, the Dungeon Master looked quite like the one portrayed by Alberto Brandolini: The overlord of the game, hidden behind his <em>DM screen</em> from where he would throw at the poor players traps and monsters, and under the cover of which he could <em>cheat on the dices</em>! It was a major breach to look behind the screen and try to have a sneak peek at the DM’s plans and scenario, something which would invariably bring upon your head a major disaster like a <em>red dragon</em> or worse, the DM leaving the game.</p>
<p>As a player, my goal was pretty much guided by <em>numbers</em>: Getting to 18/100 in <em>strength</em>, accumulating enough <em>experience points</em> to get to the next level where new spells, weapons, tricks, skills were available. And the only way to get those XPs was to <em>kill monsters</em> and <em>hoard treasures</em>! I, like other players in my team, played by the rules and kept on pursuing those goals in a never-ending cycle of more powers, more dangerours monsters, more treasures, more intricate dungeons… I moved on quickly from D&amp;D to <em>Advanced D&amp;D</em> as the latter offered to go beyond the first ten levels, more character classes, more spells, more weapons, more tricks. I bought more books, like the infamous <a href="https://en.wikipedia.org/wiki/Deities_%26_Demigods#2nd_Edition_Advanced_Dungeons_.26_Dragons">Deities and Demi-gods</a> which detailed the characteristics of numerous figures from real or fictional religions, or the <a href="https://en.wikipedia.org/wiki/Fiend_Folio">Fiend Folio</a> which detailed more dreadful monsters.</p>
<h1 id="growing">Growing</h1>
<p>At some point, we grew wary of AD&amp;D and longed for new experiences. We discovered games like <a href="https://en.wikipedia.org/wiki/Call_of_Cthulhu_%28role-playing_game%29">Call of Cthulhu</a> or <a href="https://en.wikipedia.org/wiki/RuneQuest">RuneQuest</a>. Those games offered more complex settings and characters, with subtler goals like not losing all your <em>sanity</em>. But those games were still based on the principle of <em>accumulation</em>: Characters would <em>grow</em> and become more powerful, knowledgeable, skillfull. I vividly remember that the <em>GameMaster</em> (there were no more <em>dungeons</em>) was quite upset when, during one of our Cthulhu game, in some scene that was supposed to be one of the climax of the <a href="https://index.rpg.net/display-entry.phtml?mainid=829&amp;editionid=1045">Masks of Nyarlathotep</a> campaign and following a lengthy and supposedly terrifying description of some fierce beast whiche we were fighting, I said “Oh, a Hunting Horror !” in a definitely <em>not</em> terrified voice…</p>
<p>Then I became officially adult, and then came <a href="https://en.wikipedia.org/wiki/Vampire:_The_Masquerade">Vampire</a>. This game, and other similar games we played at that time like <a href="https://en.wikipedia.org/wiki/Pendragon_%28role-playing_game%29">Pendragon</a>, <a href="https://en.wikipedia.org/wiki/Bushido_%28role-playing_game%29">Bushido</a>, <a href="https://en.wikipedia.org/wiki/Mal%C3%A9fices">Maléfices</a> or <a href="https://en.wikipedia.org/wiki/Ars_Magica">Ars Magica</a>, developed the concept of <em>campaign</em> not as a sequence of battles to gain more XP, but as long story depicting the life (and sometimes death) of the player characters.</p>
<p>All of sudden, or so it seems in retrospect, the goal of the game shifted from <em>accumulating things</em> to <em>telling a good story</em>. What became important was not whether your character was the most powerful vampire of the universe, the cunniest wizard of the Covenant or the noblest knight around the table ; but whether or not your character had been through interesting, intriguing, funny, frightful and more importantly memorable experiences. Your character could grow in power: This was not for power’s sake but to enable him or her to live new and interesting things, to be involved in more complex intrigues at the Kings’s court or the local vampire overlord’s den. One of our Bushido’s campaign ended up with one of the player’s character committing <a href="https://en.wikipedia.org/wiki/Seppuku">seppuku</a> upon request from the Shôgun on the charge of treason and this was a really a moving experience. We played some Maléfices scenarios in a candle-lit chilly cave and those were the most frightening games we are went through.</p>
<p>The role of the Game Master obviously changed, so much so that it became a <em>Storyteller</em> in Vampire. He became more a different kind of player, a referee, a source of inspiration than a traps-dealer or a dungeon designer. He would be responsible for setting the stage, starting the story or crafting some new plot in case the original one dwindled and the game dragged along, surprising the players with interesting twists, embodying <em>non player characters</em> which the player would encounter or suggest… In other words, he stopped being an omnipotent <em>dictator</em> to become a <em>facilitator</em>, a <em>master of ceremony</em>: But having fun was a shared responsibility!</p>
<p>Within this frame, it was possible to be very directive, like an author whose skill takes you off and whom you would follow anywhere. Those kind of game masters would write complex stories, intricate plots, subtle NPCs and dramatic scenes and we would follow them because we knew they were good storytellers. I was more of the other kind of gamemasters, those who could improvise a game on the spur of the moment, counting on the other players to fuel the story and their own imagination to adapt to it as it unfolded in surprising ways. My scenarios were written on a napkin but I was good at recycling the numerous books I read, combining them, taking the plot of one book and mixing it with the background of another one.</p>
<div class="figure">
<img src="http://www.legrog.org/visuels/gammes/288.jpg" class="floating-right" />

</div>
<p>At some point, role-playing games became so prominent in my life we started <a href="https://rpggeek.com/rpgpublisher/11284/sarl-sans-peur-et-sans-reproche">a company</a> to publish our own games. The first, and most successful, game we published was <a href="https://fr.wikipedia.org/wiki/Miles_Christi">Miles Christi</a>, a game set in the Middle East during the early crusades era, in which the players’ characters were exclusively <em>templars</em>. This game was the embodiment of the evolution I sketched above: The scenarios were devised to put players into conflicting situations which forced to choose between their loyalty to the cause they were supposed to defend and their loyalty to the christian ideal of universal love and forgiving God. And each game ended with a <em>confession</em> scene during which the players were supposed to confess the, usually numerous, sins they would have committed during the game and were rewarded or punished accordingly.</p>
<h1 id="discussion">Discussion</h1>
<blockquote>
<p>The purpose of Life is living.</p>
</blockquote>
<p>Those recollections are probably of low interest to the reader and might sound like nostalgic rambles from an aging man. But if I try to relate that experience with the aforementioned blog post, it seems to me it highlights something important about the way we work, and especially the way we work in teams while we develop software, and the role of so-called <em>managers</em> within a team.</p>
<p>Most organizations, and teams within those organizations, and people making up those teams, are playing D&amp;D. Just like a D&amp;D player wants to get more XPs, more gold, kill more monsters ; and D&amp;D GM wants to devise more complex dungeons, more traps, more powerful monsters to throw at playsers ; those groups and people want <em>more</em> of something: Money, power, knowledge, tools, lines of code… They have a <em>goal</em>, they are <em>mission driven</em>, they <em>achieve</em>. And when they reach those goals, they find new ones, because it is never-ending, there is always more money, more knowlege, more power to grab. This is what give rise to the kind of <em>Dungeon Masters</em> Alberto Brandolini writes about, and this is fueled by the logic of <em>accumulation</em> and <em>competition</em> bred by material goals and achievements we often crave for.</p>
<p>Those days, I personally tend to favor the other approach. As a team member, whatever my precise role may be, I find it important to have clear, tangible goals. But what I have found to be more important is what happens within the team, the relationship I have with the people, the way we work together: The journey has become more important than the destination, the <em>how?</em> (and the <em>why?</em>) more important than the <em>what?</em>. As a <em>Dungeon Master</em>, or as an experienced person or the historical developer of some piece of software, what becomes important is to ensure <em>we</em> are telling ourselves a good story. And this is a collaborative process in which everybody has its role to play, and which requires a lot of effort from everybody.</p>
<p>To conclude on a philosophical note, let me quote my favourite philosopher:</p>
<blockquote>
<p>Therefore, to man there is nothing more useful than man–nothing, I repeat, more excellent for preserving their being can be wished for by men, than that all should so in all points agree, that the minds and bodies of all should form, as it were, one single mind and one single body, and that all should, with one consent, as far as they are able, endeavour to preserve their being, and all with one consent seek what is useful to them all. Hence, men who are governed by reason–that is, who seek what is useful to them in accordance with reason,–desire for themselves nothing, which they do not also desire for the rest of mankind, and, consequently, are just, faithful, and honourable in their conduct.</p>
<p>Spinoza, Ethica IV,18,sc.</p>
</blockquote>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Multi-host Docker Networking</title>
    <link href="http://abailly.github.io/posts/multi-host-docker-net.html" />
    <id>http://abailly.github.io/posts/multi-host-docker-net.html</id>
    <published>2016-05-30T00:00:00Z</published>
    <updated>2016-05-30T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Multi-host Docker Networking</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on May 30, 2016</div>

<p>A while ago I grew the desire to experiment implementing <em>multi-host docker networking</em> to deploy <a href="/posts/cm-infra-2.html">Capital Match system</a>. This system is made of several interlinked containers and <a href="https://docs.docker.com/v1.8/compose/">docker-compose</a> does not (did not?) work across several hosts. It seemed to me the <a href="https://docs.docker.com/engine/userguide/networking/get-started-overlay/">official solution</a> based on <code>docker-machine</code>, <code>swarm</code> and service registry was a bit complicated: Our configuration is mostly static, e.g. number, distribution and relationship between containers in known at deploy time. Hence I looked for a simpler solution, something that would be more <em>networky</em>: I am indebted to <a href="https://fr.wikipedia.org/wiki/Utilisateur:Hashar">hashar</a> for suggesting a GRE-based solution and to the following references for actual technical details:</p>
<ul>
<li><a href="https://goldmann.pl/blog/2014/01/21/connecting-docker-containers-on-multiple-hosts/" class="uri">https://goldmann.pl/blog/2014/01/21/connecting-docker-containers-on-multiple-hosts/</a></li>
<li><a href="https://wiredcraft.com/blog/multi-host-docker-network/" class="uri">https://wiredcraft.com/blog/multi-host-docker-network/</a></li>
</ul>
<p>I did some experiment in shell, jotted down a couple of notes in my journal and moved on to other, more urgent duties. I had a couple of hours left on Friday last week and I stumbled on those notes which were sitting there, on my hard disk, and I decided it was a good time to write a blog post about this experiment.</p>
<p>I started writing this post embedding script fragments but I quickly wanted to check what I wrote actually worked, so I began running those scripts fragment. But then it made this experiment non repeatable which is definitely annoying if you make a mistake, want to restart from scratch, change some parameters… So I decided this stuff would warrant a minor project of its own where I could provide all the needed code to configure multi-host networking in docker based on GRE tunnels. I have done quite a share of system configuration and operations management and have been able to use or create some useful tools to streamline ops in Haskell, so it quickly became obvious I would need to write some Haskell code. So what started as a mundane journal cleanup ended up being a full-blown yak-shaving session whose result can be found in this github <a href="https://github.com/abailly/multi-host-docker">repository</a>.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Haskell-based Infrastructure</title>
    <link href="http://abailly.github.io/posts/cm-infra-2.html" />
    <id>http://abailly.github.io/posts/cm-infra-2.html</id>
    <published>2016-05-24T00:00:00Z</published>
    <updated>2016-05-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Haskell-based Infrastructure</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on May 24, 2016</div>

<p>In my <a href="/posts/cm-infra-1.html">previous post</a> I focused on the build and development tools. This post will conclude my series on Capital Match by focusing on the last stage of the rocket: How we build and manage our development and production infrastructure. As already emphasized in the previous post, I am not a systems engineer by trade, I simply needed to get up and running something while building our startup. Comments and feedback most welcomed!</p>
<h1 id="continuous-integration">Continuous Integration</h1>
<p><a href="http://www.extremeprogramming.org/rules/integrateoften.html">Continuous Integration</a> is a cornerstone of Agile Development practices and something I couldn’t live without. CI is a prerequisite for <em>Continuous Deployment</em> or <a href="http://martinfowler.com/bliki/ContinuousDelivery.html">Continuous Delivery</a>: It should ensure each and every change in code of our system is actually working and did not break anything. CI is traditionally implemented using servers like <a href="https://jenkins.io/">Jenkins</a> or online services like <a href="https://travis-ci.org/">Travis</a> that trigger a build each time code is pushed to a source control repository. But people like <a href="http://blog.javabien.net/2009/12/01/serverless-ci-with-git/">David Gageot</a>, among <a href="http://www.yegor256.com/2014/10/08/continuous-integration-is-dead.html">others</a>, have shown us that doing CI without a server was perfectly possible. The key point is that <em>it should not be possible to deploy something which has not been verified and validated by CI</em>.</p>
<h2 id="ci-server">CI Server</h2>
<p>We settled on using a central git repository and CI server, hosted on a dedicated build machine:</p>
<ul>
<li>Git repository’s master branch is “morally” locked: Although technically it is still possible to push to it, we never do that and instead push to a <code>review</code> branch which is merged to the <code>master</code> only when build passes,</li>
<li>The git repository is configured with a git deploy hook](https://www.digitalocean.com/community/tutorials/how-to-use-git-hooks-to-automate-development-and-deployment-tasks) that triggers a call to the CI server when we push on the <code>review</code> branch,</li>
<li><p>Our CI server is implemented with <a href="https://github.com/ndmitchell/bake">bake</a>, a robust and simple CI engine built - guess what? - in Haskell. Bake has a client/server architecture where the server is responsible for orchestrating builds that are run by registered clients, which are supposed to represent different build environments or configurations. Bake has a very simple web interface that looks like</p>
<div class="figure">
<img src="/images/bake-screenshot.png" />

</div></li>
<li><p>Bake provides the framework for executing “tests”, reporting their results and merging changes to <code>master</code> branch upon successful build, but does not tell you <em>how</em> your software is built: This is something we describe in Haskell as a set of steps (bake calls them all <em>tests</em>) that are linked through dependencies and possibly dependent on the capabilities of the client. Here is a fragment of the code for building Capital Match:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Action</span> <span class="fu">=</span> <span class="dt">Cleanup</span>
            <span class="fu">|</span> <span class="dt">Compile</span>
            <span class="fu">|</span> <span class="dt">Dependencies</span>
            <span class="fu">|</span> <span class="dt">RunDocker</span>
            <span class="fu">|</span> <span class="dt">Deploy</span> <span class="dt">ImageId</span>
            <span class="fu">|</span> <span class="dt">IntegrationTest</span>
            <span class="fu">|</span> <span class="dt">UITest</span>
            <span class="fu">|</span> <span class="dt">EndToEndTest</span>
            <span class="kw">deriving</span> (<span class="dt">Show</span>,<span class="dt">Read</span>)

<span class="ot">allTests ::</span> [<span class="dt">Action</span>]
allTests <span class="fu">=</span> [ <span class="dt">Compile</span>
           , <span class="dt">Dependencies</span>
           , <span class="dt">IntegrationTest</span>
           , <span class="dt">UITest</span>
           , <span class="dt">EndToEndTest</span>
           , <span class="dt">Deploy</span> appImage
           , <span class="dt">RunDocker</span>
           ]

<span class="ot">execute ::</span> <span class="dt">Action</span> <span class="ot">-&gt;</span> <span class="dt">TestInfo</span> <span class="dt">Action</span>
execute <span class="dt">Compile</span> <span class="fu">=</span> depend [<span class="dt">Dependencies</span>] <span class="fu">$</span> run <span class="fu">$</span> <span class="kw">do</span>
  opt <span class="ot">&lt;-</span> addPath [<span class="st">&quot;.&quot;</span>] []
  () <span class="ot">&lt;-</span> cmd opt <span class="st">&quot;./build.sh --report=buildreport.json&quot;</span>
  <span class="dt">Exit</span> _ <span class="ot">&lt;-</span> cmd opt <span class="st">&quot;cat buildreport.json&quot;</span>
  sleep <span class="dv">1</span>
  incrementalDone

execute <span class="dt">IntegrationTest</span> <span class="fu">=</span> depend [<span class="dt">Compile</span>] <span class="fu">$</span> run <span class="fu">$</span> <span class="kw">do</span>
  opt <span class="ot">&lt;-</span> addPath [<span class="st">&quot;.&quot;</span>] []
  () <span class="ot">&lt;-</span> cmd opt <span class="st">&quot;./build.sh test&quot;</span>
  incrementalDone</code></pre></div>
The code is pretty straightforward and relies on the toplevel build script <code>build.sh</code> which is actually a simple wrapper for running our Shake build with various targets.</li>
<li>The output of the CI process, when it succeeds, is made of a bunch of docker containers deployed to Dockerhub, each tagged with the SHA1 of the commit that succeeded,</li>
<li>We extended bake to use <a href="https://git-scm.com/docs/git-notes">git notes</a> to identify successful builds: We attach a simple note saying <code>Build successful</code> to those commits which actually pass all the tests. We also notify outcome of the build in our main <a href="https://slack.com/">Slack</a> channel,</li>
<li>Bake server and client are packaged and deployed as docker containers, which means we can pull and use those containers from any docker-enabled machine in order to reproduce a CI environment or trigger builds through bake’s command-line interface,</li>
<li><p>As the last stage of a successful build we deploy a test environment, using anonymized and redacted sample of production data.</p></li>
</ul>
<h2 id="testing">Testing</h2>
<p>An significant time slice of our build is dedicated to running tests. Unit and server-side integration tests are pretty straightforward as they consist in a single executable built from Haskell source code which is run at <code>IntegrationTest</code> stage of the CI build process. Running UI-side tests is a little bit more involved as it requires an environment with PhantomJS and full ClojureScript stack to run leiningen. But the most interesting tests are the end-to-end ones which run Selenium tests against the full system.</p>
<ul>
<li>The complete ETE tests infrastructure is packaged as - guess what? - a set of containers orchestrated with <code>docker-compose</code> and mimicking production setup:
<ul>
<li>One container per service,</li>
<li>One container for the nginx front-end,</li>
<li>One container for the <a href="https://github.com/SeleniumHQ/docker-selenium">SeleniumHub</a>,</li>
<li>One container for a Firefox node in debug mode (this allows us to use VNC to log into the container and see the Firefox instance executing the tests),</li>
<li>and one container for the test driver itself,</li>
</ul></li>
<li><p>Tests are written in Haskell using <a href="https://github.com/kallisti-dev/hs-webdriver">hs-webdriver</a>, and we try to write them in a high-level yielding something like:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">
it <span class="st">&quot;Investor can withdraw cash given enough balance on account&quot;</span> <span class="fu">$</span> runWithImplicitWait <span class="fu">$</span> <span class="kw">do</span>

  liftIO <span class="fu">$</span> invokeApp appServer <span class="fu">$</span> <span class="kw">do</span>
    iid <span class="ot">&lt;-</span> adminRegistersAndActivateInvestor arnaudEMail
    adjustCashBalance_ (<span class="dt">CashAdjustment</span> iid <span class="dv">100001</span> (<span class="dt">TxInvestorCash</span> iid))

  userLogsInSuccesfully appServer arnaud userPassword
  goToAccountSummary
  cashBalanceIs <span class="st">&quot;S$\n1,000.01&quot;</span>

  investorSuccessfullyWithdraws <span class="st">&quot;500.00&quot;</span>

  cashBalanceIs <span class="st">&quot;S$\n500.01&quot;</span>
  userLogsOut</code></pre></div></li>
<li>Those tests only need a single URL pointing at an arbitrary instance of the system, which makes it “easy” to run them during development outside of docker containers. It’s even possible to run from the REPL which greatly simplifies their development,</li>
<li>Getting the docker-based infrastructure right and reliable in CI was a bit challenging: There are quite a few moving parts and feedback cycle when working with containers is slow. We ran into subtle issues with things like:
<ul>
<li>Differing versions of Firefox between local environment and container leading to different behaviours, like how visibility of DOM elements is handled which may or may not prevent <code>click</code> actions to complete</li>
<li>Timezone differences between various containers yielding different interpretations of the same timestamp (official Selenium docker images are configured to use PST whereas test driver container uses SGT,</li>
<li>Connections and timeouts issues between all the containers depending on open ports and network state,</li>
<li>…</li>
</ul></li>
<li><p>However, once in place and executing reliably, those tests really payoff in terms of how much confidence we have in our system. We don’t aim to provide 100% feature coverage of course and try to keep <a href="http://martinfowler.com/bliki/TestPyramid.html">ETE tests small</a>: The goal is to ensure our system’s main features are still usable after each change.</p></li>
</ul>
<h1 id="deployment">Deployment</h1>
<h2 id="provisioning-infrastructure">Provisioning &amp; Infrastructure</h2>
<p>We are using <a href="https://www.digitalocean.com/">DigitalOcean</a>’s cloud as our infrastructure provided: DO provides a much simpler deployment and billing model than what provides AWS at the expense of some loss of flexibility. They also provide a simple and consistent RESTful API which makes it very easy to automate provisioning and manage VMs.</p>
<ul>
<li>I wrote a Haskell client for DO called <a href="https://github.com/capital-match/hdo">hdo</a> which covers the basics of DO API: CRUD operations on VMs and listing keys,</li>
<li>Provisioning is not automated as we do not need capacity adjustments on the go: When we need a machine we simply run the script with appropriate credentials. Having a simple way to provision VMs however has a nice side-effect: It makes it a no-brainer to fire copy of any environment we use (Dev, Ci or Production) and configure it. This was particularly useful for pairing sessions and staging deployment of sensitive features,</li>
<li>We also use AWS for a couple of services: S3 to backup data and host our static web site and CloudFront to provide HTTPS endpoint to website.</li>
</ul>
<h2 id="configuration-management">Configuration Management</h2>
<p>Configuration of provisioned hosts is managed by <a href="http://propellor.branchable.com/">propellor</a>, a nice and very actively developed Haskell tool. Configuration in propellor are written as Haskell code using a specialized “declarative” embedded DSL describing <em>properties</em> of the target machine. Propellor’s model is the following:</p>
<ul>
<li>Configuration code is tied to a git repository, which may be only local or shared,</li>
<li>When running <code>./propellor some.host</code>, it automatically builds then commits local changes, pushing them to remote repository if one is defined. All commits are expected to be signed,</li>
<li>Then propellor connects through SSH to <code>some.host</code> and tries to clone itself there, either by plain cloning from local code if <code>some.host</code> has never been configured, or by merging missing commits if host has already been configured (this implies there is a copy of git repository containing configuration code on each machine),</li>
<li>In case architectures are different, propellor needs to compile itself on the target host, which might imply installing additional software (e.g. a Haskell compiler and needed libraries…),</li>
<li>Finally, it runs remote binary which triggers verification and enforcement of the various “properties” defined for this host.</li>
</ul>
<p>Propellor manages security, e.g. storing and deploying authentication tokens, passwords, ssh keys…, in a way that seems quite clever to me: It maintains a “store” containing sensitive data <em>inside</em> its git repository, encrypted with the public keys of accredited “users”, alongside a keyring containing those keys. This store can thus be hosted in a public repository, it is decrypted only upon deployment and decryption requires the deployer to provide her key’s password.</p>
<p>Here is an example configuration fragment. Each statement separated by <code>&amp;</code> is a property that propellor will try to validate. In practice this means that some system-level code is run to check if the property is set and if not, to set it.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">ciHost ::</span> <span class="dt">Property</span> <span class="dt">HasInfo</span>
ciHost <span class="fu">=</span> propertyList <span class="st">&quot;creating Continuous Integration server configuration&quot;</span> <span class="fu">$</span> props
              <span class="fu">&amp;</span> setDefaultLocale en_us_UTF_8
              <span class="fu">&amp;</span> ntpWithTimezone <span class="st">&quot;Asia/Singapore&quot;</span>
              <span class="fu">&amp;</span> Git.installed
              <span class="fu">&amp;</span> installLatestDocker
              <span class="fu">&amp;</span> dockerComposeInstalled</code></pre></div>
<p>In practice, we did the following:</p>
<ul>
<li>All known hosts configurations are defined in a configuration file (a simple text file containing a Haskell data structure that can be <code>Read</code>) and tells, for each known IP/hostname, what type of configuration should be deployed there and for production hosts what is the <strong>tag</strong> for containers to be deployed there. As this information is versioned and committed upon each deployment run, we always know which version of the system is deployed on which machine by looking at this configuration,</li>
<li>We also defined a special <em>clone</em> configuration which allows us to deploy some version of the system using cloned data from another system,</li>
<li>We ensure the application is part of the boot of the underlying VM: Early on we had some surprises when our provider decided to reboot the VM and we found our application was not available anymore…</li>
</ul>
<h2 id="deployment-to-production">Deployment to Production</h2>
<p>Given all the components of the application are containerized the main thing we need to configure on production hosts apart from basic user information and firewall rules is docker itself. Apart from docker, we also configure our <a href="http://nginx.org">nginx</a> frontend: The executable itself is a container but the configuration is more dynamic and is part of the hosts deployment. In retrospect, we could probably make use of pre-canned configurations deployed as data-only containers and set the remaining bits as environment variables.</p>
<p>Doing actual deployment of a new version of the system involves the following steps, all part of propellor configuration:</p>
<ul>
<li>We first check or create our data containers: Those are the containers which will be linked with the services containers and will host the persisted event streams (see <a href="/posts/cm-archi.html">post on architecture</a>),</li>
<li>We then do a full backup of the data, just in case something goes wrong…</li>
<li>And finally rely on <a href="https://docs.docker.com/v1.8/compose/">docker-compose</a> to start all the containers. The <code>docker-compose.yml</code> configuration file is actually generated by propellor from some high-level description of the system which is stored in our hosts configuration file: We define for each deployable service the needed version (docker repository <em>tag</em>) and use knowledge of the required topology of services dependencies to generate the needed docker links, ports and names.</li>
</ul>
<p>The net result is the something like the following. The dark boxes represent services/processes while the lighter grayed boxes represent containers:</p>
<div class="figure">
<img src="/images/services-architecture.png" />

</div>
<p>We were lucky enough to be able to start our system with few constraints which means we did not have to go through the complexity of setting up a blue/green or rolling deployment and we can live with deploying everything on a single machine, thus alleviating to use more sophisticated container orchestration tools.</p>
<h3 id="rollbacks">Rollbacks</h3>
<p><a href="/posts/cm-archi.html">Remember</a> our data is a simple persistent stream of events? This has some interesting consequences in case we need to rollback a deployment:</p>
<ul>
<li>If the version number has not been incremented, rollbacking simply means reverting the containers’ tag to previous value and redeploying: Even if some events have been recorded before we are notified of an issue implying rollback is needed, they should be correctly interpreted by the system,</li>
<li>If the version has changed during deployment, then either we cannot rollback because new events have been generated and stored and we must roll-forward ; or we can rollback at the expense of losing data. This is usually not an option but still is possible if stored events are “harmless” business-wise, like authentication events (logins/logouts): A user will simply have to login again.</li>
</ul>
<h2 id="monitoring">Monitoring</h2>
<p>Monitoring is one the few areas in Capital Match system where we cheated on Haskell: I fell in love with <a href="http://riemann.io">riemann</a> and chose to use it to centralize log collections and monitoring of our system.</p>
<ul>
<li>Riemann is packaged as a couple of containers: One for the server and one for the <a href="http://riemann.io/dashboard.html">dashboard</a>, and deployed on a dedicated (small) VM. Both server and dashboard configuration are managed by propellor and versioned,</li>
<li>As part of the deployment of the various VMs, we setup and configure <a href="https://www.stunnel.org/index.html">stunnel</a>s containers which allow encrypted traffic between monitored hosts and monitoring server: On the monitoring host there is a stunnel server that redirects inbound connections to running docker containers, whereas on monitored hosts the stunnel server is referenced by clients and encapsulate traffic to remote monitoring host transparently,</li>
<li>Riemann is fed 2 types of events:
<ul>
<li>System level events which are produced by a <a href="https://collectd.org/">collectd</a> installed on each deployed host,</li>
<li>Applicative level events which are produced by the deployed services as part of our logging system,</li>
</ul></li>
<li>Applicative events are quite simple at the moment, mostly up/down status and a couple of metrics on HTTP requests and disk storage latency and throughput,</li>
<li>There is a simple riemann dashboard that presents those collected events in a synoptic way,</li>
<li>It is very easy to extend riemann with new clients or external connectors: At one point I considered using <a href="http://logmatic.io">LogMatic</a> to host some business-level dashboards and it took me a few hours to build a <a href="https://github.com/capital-match/riemann-logmatic">riemann plugin</a> to send events to Logmatic’s API,</li>
<li>Riemann’s event model is very simple and flexible hence it is an ideal candidate for being a one-stop sink for all your events: Dump all events to riemann using a single connector in the application and configure riemann server to massage the events and feed specialized clients,</li>
<li>There a couple of alerts configured in Riemann that notifies <em>slack</em> when disks fill up or hosts are down.</li>
</ul>
<p>We also have set up external web monitoring of both application and web site using <a href="https://checkmy.ws/fr/">Check My Website</a>.</p>
<h1 id="discussion">Discussion</h1>
<h2 id="some-takeaways">Some takeaways</h2>
<ul>
<li>Docker has its shortcomings, is far from being perfect and is becoming bloated like all enterprise software, but packaging all parts of a system as containers is a good thing. It allowed us to grow a flexible yet consistent system made of a lot of moving parts with diverse technological requirements. Containers are obviously great for <em>development</em>, providing a simple and efficient way of packaging complex tools and environments in an easy to use way. But they are also great for <em>operations</em>: They are more flexible than VMs, they can be as secure if one takes care to trim them down to the bare minimum, and pretty compact, they give you great flexibility in terms of deployment,</li>
<li>I still don’t have much experience, apart from small experiments, on how to deploy docker over multiple machines. However the ecosystem of tools for managing more complex deployments is growing and maturing fast and beside I have a couple ideas on how to do it in a “simple way” using <a href="https://github.com/openvswitch/ovs/">OpenVSwitch</a>,</li>
<li>Docker containers should do one and only one thing and they should be kept minimal: Don’t use default fat images and try to trim them down to the bare minimum (e.g. executable + support libraries + configuration files),</li>
<li>I did not pay enough attention to build time, or more precisely I did not pay attention often enough,</li>
<li>Automating as much as possible of the whole system is an investment: If you are going to throw it away in a few months, don’t do it ; but if you are going to live with it for years, do it <strong>now</strong> because later it will be too late to really payoff,</li>
<li>Having automated ETE tests is a great thing but they should be kept to a minimum: Always consider the relative size of the layers in the pyramid and do not try to cover bugs or “deviant” behaviour at the level of ETE tests,</li>
<li>Monitoring must be baked into the system from the onset, even if with simple solutions and basic alerts. It is then easy to extend when business starts to understand they could leverage this information,</li>
<li>propellor is a great tool for provisioning. I tried things like Chef or Puppet before and the comfort of working in Haskell and not having to delve into the intricacies of complex “recipes” or custom DSL is invaluable. Propellor is simple and suits my requirements pretty well, however there are a couple of pain points I would like to find some time to alleviate:
<ul>
<li>Tying deployment runs to git commits is really a good thing but this should be more customizable: I would like to keep deployment code in the same repository than production code but this currently would yield a lot of identically named commits and pollute the log of the repository,</li>
<li>Propellor needs to be built on the target machine as it is an executable: It can upload itself when architecture matches hence it would be better to run deployment inside a dedicated container that match the target OS in order to remove the need to install GHC toolchain,</li>
<li>It is hard to write and maintain <em>idempotent properties</em>: It would be simpler to be able to run propellor only once on a machine, forcing immutable infrastructure.</li>
</ul></li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Growing such a system was (and still is) a time-consuming and complex task, especially given our choice of technology which is not exactly mainstream. One might get the feeling we kept reinventing wheels and discovering problems that were already solved: After all, had we chosen to develop our system using PHP, Rails, Node.js or even Java we could have benefited from a huge ecosystem of tools and services to build, deploy and manage it. Here are some benefits I see from this “full-stack” approach:</p>
<ul>
<li>We <strong>know</strong> how our system works down to the system level, which allows us to take informed decisions on every part of it while understanding the global picture. The knowledge gained in the process of growing this system has a value in and of itself but is also an asset for the future: The better we know how the system works, the faster we can adpat it to changing requirements and constantly evolving environment,</li>
<li>It has been definitely frustrating at time but immensely fun to experiment, learn, tweak, fail or succeed, with all those moving parts,</li>
<li>It forces us to really think in terms of a single unified <strong>system</strong>: Being in charge of the whole lifecycle of your code, from writing the first line to deployment to production to retirement yields a sense of responsibility one does not gain from working in silos and throwing some bunch of code over the wall to ops team. This is truly <a href="http://www.jedi.be/blog/2010/02/12/what-is-this-devops-thing-anyway/">DevOps</a> in the way Patrick Debois initially coined the term, as a kind of system-thinking process and genuinely drives you to the <a href="http://queue.acm.org/detail.cfm?id=1142065">You build it, you run it</a> culture,</li>
<li>Managing operations, even at a small scale, is demanding, hence the need to think about automation, monitoring and short deployment cycles as early as possible in order to minimize the need for manual interventions.</li>
</ul>
<p>This completes a series of post I have written over the past few months, describing my experience building Capital Match platform:</p>
<ul>
<li><a href="/posts/cm-arch-design.html">Anatomy of a Haskell-based Application</a> described the overall design and architecture of the application,</li>
<li><a href="/posts/agile-startup.html">Using agile in a startup</a> detailed our development process,</li>
<li><a href="/posts/cm-infra-1.html">Haskell-based Development Environment</a> focused on the build system and development environment.</li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Haskell-based Development Environment</title>
    <link href="http://abailly.github.io/posts/cm-infra-1.html" />
    <id>http://abailly.github.io/posts/cm-infra-1.html</id>
    <published>2016-05-23T00:00:00Z</published>
    <updated>2016-05-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Haskell-based Development Environment</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on May 23, 2016</div>

<p>In a <a href="/posts/cm-arch-design.html">previous post</a> I described the overall design and architecture of Capital Match’s core system. I now turn to providing more details on our development and operations environment which uses mostly Haskell tools and code. As there are quite a lot of moving parts, this large topic will be covered in two posts: The present one will focus on basic principles, build tools and development environment ; it shall be followed by another post on configuration management, deployment and monitoring. I consider both development and production environments as a single integrated system as, obviously, there is a porous membrane between the two especially in a small company with 4 developers. Although I have been interested in that topic since my first systems programming course in university, some 18 years ago, I do not consider myself a genuine systems administrator and I made a lot of mistakes while building Capital Match platform. But I do believe in the <em>“you build it, you run it”</em> motto and this is all the more true for a small startup team. Hence I have tried to pay attention to building a flexible yet robust system.</p>
<h1 id="principles">Principles</h1>
<p>When we started to setup this environment, we were guided by a few principles:</p>
<ul>
<li>Automate, automate, automate: As much setup as possible should be automated,</li>
<li>Every system-level part should be containerized,</li>
<li>There should be a single versioned source of authority for configuration,</li>
<li>Use as much Haskell as possible.</li>
</ul>
<h2 id="automate">Automate</h2>
<blockquote>
<p>Automate all the things!</p>
</blockquote>
<p>Deployment to production should be as much automated as possible, involving as few manual steps as possible. The end goal is to reach a state of continuous deployment where pushed changes are built, verified and deployed continuously over the day. This implies all the steps involved in getting some feature delivered to end-users should be identified and linked into a coherent process that is implemented in code, apart from the actual coding of the feature itself. There should be no fiddling with SSHing on production machine to fix some configuration script, no manual migration process when upgrading data schema, no copying of binaries from development environment to production…</p>
<h2 id="everything-docker">Everything Docker</h2>
<blockquote>
<p>Containerize all the things!</p>
</blockquote>
<p><a href="http://docker.io">docker</a> is still a controversial technology, esp. among system and cloud specialists, and the topic of hot debates which is a sure sign it is a game changer. And back in 2014 when we started developing Capital Match’s platform, docker was in its infancy. I have had some experience in the past working with <a href="http://linux-vserver.org/Welcome_to_Linux-VServer.org">VServer</a> and <a href="https://linuxcontainers.org/">LXC</a> and containers are definitely great as a way to package (parts of) a system. Using docker allows us to:</p>
<ul>
<li>Provide seamless integration of development and production environments: The exact same software can be produced anywhere and used anywhere, whatever OS or configuration the actual developer is using, and the production configuration can be reproduced easily for testing or staging purposes,</li>
<li>Encapsulate components in immutable “packages” that require minimal system-level configuration, e.g. no more fiddling with ports, machine names, environment variables… docker-compose takes care of running everything, and we can make services dependent to stable names,</li>
<li>Simplify “hardware” configuration: All we need is something that is running docker (and a compatible kernel of course…) which means machines provisioning becomes a no-brainer,</li>
<li>Isolate build and run components from system-level dependencies conflicts,</li>
<li>Provide some level of reuse across containers and components thanks to layered FS.</li>
</ul>
<p>Note that we stuck to the initial docker “philosophy” of <em>one process per container</em>, except for some very specific needs (e.g. Selenium testing): It is not possible to ssh into our applicative containers.</p>
<h2 id="single-source-of-authority">Single Source of Authority</h2>
<blockquote>
<p>Version all the things!</p>
</blockquote>
<p>This means we should of course version our application’s code, but also the system’s configuration and as much dependencies as possible. Ideally, we should be able to reconstruct the whole system from a handful commands:</p>
<ul>
<li><code>git clone &lt;the repo&gt; cm</code></li>
<li><code>cd cm; ./build ; ./deploy</code></li>
</ul>
<p>In practice this is quite a bit more complicated as there are some glue parts missing to ensure the whole system can be rebuilt from scratch, but still we came quite close to that ideal. We are using 2 different repositories, one for the application code and one for the environment, mostly for technical reasons related to how our configuration management software works. The only unversioned part is the description of the “hardware” and the provisioning part which is still done “manually”.</p>
<h2 id="everything-haskell">Everything Haskell</h2>
<blockquote>
<p>Typecheck all the things!</p>
</blockquote>
<p>There is not a dearth of tools when it comes to configuration management, systems provisioning and deployment, build tools… When starting small you usually don’t want to invest a lot of time in learning new tools hence a common choice is simply to start small with shell scripts. But tools usually exist for a reason: Scripts quickly become a tangled maze of scattered knowledge. Yet we have at our disposal a powerful tool: Haskell itself, the language and its ecosystem, hence we decided to try as much as possible to stick to using Haskell-based tools. Beside the obvious simplification this brings us (one compiler, one toolchain, one language…), the advantages Haskell provides over other languages (type safety, lazy evaluation, immutable data structures) seemed to be equally valuable at the applicative level than at the system level.</p>
<h1 id="overview">Overview</h1>
<div class="figure">
<img src="/images/system-architecture.png" width="900" />

</div>
<p>The above figure gives a high-level overview of the system:</p>
<ul>
<li>Developers work on local machines (or <em>dev boxes</em>, see below), pushing changes to <a href="http://git-scm.com">git</a>,</li>
<li>Pushing to remote repository triggers build on <em>continuous integration</em> server <a href="https://github.com/ndmitchell/bake">bake</a>,</li>
<li>The final output of CI is a bunch of containers which are deployed to a private repositories on <a href="https://hub.docker.com/">docker hub</a>,</li>
<li>When we are ready to deploy, we update the system configuration in another git repository then run <a href="http://propellor.branchable.com/">propellor</a>,</li>
<li>This triggers configuration of <em>run</em> system which usually entails downloading correct container from repository and running it,</li>
<li>Data (also stored in a container) is regularly backed-up on S3,</li>
<li>Various components of the system feed events to <a href="http://riemann.io">riemann</a> monitoring system.</li>
</ul>
<h1 id="build-toolchain">Build &amp; Toolchain</h1>
<h2 id="build">Build</h2>
<h3 id="cabal">Cabal</h3>
<p>For building the Haskell part, we started obviously with <a href="https://www.haskell.org/cabal/">Cabal</a> which is the defacto build system/package manager in Haskell. The structure of GHC+Cabal packages system makes it quite hard to create insulated and <strong>reproducible</strong> build environments as there are various interactions between what’s installed globally (with GHC) and what’s installed per user and per project. There was no <a href="http://docs.haskellstack.org">stack</a> two years ago so we had to roll our own. Here are some key features of our cabal-based build:</p>
<ul>
<li>We used cabal snapshots with pinned down versions of all dependencies through <code>cabal freeze</code></li>
<li>Build became more complex when we started to add subpackages and sharing dependencies (&gt;100) seemed like a good idea. We shared a single sandbox by setting <code>CABAL_SANDBOX_CONFIG</code> to point to toplevel directory sandbox configuration file for all packages, then <code>add-source</code> sub-packages. This make it easier to simultaneously:
<ul>
<li>Build everything in one go,</li>
<li>Work in a sub-package,</li>
<li>Work in main (top-level) package,</li>
</ul></li>
<li>This does not prevent rebuilds when moving across packages as the build directory used by cabal is still located within each package,</li>
<li>We are still dependent on a globally available GHC. When upgrading GHC versions, you need to change globally installed GHC before rebuilding,</li>
<li>Several concurrent versions can coexist and be used in the same directory as GHC maintains version/OS dependent packages database, but care need to be taken with <code>PATH</code>s as the cabal version is likely different too…</li>
</ul>
<h3 id="stack">Stack</h3>
<p><a href="https://github.com/commercialhaskell/stack/">stack</a> represented a huge improvement for managing our build but it took us a few months to ensure it built consistently.</p>
<ul>
<li>Stack provides truly repeatable builds and segregate build environments tightly, including the tooling (compiler, lexer, parser…), managing downloads, setting package databases paths…</li>
<li>There is a single executable to install which makes creating build containers much easier: install stack, run setup and you have a fully configured container at required version. It is also very easy to upgrade,</li>
<li>Stack manages dependencies through <a href="https://www.stackage.org/">stackage</a> meaning you only have to provide a single version number and you are guaranteed to have compatible versions of libraries. This might be sometimes problematic if you require some specific version of a library that is not part of the dependency package, but it is still possible to provide custom versions,</li>
<li>I was sometimes surprised by stack not reusing some previous build result, although I could make it work manually,</li>
<li>The biggest hurdle we had to overcome to make stack work for us were the tests. Some tests relied on specific files to be present which means we had to manage relative paths: depending on whether or not tests are run from toplevel (which is the case in CI for example) or from local package directory (which is the case when using stack to build a tree of packages), relative directory may not be correctly set. Moreover stack runs tests in parallel, which is a good thing to force you to implement parallelizable tests but failed for us as we relied on starting server on some port for integration tests. We should get rid of hardwired port and allow the server to use some randomly allocated one but we chosed the simplest path and configured stack to run tests sequentially.</li>
<li>A minor annoyance is (was?) that stack maintains a build directory in each sub package, even when run from the toplevel, which is not the case when using cabal sandbox. This implies that reusing previous builds is a bit more cumbersome as one needs to save each <code>.stack-work</code> directory.</li>
</ul>
<h3 id="leiningen">Leiningen</h3>
<p><a href="http://leiningen.org/">leiningen</a> is (was?) the prominent build tool for clojure and clojurescript. We chose Clojurescript for the UI mostly because this allowed us to develop it using the excellent <a href="https://github.com/omcljs/om/">Om</a> wrapper over React. It took us quite a lot of time to get our project build comfortable and it did not evolve as quickly as the Haskell one.</p>
<ul>
<li>When to distinguish various build targets: Development mode where we want some interactive reload within the browser, test mode to run unit tests (automatically or in batch) and production mode which needs to be optimiszed,</li>
<li>Getting the tests to run correctly proved difficult and is still dependent on some manual configuration: To run clojurescript tests, we need to install <a href="http://phantomjs.org/">phantomjs</a> and configure correctly <a href="https://github.com/cljsjs/packages/wiki/Creating-Externs">externs</a> for the few javascript libraries we use and compile both code and tess <strong>with only whitespace</strong> optimizations (tests don’t run in fully optimized mode),</li>
<li>This actually means code is compiled as much as 3 times, which takes some time…</li>
<li>The CSS part of the UI is written using <a href="https://github.com/noprompt/garden">garden</a>, which means we have to compile it to proper CSS then pack and compress all CSS files together to improve load time. In retrospect, this was probably a mistake: We don’t use clojure’s power to write our CSS and it is still a mess, so we would have been better off using some standard CSS language like Less or Sass (although this adds the burden of running some thirdparty tool as part of the build…).</li>
</ul>
<h3 id="javascript">Javascript</h3>
<p>When we introduced the mobile UI for Capital Match, we had to integrate its build inside our process. This caused some headache as this part of the system is developed in pure Javascript using <a href="http://emberjs.com/">Emberjs</a> and relies on various tools in the JS ecosystem I was not familiar with. It also used <a href="http://sass-lang.com/">sass</a> to write CSS which means we needed ruby to run the compiler.</p>
<ul>
<li>We packaged all system-level dependencies into a single docker container. Note that official distribution’s package for node and npm were outdated hence we had to install them “by hand” in the container which is apparently the right way anyway,</li>
<li>There is a single top-level script which builds everything and is ran from the container.</li>
</ul>
<h3 id="shake">Shake</h3>
<p>Given the diversity of tools and components we are building, we needed a way to orchestrate build of the full solution which could be easily run as part of <em>Continuous integration</em>. We settled on <a href="http://shakebuild.com">shake</a> which is a Haskell-based tool similar to <em>make</em>.</p>
<ul>
<li>Rules are written in Haskell and shake provides support for all system-level tasks one would need to do in a build, including running arbitrary processes, manipulating their output, manipulating files… Using this embedded DSL makes it possible to track dependencies more easily. Shake maintains a database of dependencies that can be populated with arbitrary data,</li>
<li>The default target of our build is a list of docker containers, one for each service of the system plus the nginx container,</li>
<li>At the root of the dependency graph lies our build containers: one for <em>ghc + clojurescript</em> and one for building <em>javascript</em> code. Those containers are only expected to change (and be built) when we upgrade our toolchain. They are somewhat expensive to build as they need to provide all the needed tools to build (and run) our system,</li>
<li>On the server side, we use the <code>ghc-clojure</code> container to run a top-level build script that builds all services and the web UI. Given it takes ages to download and build all dependencies, then build all the various parts of the system, we tried to maximize reuse across builds: The build artifacts are exported as data containers and we link to the <span class="math inline"><em>n</em> − 1</span> build container in the <span class="math inline"><em>n</em></span> build run,</li>
<li>In order to minimize the size of our containers, we extract each service’s executable from the full build container and repack it into another container which contains a minimal runtime environment. We initially tried to do something like <a href="https://github.com/fpco/haskell-scratch/">haskell-scratch</a> but this did not work when our code needed to issue client-side HTTPS request: For some network and SSL reason the service fails to initialize properly. We resorted to use the standard busybox image, to which we add some prepackaged runtime libraries. This allows us to deploy containers with a “small” size: Our main application container weighs in at about 27MB and a typical service weighs 10MB. Note this has the additional benefit of drastically limiting the attack surface of the containers as they only contain the bare minimum to run our services and nothing else,</li>
<li>Shake build also contains rules to run different class of tests: Unit/integration server-side tests, UI tests and end-to-end-tests (see below), and rules to clean build artifacts and docker containers.</li>
</ul>
<h2 id="development-environment">Development Environment</h2>
<h3 id="haskell">Haskell</h3>
<p>There has been various attempts at providing an IDE for Haskell: * <a href="http://leksah.org/">leksah</a> is an Eclipse-based Haskell IDE, * <a href="http://haskellformac.com/">Haskell for Mac</a>, * FPComplete used to provide some web-based environment.</p>
<p>Having used emacs for years, I feel comfortable with and besides there are actually benefits using a plain-text tool for coding when you are part of a distributed team: It allows you to easily setup a distributed pairing environment with minimal latency. Yet configuring a proper Haskell development environment in Emacs can be a challenging task, and it seems this is a moving target.</p>
<ul>
<li>Starting from <a href="https://github.com/haskell/haskell-mode/">Haskell-mode</a> page is good idea as it is the base upon which one builds her own Emacs Haskell experience.</li>
<li><a href="https://github.com/serras/emacs-haskell-tutorial/blob/master/tutorial.md">Emacs haskell tutorial</a> provides some more details on how to set things up,</li>
<li><a href="https://github.com/chrisdone/emacs-haskell-config">Chris Done’s Haskell config</a> provides an easy to use full-blown configuration,</li>
<li>I tried <a href="https://github.com/chrisdone/structured-haskell-mode">SHM</a> a couple of times but could not get used to it, or could not make it work properly, or both… Might want to retry at some point in the future,</li>
<li><a href="http://tim.dysinger.net/posts/2014-02-18-haskell-with-emacs.html">this blog post</a> is a bit older but I remember having gone through it and try to reproduce some of the proposed features</li>
<li><a href="http://blog.hoersten.co/post/110096363794/modern-emacs-haskell-mode">This other post</a></li>
<li><a href="http://www.mew.org/~kazu/proj/ghc-mod/en/">ghc-mod</a> is useful but With cabal sandboxes and multiple projects it seems to be pretty unusable. I am also having a hard time making it work properly for test code: This requires different configurations and package dependencies are not properly picked up by ghc-mod. I need to investigate a bit more as I found this extension quite interesting,</li>
<li>Some people at Capital Match have started to use <a href="http://spacemacs.org/">spacemacs</a> which seems to come with a correctly configured Haskell environment out of the box.</li>
</ul>
<p>Here is my current .emacs content:</p>
<div class="sourceCode"><pre class="sourceCode scheme"><code class="sourceCode scheme">(eval-after-load <span class="st">&quot;haskell-mode&quot;</span>
  &#39;(progn
     (setq haskell-stylish-on-save t)
     (setq haskell-tags-on-save t)

     (setq haskell-process-type &#39;stack-ghci)
     (setq haskell-process-args-stack-ghci &#39;(<span class="st">&quot;--test&quot;</span>))
     
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-,&quot;</span>) &#39;haskell-move-nested-left)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-.&quot;</span>) &#39;haskell-move-nested-right)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c v c&quot;</span>) &#39;haskell-cabal-visit-file)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c v c&quot;</span>) &#39;haskell-cabal-visit-file)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-c C-t&quot;</span>) &#39;ghc-show-type)
     (define-key haskell-mode-map (kbd <span class="st">&quot;C-x C-d&quot;</span>) nil)
     (setq haskell-font-lock-symbols t)

     <span class="co">;; Do this to get a variable in scope</span>
     (auto-complete-mode)

     <span class="co">;; from http://pastebin.com/tJyyEBAS</span>
     (ac-define-source ghc-mod
       &#39;((depends ghc)
         (candidates . (ghc-select-completion-symbol))
         (symbol . <span class="st">&quot;s&quot;</span>)
         (cache)))
     
     (defun my-ac-haskell-mode ()
       (setq ac-sources &#39;(ac-source-words-in-same-mode-buffers
                          ac-source-dictionary
                          ac-source-ghc-mod)))
     (add-hook &#39;haskell-mode-hook &#39;my-ac-haskell-mode)
     
  
     (defun my-haskell-ac-init ()
       (when (<span class="kw">member</span> (file-name-extension buffer-file-name) &#39;(<span class="st">&quot;hs&quot;</span> <span class="st">&quot;lhs&quot;</span>))
         (auto-complete-mode t)
         (setq ac-sources &#39;(ac-source-words-in-same-mode-buffers
                            ac-source-dictionary
                            ac-source-ghc-mod))))
     (add-hook &#39;find-file-hook &#39;my-haskell-ac-init)))

(add-hook &#39;haskell-mode-hook &#39;turn-on-haskell-decl-scan)
(add-hook &#39;haskell-mode-hook &#39;turn-on-haskell-indentation)
(add-hook &#39;haskell-mode-hook &#39;interactive-haskell-mode)

(add-hook &#39;haskell-interactive-mode-hook &#39;turn-on-comint-history)

(eval-after-load <span class="st">&quot;which-func&quot;</span>
  &#39;(add-to-list &#39;which-func-modes &#39;haskell-mode))

(eval-after-load <span class="st">&quot;haskell-cabal&quot;</span>
    &#39;(define-key haskell-cabal-mode-map (kbd <span class="st">&quot;C-c C-c&quot;</span>) &#39;haskell-compile))</code></pre></div>
<p>Thanks to discussions with <a href="https://twitter.com/solirc_">Simon</a> and <a href="https://twitter.com/amarpotghan">Amar</a> I am now using the REPL much more than I used to. My current workflow when working on Haskell code looks like:</p>
<ul>
<li>Load currently worked on file in interpreter using <code>C-c C-l</code>: This starts an inferior-haskell which is configured to use <code>stack ghci --test</code> under the hood, meaning all files including tests are in scope,</li>
<li>Code till it compiles properly and I can run a test,</li>
<li>Make test pass in the REPL,</li>
<li>When it’s OK, run full build, e.g. <code>stack test</code> in the console. This might trigger some more changes downstream which I need to fix,</li>
<li>When all unit tests pass, commit and push to CI.</li>
</ul>
<h3 id="clojurescript">Clojurescript</h3>
<p>The nice thing when using non-modern languages like Haskell and Clojure is that you only need to be able to edit text files to develop software, hence the choice of Emacs to develop both is kind of obvious. There is very good support for Clojure in emacs through <a href="https://github.com/clojure/tools.nrepl">nrepl</a> and <a href="https://github.com/clojure-emacs/cider">Cider</a> but it seems having the same level of support for Clojurescript is still challenging.</p>
<ul>
<li>When developping UI ClojureScript code, I mostly use <a href="https://github.com/bhauman/lein-figwheel">figwheel</a> which provides interactive reloading of code in the browser. One needs to start figwheel through <code>lein figwheel</code> which provides a REPL, then load the UI in a browser: The UI connects to the figwheel server which notifies it of code changes that trigger reload of the page,</li>
<li>For (mostly) non-UI code, I tend to favour TDD and use “autotesting” build: Changes in code trigger recompilation and run of all unit tests using the same configuration than batch run,</li>
<li><a href="http://wikemacs.org/wiki/Paredit-mode">paredit-mode</a> provides a structured way to edit LISP-like code: It automatically balances parens, brackets or double-quotes and provides dozens of shortcuts to manipulate the syntax tree ensuring syntactically correct transformations. I tend to use it as much as possible but sometimes find it cumbersome,</li>
<li>What I miss most when developing ClojureScript is a way to identify and navigate across symbols: I could not find an easy way to have some symbols index, something which is provided for Haskell through simple tags support. I am pretty sure there is something out there…</li>
</ul>
<h3 id="devbox">Devbox</h3>
<p>I already discussed in a <a href="/posts/agile-startup.html">previous blog post</a> how we managed to do pair programming with a distributed team. One of the virtual machines we configured was our <em>devbox</em> which we used to do remote pairing and run experiments.</p>
<ul>
<li>The initial configuration was done in the VM. It was pretty complex, requiring setting up full Haskell and ClojureScript toolchain, correct Emacs configuration which means installing and configuring emacs packages in scripts, setting user authentications…</li>
<li>It worked quite well however, except for the time to spin up a box from scratch. We were able to develop our software using the same tools we had on our laptops, except the fancy windowing UI: Emacs works exactly in the same way in a (proper) terminal and in a Mac OS X Window, once you correctly configuring key mappings for tmux and emacs over ssh,</li>
<li>At some point we turned to a container-based configuration with a <em>fat</em> container providing full development environment, including an X server for UI testing. Setting up the VM was much simpler as it only required installing docker but the development image was pretty large (about 4GB) and this meant long download time when pulling the docker image from scratch. This environment provided a full-blown X server which means we could log into it through VNC. However, we lost interactivity of pairing as it was not possible to share connection to X server which actually means it was pretty much useless,</li>
<li>We reverted back to configuring the VM itself but this time we used images snapshot to be able to restore the box quickly,</li>
<li>We also pushed emacs configuration to a <a href="https://github.com/capital-match/cm-dotfiles/blob/master/.emacs">shared git repository</a> which is pulled when configuring the machine, something we should have done earlier of course.</li>
</ul>
<h1 id="discussion">Discussion</h1>
<h2 id="build-process">Build process</h2>
<p>In retrospect I think the biggest issue we faced while developing the platform and working on the dev and prod infrastructure was fighting back increase in <em>build time</em> as we were adding new features and services. Building a deployable container <em>from scratch</em>, including creation of the build machine, configuration of build tools, creation of the needed containers, download and build of dependencies, testing, packaging would take about 2 hours. Here is the breakdown of time for some of the build stages according to the CI:</p>
<table>
<thead>
<tr class="header">
<th>Test</th>
<th>Mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>IntegrationTest</td>
<td>7m51s</td>
</tr>
<tr class="even">
<td>EndToEndTest</td>
<td>7m05s</td>
</tr>
<tr class="odd">
<td>Compile</td>
<td>6m05s</td>
</tr>
<tr class="even">
<td>ParallelDeploy</td>
<td>1m12s</td>
</tr>
<tr class="odd">
<td>UITest</td>
<td>53.46s</td>
</tr>
</tbody>
</table>
<p>Even if tests are run in parallel, this means it takes more than 10 minutes to get to the point where we can deploy code. Actually, CI tells us our mean time to deployable is about 30 minutes, which is clearly an issue we need to tackle. To reduce build time there is no better way than splitting the system into smaller chunks, something the team has been working on for a few months now and is paying off at least by ensuring we can add feature without increasing build time! The next step would be to split the core application which currently contains more than 80 files into more services and components.</p>
<p>On the positive side:</p>
<ul>
<li>Shake provides a somewhat more robust and clearer make, removing cryptic syntax and reliance on shell scripts. All the build is concentrated in a single Haskell source file that requires few dependencies to be built,</li>
<li>Haskell build tooling has been steadily improving in last couple of years especially since stack has taken a prominent position. Stack does not remove dependency on cabal but it actually reduces it what cabal does best: Providing a simple, descriptive configuration for building single packages ; and provides a definitely better experience regarding dependency management, build reproducibility and managing multiple build configuration,</li>
<li>I am less happy with the ClojureScript and Javascript parts, probably because I am much less familiar with them, hence I won’t enter trolling mode,</li>
<li>Packaging build environments with docker greatly reduces development friction: Issues can be reproduced very easily against a reference environment. Developer’s freedom is not comprised: Everyone is free to configure her own environment with CI acting as final gatekeeper while making troubleshooting somewhat easy (grab image and run it locally to reproduce problems),</li>
<li>Using containers also makes onboarding of new developers somewhat easier: They can focus on a single part of the system (e.g. UI) and rely on the containers to run a consistent environment locally.</li>
</ul>
<h2 id="development-environment-1">Development Environment</h2>
<p>The single feature I miss from my former Java development environment is <em>refactoring</em>: The ability to safely rename, move, extract code fragments with a couple key strokes across the whole code base lowers the practical and psychological barrier to improve your code <strong>now</strong>. GHC (esp. with <code>-Wall -Werror</code> flags on) catches of course a whole lot more errors than Javac or gcc but the process of fixing compiler errors after some refactoring of a deeply nested core function is time consuming. On the other hand the lack of global refactoring capabilities is a strong incentive to modularize and encapsulate your code in small packages which can be compiled and even deployed independently.</p>
<blockquote>
<p>To be continued…</p>
</blockquote>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Notes on Failing to Understand Software Transactional Memory</title>
    <link href="http://abailly.github.io/posts/note-on-stm.html" />
    <id>http://abailly.github.io/posts/note-on-stm.html</id>
    <published>2016-05-22T00:00:00Z</published>
    <updated>2016-05-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Notes on Failing to Understand Software Transactional Memory</h1>

  <h2 class="subtitle"></h2>

<div class="info">Posted on May 22, 2016</div>

<p>I am writing some library to easily implement event sourced services in Haskell based on previous experience at Capital Match, and while doing so I rewrote a simple file-based event store. This store communicates with core service using <a href="https://hackage.haskell.org/package/stm-2.4.4.1/docs/Control-Concurrent-STM-TBQueue.html">TBQueue</a>, a bounded queue implemented over Haskell’s STM. It took me couple of hours on Friday to solve a <a href="http://hackage.haskell.org/package/base-4.8.2.0/docs/Control-Exception-Base.html#t:BlockedIndefinitelyOnSTM">BlockedIndefinitelyOnSTM</a> bug I was facing while testing this simple store. So today I posted a <a href="http://stackoverflow.com/questions/37376419/what-is-the-precise-reason-i-got-blocked-on-stm">question about STM</a> on Stack Overflow, as I did not have a clear intuition on why my code was failing, hence why my fix was correct.</p>
<p>The code of the store boils down to the following simple model.</p>
<p>First some useful imports…</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">{-# LANGUAGE ScopedTypeVariables #-}</span>
<span class="kw">module</span> <span class="dt">Main</span> <span class="kw">where</span>

<span class="kw">import           </span><span class="dt">Control.Concurrent.Async</span>
<span class="kw">import           </span><span class="dt">Control.Concurrent.STM</span>
<span class="kw">import           </span><span class="dt">Control.Exception</span>
<span class="kw">import           </span><span class="dt">Control.Monad</span>            (forever)
<span class="kw">import           </span><span class="dt">Hevents.Eff</span>
<span class="kw">import           </span><span class="dt">System.IO</span></code></pre></div>
<p>The store dequeues some <em>operation</em> from a given queue, writes the operation’s string to <code>stdout</code> then put back the length of the written string into a <a href="http://hackage.haskell.org/package/stm-2.4.4.1/docs/Control-Concurrent-STM-TMVar.html">TMVar</a>, which models communicating the result of the operation back to the caller.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Op</span> <span class="fu">=</span> <span class="dt">Op</span> <span class="dt">String</span> (<span class="dt">TMVar</span> <span class="dt">Int</span>)

<span class="ot">storerun ::</span> <span class="dt">TBQueue</span> <span class="dt">Op</span> <span class="ot">-&gt;</span> <span class="dt">IO</span> ()
storerun q <span class="fu">=</span> <span class="kw">do</span>
  h <span class="ot">&lt;-</span> openFile <span class="st">&quot;store.test&quot;</span> <span class="dt">ReadWriteMode</span>
  hSetBuffering h <span class="dt">NoBuffering</span>
  forever <span class="fu">$</span> <span class="kw">do</span>
    <span class="dt">Op</span> s v <span class="ot">&lt;-</span> atomically <span class="fu">$</span> readTBQueue q
    hPutStrLn h s
    atomically <span class="fu">$</span> putTMVar v (length s)</code></pre></div>
<p>The <code>main</code> function is responsible for creating the jobs queue, starting the “store” in a separate thread then reading lines from <code>stdin</code> and feeding them as “operations” for the store.</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">main ::</span> <span class="dt">IO</span> ()
main <span class="fu">=</span> <span class="kw">do</span>
  q <span class="ot">&lt;-</span> newTBQueueIO <span class="dv">100</span>
  _ <span class="ot">&lt;-</span> async <span class="fu">$</span> storerun q
  storeInput q
  <span class="kw">where</span>
    storeInput q <span class="fu">=</span> forever <span class="fu">$</span> <span class="kw">do</span>
      l <span class="ot">&lt;-</span> getLine
      v <span class="ot">&lt;-</span> newEmptyTMVarIO
      r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> <span class="kw">do</span>
        writeTBQueue q (<span class="dt">Op</span> l v)
        takeTMVar v</code></pre></div>
<p>This code deadlocks because STM are actually - surprise! - <strong>transactions</strong>: They do all of their operations, or nothing, and they are serialized. Hence the following block:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> <span class="kw">do</span>
  writeTBQueue q (<span class="dt">Op</span> l v)
  takeTMVar v</code></pre></div>
<p>…can succeeds <em>if and only if</em> it can <strong>atomically</strong> put an operation in the queue and read the result back from <code>v</code>. Which of course is not possible because the result is put back after the operation is read from the queue in another transaction. The correct code is:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">atomically <span class="fu">$</span> writeTBQueue q (<span class="dt">Op</span> l v)
r <span class="ot">&lt;-</span> atomically <span class="fu">$</span> takeTMVar v</code></pre></div>
<p>Pretty obvious, in retrospect. As the person who answered my question on SO, there is no way for two STM transactions to <em>exchange</em> information.</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>

</feed>
