<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Arnaud Bailly's  Blog</title>
    <link href="http://abailly.github.io/atom.xml" rel="self" />
    <link href="http://abailly.github.io" />
    <id>http://abailly.github.io/atom.xml</id>
    <author>
        <name>Arnaud Bailly</name>
        <email>arnaud@igitur.io</email>
    </author>
    <updated>2016-04-18T00:00:00Z</updated>
    <entry>
    <title>On &quot;Cakes, Custard + Category Theory&quot;</title>
    <link href="http://abailly.github.io/posts/cake-custard-category.html" />
    <id>http://abailly.github.io/posts/cake-custard-category.html</id>
    <published>2016-04-18T00:00:00Z</published>
    <updated>2016-04-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>On &quot;Cakes, Custard + Category Theory&quot;</h1>
<div class="info">Posted on April 18, 2016</div>

<p>I am not a mathematician, and this is probably the only regret of my life. When I was young I was too lazy to work seriously enough in High School to be accepted at one of the “Grandes Écoles”. Or rather I was way too much interested by role-playing games to spend time doing homework. And I must say maths were quite boring in High School and Preparatory School, not even talking about Business school’s math which barely went beyond basic arithmetics…</p>
<p>Things would probably have been quite different had I been taught math by <a href="http://www.eugeniacheng.com/">Eugenia Cheng</a>, the author of <a href="http://www.amazon.co.uk/Cakes-Custard-Category-Theory-understanding/dp/1781252874/ref=sr_1_1?ie=UTF8&amp;qid=1422244697&amp;sr=8-1&amp;keywords=eugenia+cheng">Cakes, Custard + Category Theory</a> and one of the presenter of the famous <a href="https://www.youtube.com/watch?v=9fohXBj2UEI&amp;list=PL0E91279846EC843E">Catsters</a> series, among <a href="http://liederstube.wix.com/home">other talents</a>.</p>
<p>I have read, or more precisely tried to read, <a href="https://www.cambridge.org/catalogue/catalogue.asp?isbn=9780521719162">many</a> <a href="http://www.maths.ed.ac.uk/~aar/papers/maclanecat.pdf">books</a> <a href="http://www.math.mcgill.ca/triples/Barr-Wells-ctcs.pdf">about</a> <a href="http://www.mpi-sws.org/~dreyer/courses/catlogic/awodey.pdf">category</a> <a href="http://ebooks.library.cornell.edu/cgi/t/text/text-idx?c=math;cc=math;view=toc;subview=short;idno=Gold010">theory</a> but I know I still only have an intuition about very basic things, e.g. what is a category theory, composition of morphisms, units, simple limits… The more abstract - and important - concepts (adjunctions, Yoneda lemma, topoi, sheaves…) are still inaccessible to my understanding: To state it in Eugenia’s terms, I <em>know</em> them but I don’t <em>understand</em> them.</p>
<p><em>Cakes, Custard + Category Theory</em> is a math books for non-mathematicians, a book that tries and - to my humble opinion - somehow succeeds in giving lay people some ideas on why maths are important, interesting and fascinating. More importantly it also succeeds in giving <em>intuitions</em> on what <em>is</em> math and category theory and on connecting the dull, formal and painful external aspect of maths most people see with the deep, complex, beautiful and sophisticated ideas behind that rude shell.</p>
<p>The book is divided in two parts, <em>Mathematics</em> and <em>Category Theory</em> which shares a common underlying structure: Each small chapter is introduced by the <em>recipe</em> of some cake, some classical and some invented by the author, and each part ends with a tentative explanation of <em>what</em> is math or category theory. Through the various chapters, Eugenia threads mundane life examples, recipes, cooking metaphors with actual mathematical questions in order to convey to the reader intuitions on what things like monoids, groups, morphisms, associativity or equivalence are. Mathematical notations is mostly restricted to sidebars and does not clutter reading.</p>
<p>I am not usually a great fan of analogies which more often than not obscure rather than illuminate the thing they are supposed to explain. But this book is written in a such a way that it mostly avoids this pitfall<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>:</p>
<ul>
<li>Eugenia’s style is so lively and entertaining one cannot but avidly read the book and reach for the next chapter till the end,</li>
<li>She manages to <em>motivate</em> mathematics, not as a mere tool one uses to solve more or less complex problems, but as a way to ask profound questions about the way we think and the world we live in.</li>
</ul>
<p>The key question in maths and category theory is then not <em>how</em> but <em>why</em>.</p>
<blockquote>
<p>Proof has a sociological role ; illumination has a personal role. Proof is what convinces society ; illumination is what convinces us. In a way, mathematics is like an emotion, which can’t ever be described precisely in words - it’s something that happens inside an individual. What we write down is merely a language for communicating those ideas to others, in the hope they will be able to reconstruct the feeling in their own mind.</p>
</blockquote>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Although I myself enjoy cooking very much, I was not that much convinced about the whole recipe meme…<a href="#fnref1">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>A Personal Retrospective</title>
    <link href="http://abailly.github.io/posts/personal-retrospective.html" />
    <id>http://abailly.github.io/posts/personal-retrospective.html</id>
    <published>2016-04-12T00:00:00Z</published>
    <updated>2016-04-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>A Personal Retrospective</h1>
<div class="info">Posted on April 12, 2016</div>

<p>From August 2014 to April 2016 I have been working as CTO of a startup based in Singapore, developing a peer-to-peer lending platform using Haskell programming language and environment. This experience has now come to an end and this short blog post is a way for me to look back at those 20 months and reflect on the things I have learnt. I have some vague hopes this experience might be useful to others. But the main goal is for me to make explicit things that have stayed mostly implicit in order to ensure I can benefit from my own experience.</p>
<h1 id="haskell-rocks">Haskell Rocks</h1>
<p>Nothing new under the sun but working 120% of the time in Haskell over (nearly) the whole stack of our system really reinforced that belief. The point is, Haskell is not only awesome because of its own merits as a language and a platform. After all, Haskell is a language that is <a href="https://en.wikipedia.org/wiki/Haskell_%28programming_language%29#History">about 30 years old</a> and since its inception has mostly been confined in academic circles. This is apparent in some weaknesses in the build system, standard data types like Strings and numbers, lack of support for first-class modules…</p>
<p>Those deficiencies are compensated by a simple<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> yet powerful type-system, a vibrant eco-system of good to great libraries providing all the features one needs, a state-of-the-art compiler producing efficient programs, built-in support for powerful concurrency features… I think Gabriel Gonzalez’ <a href="http://www.haskellforall.com/2016/04/worst-practices-should-be-hard.html">Worst practices should be hard</a> offers some more solid arguments in favour of Haskell.</p>
<p>What sets Haskell apart is the fact that chosing to make it your core technology attracts interesting people. This is one of the effect mentionned by Paul Graham of using non-<a href="http://www.paulgraham.com/avg.html">Blub</a> languages: Not using a mainstream language attracts non-mainstream people. <a href="http://bos.github.io/strange-loop-2011/talk/talk.html">Bryan O’Sullivan</a> of<a href="http://book.realworldhaskell.org/">Real World Haskell</a> book fame also highlighted this point: In a world flooded by noise, Haskell acts as a signal.</p>
<p>This does not mean that there aren’t great people working in Java, Javascript or Php<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. And this does not mean I would like to work with any Haskeller just because she is a Haskeller. But from my experience hiring people, I found Haskell acted like an effective filter<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>: People who cared to answer job ads or reach out the company to enquire for job openings were more often than not <em>interesting</em>. They were more diverse<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> (different countries, different ages, different professional experiences…), more curious, more motivated and for those whom I had a chance to pair with, quite good at programming.</p>
<h1 id="tdd-rocks">TDD Rocks</h1>
<p>I have always been a strong proponent of <a href="/posts/tdd.html">Test Driven Development</a>. After all these years this practice is <a href="http://david.heinemeierhansson.com/2014/tdd-is-dead-long-live-testing.html">still</a> <a href="http://iansommerville.com/systems-software-and-technology/giving-up-on-test-first-development/">controversial</a> mostly because people conflate two different things: “writing regression tests” and “using tests to guide your design”, a confusion which is caused by the use of <em>Test</em> in Test-Driven Development. In a nutshell, one needs a very different mindset to jump from “I write tests to verify my program does what I intend it to do, now and in the future” to “I write executable specifications in order to ensure 1/ I understand the problem and 2/ my program does exactly what’s intended, no more, no less”.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> The former mindset usually leads to so-called white-box tests which are thorough but brittle and painful to maintain.</p>
<p>Even within the Haskell community TDD is not widely accepted as a standard practice of development. I personally think Haskell is a really great fit for TDD if you take it in a broad sense, that is if you include all the tools the language and platform provide as part of your TDD cycle. This means leveraging the interpreter, compiler, type-checker and test runner to shorten the feedback loop.</p>
<p>Maintaining tests require (a lot of) effort and discipline, and it is tempting when pressed to deliver to cut corners. And I sometimes have done it myself: Comment out an flaky test in order to stabilize build. But except in one occasion, I have always come back to it later and reinstate it. These efforts really pay off in the long run, when you start adding features upon features, when the complexity of the system becomes too important to “fit in your head”, when you need to modify existing features or extend them to cope with new behaviours. TDD gives you both a safety net - so that it breaks when you change your code and highlights other parts of the system that need to be adapted - and a guide on current behaviour of the code.</p>
<h1 id="remote-development-works">Remote Development Works</h1>
<p>Although the company’s business is exclusively located in Singapore I never lived there and we started working remotely, me in France and my partner in Singapore. The development team has been distributed for almost all of the past 20 months, with people in England, Portugal, India, Poland and Malaysia (not all at the same time). And we managed to develop a platform that handles a modest load but has been working reliably managing financial and personal data since March 2015, steadily adding features, fixing bugs, deploying new versions several times a week or even a day, building and maintaining build and production infrastructure…</p>
<p>We used some simple form of agile methodology with daily “standup” meetings that allowed us to talk to each other at least once a day, strict automated tests, continuous integration and frequent releases. This made it possible to have rapid feedback from business people even if I was not sitting in the same room most of the time. We exposed our work process through Trello, used communication tools like Slack, Hangout, Skype, and tried a few others, and we managed to build a consensus across the whole development team on what was going on and what we had to do. We even manage to <a href="https://pragprog.com/book/jkrp/remote-pairing">pair program</a> on a somewhat regular basis.</p>
<p>As already advocated in <a href="https://37signals.com/remote">Remote</a> book, working remotely works under some conditions:</p>
<ul>
<li><em>Distribute whole team</em>: Having most of the team colocated with one or two persons distributed does not work,</li>
<li><em>Trust the people</em>: You have to trust each other and assume everybody is doing his or her best,</li>
<li><em>Communicate constantly</em>: You have to be very explicit about what you are doing, even if working alone, and you have to constantly try to detect and solve potential conflicts, misinterpretations, misunderstandings that could quickly degenerate,</li>
<li><em>Use the right tools</em>: Emails are a useful tool but one which is often abused<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>, we need “hotter” media like chat, video/phone…</li>
</ul>
<p><a href="https://open.buffer.com/">Buffer</a> is a good example of a company that has chosen to be fully distributed and is very transparent on how it works on a daily basis.</p>
<h1 id="but-it-needs-energy">… But it needs energy</h1>
<p>While keeping in touch with development team was always easy, doing same on the business side quickly became very hard. This is of course related to the very localized nature of the business the company was doing, but also to different background and maturity with respect to remote working. Remote working is definitely a viable option for software development as the success of a lot of world-spanning open-source projects has demonstrated.</p>
<p>As I advocated above, working effectively as a remote team needs some requirements to be met. But even if those requirements are met, it still can fail if people are not trained and do not make the mental leap to make it work. It might be possible that developers, having to deal constantly with abstractions, networks, virtualities, are more prone to make that leap. Once you consider it normal to work on machines located in a data center 10000 kms away, it is a small feat to consider normal to work with another developer located 10000 kms away. The network becomes an extension to standard Earth geography and there is a form of excitement in the way modern technology allows us to break distance barriers<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>.</p>
<p>Unfortunately, this particular mindset is not widespread among people practicing other trades. “Business people” who don’t need to interact constantly with developers quickly lose grasp and stop putting energy in maintaining a communication link that’s not obvious to them. The whole zoo of tools we are using appears daunting when compared with the simplicity of Outlook and Excel. When one has a lot more face-to-face interactions than online ones, she or he is quite prone to drop the latter in favour of the former. Note that working as a distributed team is <em>not</em> to be equated with working <em>remotely</em>. Obviously, organizations have been distributed for a long time: Businesses are used to employ people like salespersons who largely work remotely or to have various business units all over the planet. But this is different from the kind of real-time cooperation and interactions one needs when developing software and working as a distributed team.</p>
<h1 id="takeaways">Takeaways</h1>
<p>You can’t summarize 20 months of your life in a couple of bullet points and I definitely think this experience was amazing and has changed my life and the way I envision my work in a very deep way:</p>
<ul>
<li>Working as team remotely can be both satisfying and efficient when done properly,</li>
<li>Working with people from diverse origins and nationalities in a foreign setting is exciting<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>, and travelling to work with those people occasionally is the best way to discover local culture,</li>
<li>Haskell is <em>really</em> practical for large-ish systems development.</li>
</ul>
<p><strong>Afterwords</strong>: Many thanks to Cédric and Éric for their feedback on this small piece.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Yes, simple when compared with something like Scala’s or C++ type system. Haskell’s type system only uses a few key concepts that can be rather easily understood and explained and which allow you to build powerful abstractions on top of it without resorting to syntax-directed tricks (e.g. macros).<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>I personally know quite a few of them…<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Of course, there is still the possibility this was just another way of selecting like minded people thus implicitly rejecting genuine <em>diversity</em><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>With the notable exception of gender diversity: Over the 50+ person I interviewed I have had a single woman.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>For a good rebutal of the previous arguments, see <a href="http://blog.cleancoder.com/uncle-bob/2016/03/19/GivingUpOnTDD.html">Uncle Bob</a>’s reply to the “Giving up on TDD” post.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Emails are terrible for discussions - exchanging and/or arguing over some more or less complex point - or task tracking - maintaining and updating status of some work in progress - yet they are unfortunately often used that way.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>As people dealing with technology we might also be keener to fall to its trap and seductive power.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Having to make yourself understood in a language (English) which is not the mother tongue of any of the people you work with is sometimes frustrating, but always interesting. In can provide some natural dampening of feelings and emotions that cannot fail to crop up in any collective endeavour.<a href="#fnref8">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Anatomy of a Haskell-based Application</title>
    <link href="http://abailly.github.io/posts/cm-arch-design.html" />
    <id>http://abailly.github.io/posts/cm-arch-design.html</id>
    <published>2015-11-16T00:00:00Z</published>
    <updated>2015-11-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Anatomy of a Haskell-based Application</h1>
<div class="info">Posted on November 16, 2015</div>

<p>This is the first post of a series I am planning to write about my experience developing software as CTO of <a href="http://www.capital-match.com">Capital Match</a>, a Singapore-based startup providing a peer-to-peer lending marketplace for Small and Medium Businesses and private and corporate investor.</p>
<p>This post is about the design and architecture of the system itself, the choices and tradeoffs that were made, whether good or bad. In the conclusion I try to provide an assessment of the current situation and reflect on those choices.</p>
<h1 id="fundamental-design-choices">Fundamental Design Choices</h1>
<h2 id="haskell">Haskell</h2>
<p>Basing Capital Match’s tech stack on Haskell was an obvious choice for me from the onset, even if I had had limited professional experience with Haskell before that:</p>
<ul>
<li>Haskell is a <a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/history-of-haskell/">very mature language</a> with a <a href="https://www.haskell.org/ghc/">state-of-the-art compiler</a> that receives constant attention from a bunch of extremely bright people and thus keeps improving and evolving,</li>
<li>Haskell’s tools for building robust web-based applications is not as mature as what you can find in Java or .Net worlds but it is evolving quickly as the platform is gaining traction thanks to efforts from both a vibrant <a href="https://wiki.haskell.org/Haskell_Communities_and_Activities_Report">community</a> and few but dedicated <a href="https://github.com/commercialhaskell">private bodies</a>,</li>
<li>Haskell developers are few and far between, but their number is growing and they are more often than not passionate and talented,</li>
<li>I have been programming for fun and small side projects in Haskell since 2002 and I always have wanted to know how it would feel to build a whole system with it. Now I know,</li>
<li>Because it enforces a strict separation of pure and effectful code, Haskell incentivizes the growth of a <a href="http://alistair.cockburn.us/Hexagonal+architecture">Hexagonal Architectures</a> aka. <a href="http://c2.com/cgi/wiki?PortsAndAdaptersArchitecture">Ports and adapter</a>: A pure domain kernel which interacts with the outside world through <em>adapters</em>.</li>
</ul>
<h2 id="event-sourcing">Event Sourcing</h2>
<p>The system was designed from the onset as an <a href="http://martinfowler.com/eaaDev/EventSourcing.html">event-sourced</a> application: The source of truth in the system is a sequence of <em>events</em> where each event defines a transition between two states. At any point in time, the state of the system is thus whatever state the current sequence of events leads to. Among the motivations behind using ES are:</p>
<ul>
<li>Having fun and explore this corner of the design space instead of going for the more traditional RDBMS-based web app,</li>
<li>Auditability and traceability of all actions impacting data on the platform, a property which is highly-desirable in a banking-like system. I have had previous exposure to finance software and they all end up implementing some journalling system to trace users actions and data changes,</li>
<li>Reluctance to add the operational burden of maintaining a RDBMS as part of the system. We could have used SaaS relational (or non-relational) database to remove that burden but this implies using yet another tool, learning some other piece of technology, using some set of drivers with specific bugs and requirements,</li>
<li>Personal bias against RDBMS used as runtime storage<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>,</li>
<li>Simplicity of implementation, at least when you don’t require HA, partition tolerance or more generally fault-tolerance: A single file to which all events are appended is enough, and this is exactly what we do,</li>
<li>Avoiding languages impedance mismatch. There is the tradional <a href="http://c2.com/cgi/wiki?ObjectRelationalImpedanceMismatch">Object-relational Impedance Mismatch</a> although <a href="http://blog.jooq.org/2015/08/26/there-is-no-such-thing-as-object-relational-impedance-mismatch/">some have argued</a> it is not where we usually think it is. As argued in the latter I think the real issue is in SQL: SQL is (probably) great for writing complex queries<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> but not so much for inserting data.</li>
</ul>
<h1 id="architecture">Architecture</h1>
<p>The main interface to the system is a REST-like API providing various resources and actions over those resources. Most exchanges with the outside world are done using JSON representation of resources, with some CSV. The <em>User Interface</em> is merely a client of the API and is (morally if not to the letter) a single page application. There is also a command-line client which offers access to the complete API and is used for administrative purpose.</p>
<h2 id="models">Models</h2>
<p>The core of the application is purely functional and made of several loosely coupled <code>BusinessModel</code> instances (think Aggregates in <a href="https://en.wikipedia.org/wiki/Domain-driven_design">DDD</a> parlance) that each manage a specific sub-domain: <code>Accounting</code> manages accounts and transactions, <code>Facility</code> manages facilities lifecycle, <code>Investor</code> and <code>Borrower</code> manage profiles and roles-dependent data, <code>User</code> manages basic registration, authentication and settings for users (e.g. features)…</p>
<p>A <code>BusinessModel</code> is defined as:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">class</span> <span class="dt">BusinessModel</span> a <span class="kw">where</span>
  <span class="kw">data</span> <span class="dt">Event</span><span class="ot"> a ::</span> <span class="fu">*</span>
  <span class="kw">data</span> <span class="dt">Command</span><span class="ot"> a ::</span> <span class="fu">*</span>
<span class="ot">  init ::</span> a
<span class="ot">  act ::</span> <span class="dt">Command</span> a <span class="ot">-&gt;</span> a <span class="ot">-&gt;</span> <span class="dt">Event</span> a
<span class="ot">  apply ::</span> <span class="dt">Event</span> a <span class="ot">-&gt;</span> a  <span class="ot">-&gt;</span> a</code></pre></div>
<ul>
<li>A type of events this model generates</li>
<li>A type of commands this model can process</li>
<li>An initial value for the model</li>
<li>A pair of functions describing which event is generated by a command <em>acting</em> on the model and how an event changes the model when it is <em>applied</em> to it</li>
</ul>
<p>The state of each BusinessModel instance is computed upon application startup by loading all the events and applying each stored event to an <code>init</code>ialised model. Models are then kept in memory while events are stored persistently. This initial startup process takes a couple of seconds given the small scale at which we operate.</p>
<p>Each model demarcates transactional boundaries and is the unit of consistency within the system. Commands and events on a single model are assumed to occur <em>sequentially</em>.</p>
<h2 id="services">Services</h2>
<p>Above <code>BusinessModel</code>s are <code>Service</code>s which provides the interface to the system. Services orchestrate the interactions of one or more Models. At the simplest level, a <code>Service</code> simply consists in the application of a single <code>Command</code> on some <code>BusinessModel</code>, but it can be more complex, synchronizing application of commands over several models. Based on the ideas exposed in <a href="http://adrianmarriott.net/logosroot/papers/LifeBeyondTxns.pdf">Life Beyond Distributed Transactions</a>, a <code>Service</code> represents the state of the interaction between a single user of the system, e.g. a request, and one or more piece of data maintained by the system.</p>
<p>Because they are the agents of the outside world in the system, <code>Service</code>s operates in an impure context, hence in a dedicated <code>Monad</code> called <code>WebM</code>. Services typically return some representable type, when they are queries, or an <code>Event</code> denoting the outcome of the request. <code>WebM</code> is actually an instance of a monad transformer <code>WebStateM</code> over IO, hence it is impure. It has access to 2 pieces of state.</p>
<p>Here is the definition of <code>WebStateM</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">WebStateM</span> shared local m a <span class="fu">=</span> <span class="dt">WebStateM</span> {<span class="ot"> runWebM ::</span> <span class="dt">TVar</span> shared <span class="ot">-&gt;</span> local <span class="ot">-&gt;</span> m a }

<span class="kw">type</span> <span class="dt">WebM</span> a <span class="fu">=</span> forall s <span class="fu">.</span> <span class="dt">EventStore</span> s <span class="ot">=&gt;</span> <span class="dt">WebStateM</span> <span class="dt">SharedState</span> <span class="dt">LocalState</span> s a</code></pre></div>
<p>This is simply a <code>Reader</code> monad with two different pieces of data:</p>
<ul>
<li><code>LocalState</code> is filled with information relevant to a single query (e.g. user id, request id, time…),</li>
<li><code>SharedState</code> is a <code>TVar</code> (transaction variable living in <code>STM</code> monad) that is shared across all requests,</li>
<li>The <code>EventStore</code> constraint means we need the underlying monad to provide access to persistent storage.</li>
</ul>
<p>The vast majority of services use the generic <code>applyCommand</code> function which is the critical part of the system. This function is responsible for:</p>
<ul>
<li>applying the command and updating the stored Model,</li>
<li>persist the event in the “database”,</li>
<li>dispatch the event to interested components.</li>
</ul>
<h2 id="web">Web</h2>
<p>The REST interface is provided by <a href="https://github.com/scotty-web/scotty">scotty</a> which is a simple framework based on <a href="https://github.com/yesodweb/wai">WAI</a> and <a href="https://github.com/yesodweb/wai">warp</a><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>. Most action handlers are pretty simple:</p>
<ul>
<li>They extract some parameters or JSON data from the body of the request,</li>
<li>They invoke some service,</li>
<li>They provide an HTTP response according to the result returned:
<ul>
<li>Queries simply serialize the result to JSON or other requested media type,</li>
<li>Actions look at the returned <code>Event</code> to provide meaningful answers.</li>
</ul></li>
</ul>
<p>On top of REST endpoints sit some <code>Middleware</code>s which check or apply transformations to requests and/or responses:</p>
<ul>
<li>Provide a <code>Request-Id</code> header,</li>
<li>Authorisation and authentication,</li>
<li>Sanity checks (e.g. sizes of payloads),</li>
<li>Logging,</li>
<li>Caching and static data service.</li>
</ul>
<h2 id="lost-in-translation">Lost in Translation</h2>
<p>Executing a user-triggered action is in a sense a series of translations occuring between different <em>level of languages</em>:</p>
<ul>
<li>From REST to <code>WebM</code> we use <code>inWeb :: WebStateM CapitalMatchState LocalState m a -&gt; ActionT e (WebStateM CapitalMatchState   LocalState m) a</code>,</li>
<li>From <code>WebM</code> to <code>STM Model</code> we use <code>liftIO . atomically</code>,</li>
<li>… and finally in <code>Model</code> we reach the pure kernel of the business domain!</li>
</ul>
<p>Conceptually, we have this hierarchy of monads, expressed in types:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">model ::</span> <span class="dt">Command</span> <span class="ot">-&gt;</span> <span class="dt">StateT</span> <span class="dt">STM</span> <span class="dt">Model</span> (<span class="dt">Event</span> <span class="dt">Model</span>)
<span class="ot">service ::</span> <span class="dt">WebM</span> (<span class="dt">Event</span> <span class="dt">Model</span>)
<span class="ot">web ::</span> <span class="dt">ActionT</span> ()</code></pre></div>
<p>This hierarchy of monads delineates, somewhat obviously, the following languages:</p>
<ul>
<li>Language of <em>Models</em> expresses atomic (e.g. often CRUDesque) changes to a Model, like <code>RegisterTransaction</code>, <code>UpdateProfile</code> or <code>CloseFacility</code>,</li>
<li>Language of <em>Services</em> expresses either direct changes to Models or more complex interactions like <code>addPledge</code> or <code>acceptFacility</code> which require more than one command to complete,</li>
<li>Language of <em>Web</em> manages HTTP Requests and responses, JSON structures and delegate work to services. It is the language of representation of things.</li>
</ul>
<h1 id="cross-cutting-concerns">Cross-cutting Concerns</h1>
<h2 id="concurrency">Concurrency</h2>
<p>Concurrency is mostly handled at the REST layer through Warp and Scotty: Each request is handled concurrently by separate threads which are <a href="https://ghc.haskell.org/trac/ghc/wiki/LightweightConcurrency">very lightweight in Haskell/GHC</a>. On top of that we have a couple more threads in the application:</p>
<ul>
<li>One logging thread per handler (currently 2), which handle logging messages,</li>
<li>A storage thread which handle low-level read/write requests to events file,</li>
<li>A driver thread which handle events storage<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>,</li>
<li>A <em>Heartbeat</em> thread periodically checks other threads and notifies health.</li>
</ul>
<p>We used to run directly threads with <code>forkIO</code> and friends but finally moved to something simpler and much more robust: The <a href="http://hackage.org/packages/async">async</a> package. Concurrent updates to the model are handled through <a href="http://hackage.org/packages/stm">Software Transactional Memory</a>: A <code>TVar</code> (transactional variable) holds a reference to the state and all operations on the state are thus transactional.</p>
<p>The initial goal was to enforce a strict separation between the various <em>Business Models</em> with an eye towards being able to deploy them as independent services exchange messages. But it happened this rule was broken more than once and a few months later we ended up having built a monolith with uncontrolled dependencies across domains and layers. We then undertook the necessary refactoring steps to get back to a “saner” state where <code>STM</code> transactions operate at the level of a single <code>Command</code> through the <code>applyCommand</code> function.</p>
<h2 id="persistence-and-storage">Persistence and Storage</h2>
<p>Persistence is managed through a dedicated event bus: <code>Event</code> are first packaged into a more opaque <code>StoredEvent</code> object containing metadata useful for traceability of the system:</p>
<ul>
<li>An event version (more on this later)</li>
<li>An event type which encodes at the value level the actual type of event</li>
<li>Timestamp (in UTC)</li>
<li>ID of user generating the event</li>
<li>ID of original request</li>
<li>SHA1 of commit, e.g. version of the code (thanks to <a href="http://geoffroycouprie.com/">Geoffroy Couprie</a> for the suggestion)</li>
<li><code>ByteString</code> payload containing serialized version of the event</li>
</ul>
<p>Then <code>StoredEvent</code>s are pushed to a dedicated <code>Driver</code> thread which stores events in the underlying events file. Physical <code>Storage</code> is a simple append-only file which contains sequence of applied events serialized to some binary format (<a href="http://kafka.apache.org">Kafka</a>-like). We are in the process of moving to a much more robust storage solution:</p>
<ul>
<li>externalize data store to another process/host,</li>
<li>replicate it to increase fault-tolerance,</li>
<li>provide strong consistency through distributed consensus.</li>
</ul>
<h3 id="event-versioning">Event Versioning</h3>
<p>Events are stored with a <em>version</em> number which is a monotonically increasing number. This version number is bumped each time we change the structure of our events, e.g. adding a field to some record, changing a field’s type… When an event is persisted, it contains the <em>current version</em> number that’s defined in the application at that time. When the event is read back (i.e. deserialized) to rebuild the state of the system, this version number is used to select the correct read function.</p>
<p>Hence modifying the structure of events always entails the following steps in development:</p>
<ul>
<li>Write deserialization test for current version number<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>,</li>
<li>Bump version number,</li>
<li>Write new code,</li>
<li>Write <em>migration code</em> to adapt old events to new version.</li>
</ul>
<p>This mechanism adds some interesting properties to our underlying storage:</p>
<ul>
<li>Stored events are immutable hence storage system is append-only: We never need to rewrite past events,</li>
<li>It is possible to rebuilt state of the system (code <em>and</em> data) at any point in the past.</li>
</ul>
<h2 id="user-interface">User Interface</h2>
<p>UI code still lives partly in the server and partly as pure client-side code:</p>
<ul>
<li>HTML code is generated and served by the server using standard endpoints according to <code>Accept</code> header in request. We use <a href="https://hackage.haskell.org/package/blaze-html">blaze-html</a> combinators to describe the pages in Haskell,</li>
<li>Static assets are served by <a href="https://hackage.haskell.org/package/wai-middleware-static">wai-middleware-static</a></li>
</ul>
<p>But the grunt of UI work is done on the client with <a href="https://github.com/omcljs/om/">Om</a>. Om is a <a href="http://github.com/clojure/clojurescript">clojurescript</a> interface to Facebook’s <a href="http://facebook.github.io/react/">React</a><a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>. We treat the UI-backend interaction as a pure client-server: UI maintains its own state and interact with server through usual Ajax calls, updating state accordingly. The interface a user sees is a single-page application.</p>
<h2 id="logging-and-monitoring">Logging and Monitoring</h2>
<p>There is a <code>Log</code> structure which is a queue consuming logging events and handling it according to some function. We log all queries, all commands issued and various other events occuring in the system: application startup/stop, heartbeat, I/O errors, storage events… In order to prevent sensitive data to leak to logging, we have a <code>redact</code> function that rewrites commands to remove those data before passing it to logging system.</p>
<p>We currently have two different log backends:</p>
<ul>
<li>One log handler outputs JSON-formatted events to <code>stdout</code>,</li>
<li>One log handler outputs some events to <a href="http://riemann.io">Riemann</a>, using <a href="https://github.com/tel/riemann-hs">riemann-hs</a>. Those events are then used for notification and monitoring of infrastructure (more on this in a later post).</li>
</ul>
<p>At startup of application we also notify dev team by sending an email with the configuration. This is useful to check startup of production environment, as this email contains among other things the version of the application and the command line with which is has been started.</p>
<h1 id="reflection">Reflection</h1>
<p>It’s been a bit over a year since I have started working on Capital Match’s platform. I – we – have made mistakes, not everything went as smoothly as we would have liked and it is still just the beginning of a hopefully long adventure. One year is a good time to stop - or slow down a bit - and reflect on what’s been accomplished, what went wrong and what went well. In the next sections I try to provide a more or less objective assessment of the architecture we have put in place, and what would be our next steps.</p>
<h2 id="the-good-the-bad-and-the-ugly">The Good, the Bad and the Ugly</h2>
<p>We have been live since March 2015, serving more than S$ 3 millions - and counting - in facilities for SMEs in Singapore without any major interruption of service. This in itself is an extremely positive fact: It works and it supports continuous improvements in a smooth way<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>.</p>
<p>Here are some benefits I see in our approach, encompassing both the technology used (Haskell, Om/Clojurescript) and the architecture:</p>
<ul>
<li>Strong and expressive types greatly improves confidence in the code<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>. Among the <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghc-language-features.html">many features</a> supported by GHC, here are the ones, mostly simple and straightforward, we use routinely:
<ul>
<li><code>newtype</code>s are cheap in Haskell, being unpacked at runtime, but they are enforced during compilation and makes for very expressive signatures: No more <code>String</code>-based programs but <code>UserId</code>, <code>PassportNr</code> or <code>EMail</code>,</li>
<li>Phantom types is a simple technique to distinguish between various objects with equivalent representations, like encoding of a <code>ByteString</code>,</li>
<li>Type-classes are very useful to define interfaces, possibly with default implementations. Most of the time we use <code>MultiParamTypeClasses</code> to express relations between different part of the systems,</li>
<li>Existential types are useful to <em>pack</em> related things under a common opaque type for e.g. serialization or logging, where you don’t care about the details,</li>
<li>But most of the time using a simple type with a set of constructors is clearer.</li>
</ul></li>
<li>We use <code>-Wall -Werror</code> for compiling code which catches things like unused variables (dead code), variable names overriding (potential troubles), incomplete pattern matching (runtime failure ahead…),</li>
<li>Event Sourcing greatly simplifies storage management and removes all the hassle of having to manage data types mapping to a relational model, not speaking of managing migration between versions or the burden of operating a DBMS,</li>
<li>Because data is stored as a flat file of versioned events, querying the system can be done directly in Haskell: Retrieve event stream, build in-memory state from it then use GHCi or Emacs REPL to manipulate state<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> at your will. Over time we have written a number of <em>scripts</em> that are small Haskell programs implementing complex queries (e.g. user funnel) or programmatic one-shot transformations of data,</li>
<li>Scotty, WAI and Warp makes it easy to quickly develop and maintain REST interfaces, both for endpoints and middlewares.</li>
</ul>
<p>Here are some mistakes I made:</p>
<ul>
<li>Too many use of partial functions like <code>fromJust</code> or even <code>head</code>: This makes things simple at first but of course blows up at runtime. Lesson learned: Always use <strong>total functions</strong>,</li>
<li>Too many typeclasses: This might come from my Java background where using an interface is usually a good idea to abstract details. Over the time, we have created new typeclasses to answer to express new behaviour, which clutters types,</li>
<li>Not taking enough care to keep compilation time low: Our application has grown over time, and I have not taken care of splitting it early enough to prevent bloat. Compilation time has grown over time to the point where it is now a problem. Lesson learned: Aggressively split code as early as possible, and don’t be afraid of having packages with one or two files,</li>
<li>Too much reliance on <code>DeriveGeneric</code> based JSON serialization: Generating <code>Generic</code> instance for large types dramatically increases compilation time. Lesson learnt: Use more <code>TemplateHaskell</code> derivation or custom <code>ToJSON/FromJSON</code> instances which provide better flexibility<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a></li>
<li>Having data accessible only through Haskell implies non-tech people either need to learn it or go through the dev team to get data. This is not too much of a trouble in a very small team but could quickly become a problem as the company grows. This is where <a href="http://martinfowler.com/bliki/CQRS.html">CQRS</a> will nicely complement our Event Sourced system: It is a rather simple matter to build one or more relational models from our data and ensure the RDBMS is updated on a regular basis,</li>
<li>Separation of concerns among the various business models has been sloppier over time, leading to too much coupling among the models,</li>
<li>Events are not invertible which means that one cannot travel back and forth in an event stream easily to select required state,</li>
<li>Generating HTML on the server-side: At the onset of the project, we had a static HTML file. We moved to server-side HTML generation using Blaze because we wanted to be able to control the structure of the HTML:
<ul>
<li>To cope for dev/prod environment on the front-end: Code is compiled and optimized differently in the two modes and this requires importing a different set of scripts,</li>
<li>To manage <em>feature toggles</em> which allow us to provide a different UI for different users according to their account’s settings. This was very useful to handle gracefully migration of our UI,</li>
<li>However this strategy entails a number of problems:
<ul>
<li>You sometimes have to recompile server when working on the UI, e.g. when changing structure of pages or handling of features,</li>
<li>It’s hard to collaborate with front-end designers and developers,</li>
<li>It makes UI and server more coupled,</li>
</ul></li>
</ul></li>
<li>REST interface seems to be growing too quickly. There are some query abstractions that should be developed out of the raw endpoints we are exposing.</li>
</ul>
<h2 id="whats-next">What’s Next?</h2>
<p>Within the span of a single year, much has happened in the Haskell ecosystem and things that were experimental or unwieldy one year ago are now mature and could easily make their way to production: <a href="https://github.com/ghcjs/ghcjs">ghcjs</a> is now much easier to build and work with, there are more mature solutions in the front-end like <a href="https://github.com/ryantrinkle/reflex">reflex</a>, build has never been easier thanks to <a href="https://github.com/commercialhaskell/stack/">stack</a>, <a href="https://downloads.haskell.org/~ghc/7.10.1/docs/html/users_guide/release-7-10-1.html">GHC 7.10</a> has brought a number of improvements (and controversial breaking changes like the TAP proposal)… Gabriel Gonzalez maintains a <a href="http://www.haskellforall.com/2015/08/state-of-haskell-ecosystem-august-2015.html">State of Haskell Ecosystem</a> page that provides interesting overview of what’s hot and what’s not in the Haskell world.</p>
<p>Here are some major challenges that lie ahead of us to improve our system:</p>
<ul>
<li><strong>Services</strong>: In spite of good initial intention we still have built a monolith, albeit a small one and one that will be not too hard to split. We now want to increase robustness, resilience and scalability of our development process and our system by breaking the monolith into components services. We are in the process of splitting the application into smaller constituents along the following lines:</li>
<li>Glue code to wire things together in a single app,</li>
<li>Support code,</li>
<li>One component per group of related services,</li>
<li>One component per “Model”, possibly clustered,</li>
<li>Ideally each component should be deployable independently or alongside other components in the same process depending on needed granularity and redundancy. This can be achieved easily through configuration at the level of the glue code according to some topology configuration.</li>
<li><strong>Performance</strong>: I tried to follow this simple development principle: <a href="http://c2.com/cgi/wiki?MakeItWorkMakeItRightMakeItFast">Make it, make it right, make it fast</a>. We mostly are done with the first part and are quite advanced on the second, so making it fast will be our next challenge especially as user base and data set grow in size. There are quite a few areas of improvement on the front: Caching computations, better data structures, improve strictness in key areas… But of course the first step will be to measure and set goals for those performance improvements.</li>
<li><strong>Robustness</strong>: No system is ever safe from failure but it depends on us what the impact of a failure is. This is definitely a must-have and something we can improve using standard replication and redundancy techniques. Splitting the system in finer-grained components is a first step towards that goal but we need specific components to ensure consistency in presence of failure.</li>
</ul>
<h1 id="conclusion">Conclusion</h1>
<p>This article is already quite long yet it is only a brief overview of our system: It is hard to summarize one year of intense work! In future installments of this blog post series I plan to address other aspects of the system that were not covered here: Development and production infrastructure, user interface development from the point of view of a backend developer, development process.</p>
<p>As a final note, my highest gratitude goes to the following persons without the help of whom this adventure would not have been possible: Pawel Kuznicki, Chun Dong Chau, Pete Bonee, Willem van den Ende, Carlos Cunha, Guo Liang “Sark” Oon, Amar Potghan, Konrad Tomaszewski and all the great people at <a href="http://www.capital-match.com">Capital Match</a>. I also would like to thank Corentin Roux-dit-Buisson, Neil Mitchell, Joey Hess for their support and feedback.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I have been using RDBMS since the 90’s, developed a point-of-sale application in Access, have been using PostgreSQL through its various versions since 1998, and recently worked on integrating DB migration process into a very large system. I am not an expert but I have had quite an extensive experience of relational databases over a significant number of years and I have always found that <em>writing</em> to DB quickly became a painful things.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Although one could argue that there exists “languages” like Excel that allow you to write complex queries and explore data in a very sophisticated way without the use of SQL<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="http://haskell-servant.github.io/">Servant</a> is definitely on our roadmap.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>This thread is pretty much redundant with storage thread for the moment. The plan is to use it for serialising <code>applyCommand</code> operations on the models<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>We use <a href="https://hackage.haskell.org/package/QuickCheck">QuickCheck</a> to generate a bunch of events for the type of interest.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>It looks like our Om will be soon superceded by <a href="https://github.com/omcljs/om/wiki/Quick-Start-%28om.next%29">om.next</a><a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>I plan to provide more insights on our development and operations process in another blog post, but to give rough ideas we have deployed our application about a hundred times in the past 6 months.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Having a strong type system is no replacement for a decent test suite however, because obviously a lot of bugs happen at the boundaries of the system, e.g. when invoking REST API.<a href="#fnref8">↩</a></p></li>
<li id="fn9"><p>Obviously, this works as long as your data fits in memory. My bet is this will be the case for <a href="http://yourdatafitsinram.com/">quite a long time</a>. Shall this ever become a <a href="https://gettingreal.37signals.com/ch04_Scale_Later.php">problem</a>, we will most probably be in a position to handle it.<a href="#fnref9">↩</a></p></li>
<li id="fn10"><p>This is the approach I took in <a href="https://github.com/capital-match/hdo/blob/master/src/Network/DO/Types.hs">hdo</a> because external representation was already defined, and in the end it makes encoding more explicit and easier to work with<a href="#fnref10">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Du mode d&#39;existence des objets techniques&quot;</title>
    <link href="http://abailly.github.io/posts/objets-techniques.html" />
    <id>http://abailly.github.io/posts/objets-techniques.html</id>
    <published>2015-11-07T00:00:00Z</published>
    <updated>2015-11-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Du mode d&#39;existence des objets techniques&quot;</h1>
<div class="info">Posted on November  7, 2015</div>

<p>Je suis un grand <a href="/posts/eme.html">admirateur</a> de Bruno Latour, même si je ne suis pas certain de comprendre l’ensemble des concepts qu’il développe. Mais il y a une chose que je crois comprendre et qui m’attire dans sa pensée, c’est l’idée, développée en particulier dans <a href="">Nous n’avons jamais été moderne</a> et bien sûr <a href="">Enquête sur les modes d’existence</a> que Nature et Culture ne sont pas deux blocs antagonistes mais deux pôles en interaction dont les sciences et les techniques sont, entre autres, des médiateurs dont il faut se préoccuper. Dans EME il identifie un certains nombres d’êtres et de modes d’existence d’iceux. Latour cite régulièrement <a href="http://gilbert.simondon.fr/">Gilbert Simondon</a> et lui emprunte d’ailleurs une partie du titre de sa thèse: <a href="http://editions.flammarion.com/Albums_Detail.cfm?ID=41344&amp;levelCode=home">Du mode d’existence des objets techniques</a>.</p>
<p>Simondon est un des rares philosophes qui essaye de <em>penser</em> la technique, ses objets et sa relation à l’homme. Son livre est dense, ardu, difficile à lire avec un style hâché et une profusion de termes peu usités et de tournures de phrases quelques peu alambiquées, je ne suis pas sûr d’en avoir saisi toutes les subtilités n’ayant pas eu la possibilité de fréquenter la rue d’Ulm mais j’en ai retenu quelques éléments qui résonnent avec mon expérience de programmeur et mainteneur de logiciels.</p>
<p>Un <em>objet</em> technique est un <em>individu</em> technique issu par <em>invention</em> d’un assemblage inédit d’<em>éléments</em> techniques, constituants atomiques de la <em>technicité</em> dans lesquels résident une puissance, une capacité d’agir sur le réel et qui sont le produit d’un <em>ensemble technique</em>. Il n’y a pas de hiérarchie dans la technicité entre éléments, objets et ensembles. Un marteau par exemple, est un objet technique issue de l’assemblage d’éléments pré-existants : une masse métallique et un manche en bois pour faire simple ; le marteau s’insère dans un ensemble technique, p.ex. la menuiserie ou même plus généralement la construction, les métiers du bâtiment, dans lequel il joue un rôle particulier. La fonction de l’objet technique n’est pas fixée par sa forme mais dépend de son milieu, mais il subit un processus d’<em>adaptation</em> lorsqu’inséré dans un milieu il se modifie par l’usage qui est en fait : la forme et la fonction sont reliés l’une à l’autre par une boucle de rétroaction sans qu’un des éléments soit prépondérant.</p>
<p>Simondon développe le concept d’abstraction et de concrétisation de l’objet technique pour décrire son évolution. Un objet technique sera d’autant plus concret qu’il sera “adhérent” au monde et que ses éléments seront en interaction “harmonieuses”, et par conséquent d’autant plus abstrait qu’il sera détaché du monde, générique. La concrétisation exprime le degré de perfection d’un élément ou d’un objet technique. Ce qui est particulier à l’objet c’est que ses éléments constitutifs peuvent produire des contraintes antagonistes, contraintes qui peuvent se résoudre soit en réduisant la marge d’indétermination de l’objet dans son usage<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, soit au travers de l’invention et de la découverte dans un changement de l’un ou de plusieurs des éléments de l’objet, voire carrément dans la création d’un nouvel objet. Simondon développe l’exemple du moteur à explosion dont le corps subit les contraintes de résistance à l’explosion et de dissapation de la chaleur: l’invention d’ailettes perpendiculaires à la paroi permet de résoudre partiellement les deux contraintes, mais alors une nouvelle tension apparaît entre le volume des ailettes et celui de la soupape.</p>
<p>Les objets techniques ont donc une sorte de logique interne, une existence propre relativement indépendante de leur fonction et qui résulte d’une tension entre des contraintes physiques, des éléments, entre matière et forme indisolublement liés dans l’objet. L’objet technique n’est pas que fonction mais aussi forme, assemblage d’éléments et constituant d’ensembles. L’ensemble technique est le stade “moderne” d’évolution de la technicité, et ce qui appelle une <em>technologie</em>. Le rejet de la technique par l’homme apparaît quand l’homme devient lui-même élément d’un objet technique - la <em>machine</em> - et seul le passage à l’étape suivante c’est-à-dire la compréhension des ensembles et l’insertion de l’humain dans ces ensembles permet de dépasser cette opposition en faisant de la technique une part intégrale de la <em>culture</em>.</p>
<p>Dans la deuxième partie du livre Simondon propose une explication génétique du fait technique et de ce qu’il engendre dans la société humaine basée sur l’opposition entre <em>figure</em> et <em>fond</em>, une dualité qui vise à supplanter la dualité traditionnelle entre <em>forme</em> et <em>matière</em><a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>:</p>
<ul>
<li>dans les temps immémoriaux, aucune séparation n’existe: l’humain ne se distingue pas de la nature dont il est partie intégrante. C’est le temps dit “primitif”, celui des premiers hommes que nous ne connaissons quasiment pas ;</li>
<li>puis vient le temps <em>magique</em> dans lequel la figure commence à se détacher du fond mais comme un réseau de noeuds “magiques”, objets, lieux, personnes, moments, phénomènes naturels interconnectés et toujours enserrés. Les figures magiques sont les points nodaux, les “nexus”, qui font sens sur le fond du monde mais n’en sont pas séparées ;</li>
<li>cette unité magique se brise à mesure que la complexité du monde s’accroît:
<ul>
<li>les figures s’individualisent en objets techniques qui incarnent donc le processus d’objectivation,</li>
<li>le fond est universalisé en divinité, et devient le domaine du <em>religieux</em> et de la subjectivité<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> ;</li>
</ul></li>
<li>lorsque la technique est en échec, lorsque la “figure” qu’est l’objet technique trouve ses limites dans les conditions du monde, le “fond”, elle se subdivise à son tour et donne naissance à:
<ul>
<li>la <em>pensée pratique</em>, préoccupée de simplicité, d’efficacité, de la gestion de l’effort, donc figurale, locale, individuée,</li>
<li>la <em>pensée scientifique</em> préoccupée d’unité et d’universalité, de “lois naturelles”, donc un fond sur lequel s’appuyer pour développer des objets techniques et une pratique ;</li>
</ul></li>
<li><p>symétriquement la religion se divise en un fond, normatif, éthique et moral, et des figures théoriques, doctrinales, visant à l’universalité et à un savoir de type contemplatif.</p></li>
<li>l’art est un des chemins par lequel l’être humain retrouve l’unité magique: les expériences esthétiques constituent autant de <em>points remarquables</em> reliés par un réseau artistique visant à recréer du sens sur le fond du monde ;</li>
<li><p>l’autre chemin est, on s’en serait douté, celui de la philosophie dont les <em>concepts</em> réunissent les modes de pensée religieux et techniques.</p></li>
</ul>
<p>Ce modèle, discutable et discuté, a le mérite de proposer une grille de lecture riche et multiple du réel, d’articuler l’individu et le collectif, l’homme et le monde, les objets et les sujets dans un réseau de relations infiniment complexe. Il permet aussi d’argumenter sur l’importance des techniques dans la culture et sur l’amputation volontaire que constitue l’ignorance des techniques par de nombreuses personnes. Simondon appelle de ses voeux la formation d’une <em>technologie</em>, c’est-à-dire littéralement un savoir de la technique, une pensée technique, à commencer par le travail:</p>
<blockquote>
<p>L’activité technique se distingue du simple travail, et du travail aliénant, en ce que l’activité technique comporte non seulement l’utilisation de la machine mais aussi un certain coefficient d’attention au fonctionnement technique. [..] L’aliénation fondamentale [de l’homme par la machine] réside dans la rupture qui se produit enttre l’ontogénèse de l’objet technique et l’existence de cet objet technique. [..] Les objets techniques qui produisent le plus d’aliénation sont aussi ceux qui sont destinés à des utilisateurs ignorants.</p>
<p>p.339</p>
</blockquote>
<p>Il est pour moi évident que cette pensée fournit un substrat unifiant tout un ensemble de faits, mouvements, idées qui sont de plus en plus prégnants dans notre société: DIY, Makers, logiciel libre, économie collaborative et participative, open science, hackathon, Devoxx4Kids… De plus en plus nombreux sont ceux qui considèrent que reprendre possession de la technique, sur le plan pratique autant que théorique, est une nécessité, voire une urgence.</p>
<p>Dans les dernières pages de son livre Simondon critique le monde du travail, l’entreprise de son temps - et du nôtre:</p>
<blockquote>
<p>L’entreprise [..] doit être organisée à partir de sa fonction essentielle, c’est à dire de son fonctionnement technique.</p>
<p>p.343</p>
</blockquote>
<p>ainsi que l’obsession du rendement:</p>
<blockquote>
<p>Le critère de rendement ne peut pas conduire à une résolution du problème [de la zone obscure subsistant entre capital et travail] ; le rendement, par rapport à l’activité technique etst très abstrait et ne permet pas d’entrer dans cette activité pour en voir l’essence.</p>
<p>p.344</p>
</blockquote>
<p>Loin du technologisme conquérant et abstrait du <em>management scientifique</em> prôné, dans le domaine de l’organisation du travail, par Taylor et ses successeurs, prônant la séparation toujours plus fine des tâches et des rôles entre conception et réalisation, direction et exécution, pensée et action au nom de l’efficacité économique, et tout autant éloigné du scientisme positiviste aveugle, Simondon propose une philosophie de la technique à hauteur d’homme et de femme, un projet peut-être utopique mais ancré dans le réel, de réenchanté le monde en retrouvant l’unité perdue de la figure et du fond.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>C’est que Simondon nomme <em>l’hypertélie</em> : la sur-adaptation de l’objet à sa finalité.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Simondon utilise le joli mot d’hylémorphique ou hylémorphisme pour désigner ce mode de pensée issu originellement de la philosophie aristotélicienne.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>religion doit ici être entendu dans son sens le plus large, <em>ce qui relie</em>, et inclut donc les systèmes sociaux et politiques, les schèmes de pensées qui permettent d’universaliser, de relier les individus dans un tout plus grand qu’eux.<a href="#fnref3">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Sur &quot;Technological Revolutions and Financial Capital&quot;</title>
    <link href="http://abailly.github.io/posts/techno-capital.html" />
    <id>http://abailly.github.io/posts/techno-capital.html</id>
    <published>2015-11-06T00:00:00Z</published>
    <updated>2015-11-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Sur &quot;Technological Revolutions and Financial Capital&quot;</h1>
<div class="info">Posted on November  6, 2015</div>

<p>Il y a quelques mois j’ai eu l’occasion d’assister à une <a href="http://conseil-developpement.loire-atlantique.fr/assaut-numerique-decrypte-devant-100-citoyens-et-professionnels-de-loire-atlantique/">conférence</a> de <a href="https://twitter.com/Nicolas_Colin">Nicolas Collin</a> donnée à l’Hôtel de Département dans le cadre du <a href="http://conseil-developpement.loire-atlantique.fr/">Comité de Développement de la Loire-Atlantique</a>. Sur les conseils de Nicolas Colin et après une discussion sur twitter, j’ai donc commandé et lu <a href="https://books.google.fr/books/about/Technological_Revolutions_and_Financial.html">Technological Revolutions and Financial Capital</a> de <a href="http://www.carlotaperez.org/">Carlota Perez</a>, professeure à la prestigieuse London School of Economics. J’en recommande la lecture et j’appelle de mes voeux une traduction qui permettrait de mieux diffuser les hypothèses et le modèle intéressant - et positif - que propose Carlota Perez.</p>
<p>Dans ce livre C.Perez propose une relecture des modèles cycliques du capitalisme (p.ex. <a href="https://fr.wikipedia.org/wiki/Cycle_de_Kondratiev">cycles de Kondratiev</a>) en articulant les (r)évolutions technologiques, financières et socio-politiques. L’hypothèse centrale du livre, soutenue par une démonstration historique, est que le capitalisme est caractérisé par des cycles longs, induits par des sauts technologiques majeurs, qui sont entrecoupés de crises plus ou moins profondes manifestant différentes phases d’intégration du nouveau paradigme. La survenue d’un nouveau paradigme technologique s’accompagne inévitablement de transformations majeures de la société dans toutes ses dimensions: économiques, sociétales, organistionelles, politiques, économiques… Ces transformations se diffusent par vague à partir d’un noyau central en provoquant des bouleversements <a href="https://en.wikipedia.org/wiki/Creative_destruction">schumpéteriens</a> dont nous subissons les effets.</p>
<p>Elle distingue dans l’histoire du capitalisme cinq paradigmes majeurs se succédant environ tous les cinquante ans:</p>
<ul>
<li>la révolution industrielle proprement dite, dont le métier à tisser automatique est l’emblème, qui démarre en Angleterre vers 1760,</li>
<li>la machine à vapeur et le train à partir de 1820, toujours depuis l’Angleterre,</li>
<li>l’acier, l’électricité et l’ingénierie, à partir de 1870 et dont le centre est l’Allemagne et les USA,</li>
<li>le pétrole, l’automobile et la production de masse, aux USA toujours, démarrant dans les années 1910-1920,</li>
<li>enfin les semi-conducteurs et technologies de l’information, dont le noyau se situe toujours aux US, à partir des années 70.</li>
</ul>
<p>La diffusion de chacun de ces paradigmes est séparée en deux grandes phases - <em>Installation</em> et <em>Déploiement</em> - séparées par un <em>point de retournement</em>, chaque phase étant elle-même subdivisée en deux sous-phases. Le modèle s’articule donc en cinq étapes caractérisées par différents modes d’interactions entre technologie, capitalisme financier et investissement productif:</p>
<ol style="list-style-type: decimal">
<li>l’<strong>Irruption</strong> dont le point de départ est un <em>big bang</em> technologique à partir duquel se déploie un faisceau de plus en plus dense d’innovations. Cette phase est celle des succès fulgurants, des innovations spectaculaires, des entrepreneurs de génies, des croissances faramineuses à mesure que le nouveau paradigme conquiert de nouveaux territoires tout en commencant à mordre sur l’ancien paradigme (toujours en place et “installé” désormais dans la routine et le conservatisme). La croissance est d’autant plus rapide qu’elle est alimentée par des flux de capitaux qui cherchent à s’employer, capitaux générés par les profits accumulés dans l’ancien paradigme mais qui ne se satisfont plus de taux de rentabilité de “pères de familles” ;</li>
<li>la <strong>Frénésie</strong> s’empare du système à mesure que le nouveau paradigme s’impose comme un nouvel <em>eldorado</em>, les investissements sont de plus en plus importants, les risques plus grands, les innovations de plus en plus risquées voires carrément frauduleuses dans le système financier. C’est l’époque des <strong>bulles spéculatives</strong>, Canal de Panama, chemins de fer transcontinentaux, Années Folles, hedge funds et CDO, des fortunes éclairs, des IPO monstrueuses… Le capital financier prend le pas sur le capital productif et l’hystérie s’auto-alimente, jusqu’à ce que…</li>
<li>le <strong>Point de retournement</strong> fasse éclater la bulle, provoquant l’effondrement du systéme financier devenu fou, et une crise généralisée plus ou moins grave et douloureuse (crise de 1890, 1929, 1973, 2008…) de l’ensemble du système économique et souvent socio-politique,</li>
<li>à cette “purge” succède la phase de <strong>Synergie</strong> qui voit se déployer le nouveau paradigme dans l’ensemble de la société. De nouvelles lois et de nouveaux modes de régulation apparaissent pour juguler la finance, un nouvel “âge d’or” s’installe tandis que l’innovation apparaît enfin sous un jour bénéfique en s’adaptant et en adaptant la structure sociale. L’ensemble des acteurs du système se convertissent au nouveau paradigme et en tirent des bénéfices, la richesse globale s’accroît et se diffuse… La <em>Belle époque</em>, le <em>New Deal</em> et les <em>Trente glorieuses</em> en sont quelques manifestations emblématiques. Durant cette phase c’est le capitalisme productif qui prend le pas sur le capitalisme financier, les ingénieurs et gestionnaires qui supplantent les financiers et les spéculateurs,</li>
<li>enfin vient le temps de la <strong>Maturité</strong> où les dernières “marches” du système sont touchées par le nouveau paradigme, où l’optimisation devient plus importante que l’innovation. Cette phase recouvre en la dissimulant plus ou moins l’irruption de la prochaine vague technologique, elle voit s’exacerber les tensions que l’expansion de la phase précédente masquait : les pauvres, moins pauvres mais plus instruits et plus exigeants réclament une part plus importante de la richesse ; le conservatisme gagne du terrain : il devient plus important de protéger ses avantages acquis que d’innover et d’en créer de nouveaux. Le capital productif trouve ses limites car les rendements décroissent, l’argent s’accumule sans trouver - encore - à s’employer…</li>
</ol>
<p>Ce qui est particulièrement intéressant dans le modèle de Carlota Perez c’est que :</p>
<ol style="list-style-type: decimal">
<li>c’est un modèle <strong>dynamique</strong> et non statique : il permet de comprendre l’évolution de notre système et non une situation particulière, aussi désirable soit-elle ;</li>
<li>il articule trois modalités du changement, technologique, économique et institutionnel, ne considérant pas qu’il y aurait une cause racine et un <em>sens de l’histoire</em> auquel chacun devrait se plier mais plutôt qu’un état de fait est la résultante d’interactions extrêmement complexes entre de nombreux acteurs ;</li>
<li>il cherche à être utile non seulement pour comprendre mais aussi pour agir : identifier les cycles et les phases devrait permettre d’ajuster au mieux les politiques publiques, pour atténuer les effets négatifs et augmenter les effets positifs de chaque étape.</li>
</ol>
<p>Je n’ai pas les compétences pour juger de la validité scientifique et historique de ce livre. “Tous les modèles sont faux, certains sont utiles” disait <a href="https://en.wikiquote.org/wiki/George_E._P._Box">G.Box</a> et le peu que je connais des différents domaines qu’il couvre m’incite à penser que ce modèle particulier fait partie de la seconde catégorie. Les question qu’il m’incite à me poser sont les suivantes:</p>
<ol style="list-style-type: decimal">
<li>si nous suivons ce modèle, dans quelle phase nous situons nous actuellement et qu’est ce que cela implique pour la société et l’action publique ? Certains semblent penser que nous nous trouvons dans la phase de Synergie du paradigme <em>technologie de l’information</em> dont le point de retournement aurait été la bulle Internet des années 2000 suivi par la crise de 2008, ce qui signifierait que l’on assiste au déploiement du nouveau paradigme destiné à supplanter l’ancien à bref échéance ;</li>
<li>si le <a href="https://en.wikipedia.org/wiki/Accelerating_change">changement accélère</a>, le modèle ne devient-il pas caduque car il supppose pour chacune des phases un temps plus ou moins incompressible nécessaire ?</li>
</ol>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Some Notes on ML in Haskell following MLWeek</title>
    <link href="http://abailly.github.io/posts/ml-week.html" />
    <id>http://abailly.github.io/posts/ml-week.html</id>
    <published>2015-11-06T00:00:00Z</published>
    <updated>2015-11-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Some Notes on ML in Haskell following MLWeek</h1>
<div class="info">Posted on November  6, 2015</div>

<p>From Monday 2/11 to Thursday 5/11 I attended <a href="http://www.ml-week.com/fr">ML Week</a>, a training session lead by <a href="http://jeff.purple.com/qr/">Jeff Abrahamson</a> who also organizes the <a href="http://www.meetup.com/fr/Nantes-Machine-Learning-Meetup/">Nantes ML Meetup</a>. This session was great, not only because of its content, mostly an overview of the main techniques available and a hands-on dive into Python’s eco-system to support data analysis, but also because of the discussions we had with other attendees and with Jeff whose depth of knowledge on the subject is truely amazing.</p>
<p>However I was a bit frustrated of not being able to epxlorer the topic using my language of choice, namely Haskell. So I took opportunity of this training to start collecting links and ideas on how to do data analysis and ML in Haskell. Here are a few links and comments on my attempts to <em>map</em> the tools we were using in Python to equivalent things in the Haskell eco-system:</p>
<ul>
<li>All the hands-on codelabs for the training were provided in the form of <a href="http://ipython.org/notebook.html">IPython Notebooks</a>, so I went to install <a href="https://github.com/gibiansky/IHaskell">IHaskell</a> which provides a Haskell <em>kernel</em> for notebooks. It works great straight out of the box, I only had some minor glitches with <a href="https://hackage.haskell.org/package/Chart">Charts</a> display. I must say that the community for IHaskell is very responsive!</li>
<li><a href="http://www.kronosnotebook.com/haskell">Kronos</a> provides a packaged interactive data visualization tool that contains everythign that’s needed to run IHaskell out-of-the-box when you dont’ want to bother with installing Haskell eco-system,</li>
<li><a href="https://hackage.haskell.org/package/cassava">cassava</a> provides type-safe parsing of CSV data,</li>
<li>There is a base statistics package for Haskell: http://hackage.haskell.org/package/statistics, which is maintained by Brian O’Sullivan who is also behind <a href="https://hackage.haskell.org/package/wreq">wreq</a>, the one-stop shop for making HTTP clients. This package among many other stuff provides linear regression,</li>
<li><a href="https://github.com/mikeizbicki/HLearn">HLearn</a> is an ambitious project to provide efficient pure Haskell implementations of various standard ML algorithms,</li>
<li>Basic matrices operations are provided by <a href="http://dis.um.es/~alberto/hmatrix/hmatrix.html">hmatrix</a> which is based on efficient routines implemented by LAPACK, BLAS, and GSL,</li>
<li><a href="https://hackage.haskell.org/package/hstatistics">hstatistics</a> is another statistics package based on hmatrix,</li>
<li>There is a very interesting series of post from Dominik Steinitz: The ones I have been particularly interested in are on <a href="https://idontgetoutmuch.wordpress.com/2013/04/26/regression-and-automated-differentiation-4/">linear</a> and <a href="https://idontgetoutmuch.wordpress.com/2013/04/30/logistic-regression-and-automated-differentiation-3/">logistic</a> regressions using <em>automatic differentiation</em>. There has been some code drift in AD since the posts were written so they don’t compile as-is using latest versions of libraries but modifications are minor,</li>
<li>I thus turned to <a href="http://hackage.haskell.org/package/ad-3.4">ad</a> package by E.Kmett which happens to contain a routine for computing directly approximations of functions through gradient descent techniques,</li>
<li><a href="https://hackage.haskell.org/package/chatter">chatter</a> implements some “standard” NLP algorithms which we had to deal with to implement a spam detector,</li>
<li>Support Vector Machines support in Haskell is implemented in a couple of packages:
<ul>
<li>There are <a href="http://hackage.haskell.org/package/bindings-svm">haskell bindings</a> to the (apparently) state-of-the-art library <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a> which is what is used by scikit-learn,</li>
<li><a href="https://hackage.haskell.org/package/svm">svm</a> is another package which seems a bit oldish and unmaintained,</li>
</ul></li>
<li>I don’t think there is a compelling implementation of general purpose neural networks of any kind, although there appear to be quite a few package dealing with those beasts on hackage,</li>
<li>There are two libraries for computing K-means, both pretty recent:
<ul>
<li><a href="https://hackage.haskell.org/package/kmeans-vector">kmeans-vector</a>,</li>
<li><a href="https://hackage.haskell.org/package/kmeans">kmeans</a>,</li>
</ul></li>
<li>For Principal Component Analysis, there is <a href="https://hackage.haskell.org/package/hstatistics-0.2.5.3/docs/Numeric-Statistics-PCA.html">hstatistics</a> or <a href="https://hackage.haskell.org/package/hmatrix-nipals">hmatrix-nipals</a></li>
</ul>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>On Free DSLs and Cofree interpreters</title>
    <link href="http://abailly.github.io/posts/free.html" />
    <id>http://abailly.github.io/posts/free.html</id>
    <published>2015-06-04T00:00:00Z</published>
    <updated>2015-06-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>On Free DSLs and Cofree interpreters</h1>
<div class="info">Posted on June  4, 2015</div>

<p>This post has been triggered by a <a href="https://twitter.com/etorreborre/status/605562458279944192">tweet</a> from Eric Torreborre on a talk by David Laing presenting the interaction of Free DSLs and Cofree interpreters at the Brisbane Functional Programming Group. I am currently engaged in the development of a Haskell-based system for <a href="http://www.capital-match.com">Capital Match</a> which is basically an API for managing peer-to-peer lending, and I am trying to formalise the API of the system as the result of a composition of several domain-specific languages.</p>
<p>The ultimate goal is to be able to use these DSLs to define complex actions that could be interpreted in various ways: a command-line client sending RESTful queries to a server, a Webdriver-based test executor or a simple test recorder and comparator, or even by a core engine interpreting complex actions in terms of simpler sequencing of service calls.</p>
<p>The rest of the post is a simple literate Haskell style explanation of what I came up with today exploring the specific topic of the composition of DSLs and interpreters: Given we can compose DSLs using <em>Free</em> monads and <em>Coproduct</em>, how can we <em>Pair</em> a composite DSL to the composition of several interpreters? The answer, as often, lies in the category theoretic principle for duality: <em>Reverse the arrows!</em> One composes interpreters into a <em>Product</em> type which is then lifted to a <em>Cofree</em> comonad paired to a <em>Free Coproduct</em> monad.</p>
<p>This post has no original idea and is just rephrasing and reshaping of work done by more brilliant people than I am:</p>
<ul>
<li>Dan Piponi’s <a href="http://blog.sigfpe.com/2014/05/cofree-meets-free.html">Cofree meets free</a> blog post,</li>
<li>This <a href="http://programmers.stackexchange.com/questions/242795/what-is-the-free-monad-interpreter-pattern">thread on Stack overflow</a> about free monads,</li>
<li>Runar Bjarnason talk on <a href="https://dl.dropboxusercontent.com/u/4588997/ReasonablyPriced.pdf">Reasonably Priced Monads</a>,</li>
<li>An <a href="https://gist.github.com/aaronlevin/87465696ba6c554bc72b#file-reasonable-hs">Haskell implementation</a> of the above by Aaron Levin,</li>
<li><a href="http://www.haskellforall.com/2013/02/you-could-have-invented-comonads.html">Comonads are objects</a> by Gabriel Gonzalez,</li>
<li><a href="http://www.cs.ru.nl/~W.Swierstra/Publications/DataTypesALaCarte.pdf">Data types à la carte</a> by Wouter Swiestra,</li>
<li>Edward Kmett’s <a href="http://comonad.com/haskell/Comonads_1.pdf">All about comonads</a> slide deck,</li>
<li>And of course David Laing’s <a href="https://github.com/dalaing/cofun">github</a> repository.</li>
</ul>
<p>I would not dare to say I really <em>understand</em> all of this, but at least I got some code to compile and I have some ideas on how to turn this into a useful “pattern” in our codebase.</p>
<h1 id="free-coproduct-dsls">Free Coproduct DSLs</h1>
<p>So let’s start with some usual declaration and imports…</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="ot">{-# LANGUAGE DeriveFunctor         #-}</span>
<span class="ot">{-# LANGUAGE FlexibleContexts      #-}</span>
<span class="ot">{-# LANGUAGE FlexibleInstances     #-}</span>
<span class="ot">{-# LANGUAGE MultiParamTypeClasses #-}</span>
<span class="ot">{-# LANGUAGE OverlappingInstances  #-}</span>
<span class="ot">{-# LANGUAGE RankNTypes            #-}</span>
<span class="ot">{-# LANGUAGE TypeOperators         #-}</span>
<span class="kw">module</span> <span class="dt">Capital.Client.Free</span>  <span class="kw">where</span>

<span class="kw">import           </span><span class="dt">Control.Applicative</span>
<span class="kw">import           </span><span class="dt">Control.Comonad.Cofree</span>
<span class="kw">import           </span><span class="dt">Control.Monad</span>
<span class="kw">import           </span><span class="dt">Control.Monad.Free</span>
<span class="kw">import           </span><span class="dt">Control.Monad.Identity</span>
<span class="kw">import           </span><span class="dt">Control.Monad.Trans</span>    (<span class="dt">MonadIO</span>, liftIO)</code></pre></td></tr></table></div>
<p>This relies on the <a href="https://hackage.haskell.org/package/free">free</a> package which defines standard <em>free</em> Constructions for <code>Applicative</code> and <code>Monad</code>, and <em>cofree</em> for <code>Comonads</code>.</p>
<p>We define our basic business-domain specific functors, one for logging some messages and another for persisting some string value. The actual functors defined are not important, what interests us here is the fact we define those “actions” independently but we want in the end to be able to “Assemble” them yielding more complex actions which can at the same time log messages and persist things.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">Logging</span> a <span class="fu">=</span> <span class="dt">Logging</span> <span class="dt">String</span> a  <span class="kw">deriving</span> (<span class="dt">Functor</span>)

<span class="kw">data</span> <span class="dt">Persist</span> a <span class="fu">=</span> <span class="dt">Store</span> <span class="dt">String</span> a <span class="kw">deriving</span> <span class="dt">Functor</span></code></pre></td></tr></table></div>
<p>Our composite DSL should be able to interpret actions which are either logging actions, or persist actions, so we need a way to express this alternative at the type-level, introducing the notion of <em>Coproduct</em> or <em>Sum</em>. This work has already been packaged by Ed Kmett in the <a href="https://hackage.haskell.org/package/comonad-transformers-2.0.3">comonads-transformers</a> package but let’s rewrite it here for completeness’ sake.</p>
<div class="sourceCode"><table class="sourceCode ha1skell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
</pre></td><td class="sourceCode"><pre><code class="sourceCode">newtype Coproduct f g a = Coproduct { getCoproduct :: Either (f a) (g a) }</code></pre></td></tr></table></div>
<p>A <code>Coproduct</code> of two functors is then simply the type-level equivalent of the familiar <code>Either</code> type, for which we provide smart constructors to inject values from left or right and a suitable <code>Functor</code> instance.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="ot">left ::</span> f a <span class="ot">-&gt;</span> <span class="dt">Coproduct</span> f g a
left <span class="fu">=</span> <span class="dt">Coproduct</span> <span class="fu">.</span> <span class="dt">Left</span>

<span class="ot">right ::</span> g a <span class="ot">-&gt;</span> <span class="dt">Coproduct</span> f g a
right <span class="fu">=</span> <span class="dt">Coproduct</span> <span class="fu">.</span> <span class="dt">Right</span>

<span class="ot">coproduct ::</span> (f a <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> (g a <span class="ot">-&gt;</span> b) <span class="ot">-&gt;</span> <span class="dt">Coproduct</span> f g a <span class="ot">-&gt;</span> b
coproduct f g <span class="fu">=</span> either f g <span class="fu">.</span> getCoproduct

<span class="kw">instance</span> (<span class="dt">Functor</span> f, <span class="dt">Functor</span> g) <span class="ot">=&gt;</span> <span class="dt">Functor</span> (<span class="dt">Coproduct</span> f g) <span class="kw">where</span>
  fmap f <span class="fu">=</span> <span class="dt">Coproduct</span> <span class="fu">.</span> coproduct (<span class="dt">Left</span> <span class="fu">.</span> fmap f) (<span class="dt">Right</span> <span class="fu">.</span> fmap f)</code></pre></td></tr></table></div>
<p>We want to be able to implicitly “lift” values from a component into its composite without resorting to explicit packing of the various parts of the alternative formed by a <code>Coproduct</code> type, something which would be extremely cumbersome to express, hence the introduction of a <em>natural transformation</em> <code>Inject</code> expressed in Haskell as a typeclass.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">class</span> (<span class="dt">Functor</span> f, <span class="dt">Functor</span> g) <span class="ot">=&gt;</span> f <span class="fu">:&lt;:</span> g <span class="kw">where</span>
<span class="ot">  inject ::</span> f a <span class="ot">-&gt;</span> g a</code></pre></td></tr></table></div>
<p>To be useful we provide several interesting instances of this typeclass that defines how to inject functors into a <code>Coproduct</code>. Note that this requires the <code>OverlappingInstances</code> extension otherwise the compiler<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> will refuse to compile our programs. I think this stuff could be expressed as <em>type families</em> but did not manage to get it right, so I gave up and resorted to original formulation by Wouter Swiestra.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">instance</span> (<span class="dt">Functor</span> f, <span class="dt">Functor</span> g) <span class="ot">=&gt;</span> f <span class="fu">:&lt;:</span> <span class="dt">Coproduct</span> f g <span class="kw">where</span>
  inject <span class="fu">=</span> left

<span class="kw">instance</span> (<span class="dt">Functor</span> f, <span class="dt">Functor</span> g, <span class="dt">Functor</span> h, g <span class="fu">:&lt;:</span> h) <span class="ot">=&gt;</span> g <span class="fu">:&lt;:</span> <span class="dt">Coproduct</span> f h <span class="kw">where</span>
  inject <span class="fu">=</span> right <span class="fu">.</span> inject

<span class="kw">instance</span> (<span class="dt">Functor</span> f) <span class="ot">=&gt;</span> f <span class="fu">:&lt;:</span> f <span class="kw">where</span>
  inject <span class="fu">=</span> id</code></pre></td></tr></table></div>
<p>Finally, we provide “smart constructors” that generates <code>Free</code> monadic expressions out of the individual instructions of our two tiny DSLs. We use a <code>inFree</code> function combining lifting into <code>Free</code> monad and possible transformation between functors so that each expressed action is a <code>Free</code> instance whose functor is polymorphic. This is important as this is what will allow us to combine arbitrarily our DSL fragments into a bigger DSL.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="ot">inFree ::</span> (<span class="dt">Functor</span> f, f <span class="fu">:&lt;:</span> g) <span class="ot">=&gt;</span> f a <span class="ot">-&gt;</span> <span class="dt">Free</span> g a
inFree <span class="fu">=</span> hoistFree inject <span class="fu">.</span> liftF

log<span class="ot"> ::</span> (<span class="dt">Logging</span> <span class="fu">:&lt;:</span> f) <span class="ot">=&gt;</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">Free</span> f ()
log msg <span class="fu">=</span> inFree (<span class="dt">Logging</span> msg ())

<span class="ot">store ::</span> (<span class="dt">Persist</span> <span class="fu">:&lt;:</span> f) <span class="ot">=&gt;</span> <span class="dt">String</span> <span class="ot">-&gt;</span> <span class="dt">Free</span> f ()
store s <span class="fu">=</span> inFree (<span class="dt">Store</span> s ())</code></pre></td></tr></table></div>
<p>Equipped with all this machinery we are ready to write our first simple program in a combined DSL:</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">Effect</span> <span class="fu">=</span> <span class="dt">Coproduct</span> <span class="dt">Logging</span> <span class="dt">Persist</span>

<span class="ot">prg ::</span> <span class="dt">Free</span> <span class="dt">Effect</span> ()
prg <span class="fu">=</span> store <span class="st">&quot;bar&quot;</span> <span class="fu">&gt;&gt;</span> log <span class="st">&quot;foo&quot;</span></code></pre></td></tr></table></div>
<h1 id="cofree-product-interpreters">Cofree Product Interpreters</h1>
<p>We are now done with the DSL part, let’s turn to the interpreter part. First we need some atomic interpreters which should be able to interpret commands from each of our DSL. We will prefix these functors with <code>Co</code> to demote the relationship they have with the DSL functors. Something which is not obvious here (because our DSL functors only have a single constructor) is that these interpreters should have a dual structure to the DSL functors: Given a DSL expressed as a sum of constructors, we need an interpreter with a product of intepretation functions. The DSL presented in David’s post are more expressive…</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">data</span> <span class="dt">CoLogging</span> a <span class="fu">=</span> <span class="dt">CoLogging</span> {<span class="ot"> cLog ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> a }  <span class="kw">deriving</span> <span class="dt">Functor</span>

<span class="kw">data</span> <span class="dt">CoPersist</span> a <span class="fu">=</span> <span class="dt">CoPersist</span> {<span class="ot"> cStore ::</span> <span class="dt">String</span> <span class="ot">-&gt;</span> a }  <span class="kw">deriving</span> <span class="dt">Functor</span></code></pre></td></tr></table></div>
<p>Of course we need concrete interpretation functions, here some simple actions that print stuff to stdout, running in <code>IO</code>.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="ot">coLog ::</span> (<span class="dt">MonadIO</span> m) <span class="ot">=&gt;</span> m () <span class="ot">-&gt;</span> <span class="dt">String</span> <span class="ot">-&gt;</span> m ()
coLog a s <span class="fu">=</span> a <span class="fu">&gt;&gt;</span> (liftIO <span class="fu">$</span> print s)

<span class="ot">coStore ::</span> (<span class="dt">MonadIO</span> m) <span class="ot">=&gt;</span> m () <span class="ot">-&gt;</span> <span class="dt">String</span> <span class="ot">-&gt;</span> m ()
coStore a s <span class="fu">=</span> a <span class="fu">&gt;&gt;</span> (liftIO <span class="fu">.</span> print <span class="fu">.</span> (<span class="st">&quot;storing &quot;</span> <span class="fu">++</span>)) s</code></pre></td></tr></table></div>
<p>To be able to compose these interpreters we need a <code>Product</code> type whose definition is straightforward: This is simply the type-level equivalent of the <code>(,)</code> tupling operator.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">newtype</span> <span class="dt">Product</span> f g a <span class="fu">=</span> <span class="dt">Product</span> {<span class="ot"> p1 ::</span> f a,<span class="ot"> p2 ::</span> g a }

<span class="kw">instance</span> (<span class="dt">Functor</span> f, <span class="dt">Functor</span> g) <span class="ot">=&gt;</span> <span class="dt">Functor</span> (<span class="dt">Product</span> f g) <span class="kw">where</span>
  fmap f (<span class="dt">Product</span> (a,b)) <span class="fu">=</span> <span class="dt">Product</span> (fmap f a, fmap f b)</code></pre></td></tr></table></div>
<p>Then we can define our complex interpreter and what interpretation means in the context of this composite. <code>coiter</code> is a function from the <a href="https://hackage.haskell.org/package/free-4.12.1/docs/Control-Comonad-Cofree.html"><code>Cofree</code></a> module that “lifts” computation in a Functor into a <code>Cofree</code> monad, starting from a seed value.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">type</span> <span class="dt">Interp</span> <span class="fu">=</span> <span class="dt">Product</span> <span class="dt">CoLogging</span> <span class="dt">CoPersist</span>

<span class="ot">interpretEffect ::</span> <span class="dt">Cofree</span> <span class="dt">Interp</span> (<span class="dt">IO</span> ())
interpretEffect <span class="fu">=</span> coiter f (return ())
  <span class="kw">where</span>
     f a <span class="fu">=</span> <span class="dt">Product</span> (<span class="dt">CoLogging</span> <span class="fu">$</span> coLog a, <span class="dt">CoPersist</span> <span class="fu">$</span> coStore a)</code></pre></td></tr></table></div>
<h1 id="tying-free-to-cofree">Tying Free to Cofree</h1>
<p>This is where the “magic” occurs! We need a way to <em>tie</em> our DSLs to our interpreters so that we can apply the latter to the former in a consistent way, even when they are composed. Enters the <code>Pairing</code> class which express this relationship using a function tying together each functor (DSL and interpreter) to produce a result.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">class</span> (<span class="dt">Functor</span> f, <span class="dt">Functor</span> g) <span class="ot">=&gt;</span> <span class="dt">Pairing</span> f g <span class="kw">where</span>
<span class="ot">  pair ::</span> (a <span class="ot">-&gt;</span> b <span class="ot">-&gt;</span> r) <span class="ot">-&gt;</span> f a <span class="ot">-&gt;</span> g b <span class="ot">-&gt;</span> r</code></pre></td></tr></table></div>
<p>For the <code>Identity</code> functors, <code>pair</code>ing is simply two-arguments function application.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Pairing</span> <span class="dt">Identity</span> <span class="dt">Identity</span> <span class="kw">where</span>
  pair f (<span class="dt">Identity</span> a) (<span class="dt">Identity</span> b) <span class="fu">=</span> f a b</code></pre></td></tr></table></div>
<p>We can also define a pair relating function types and tuple types, both ways:</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Pairing</span> ((<span class="ot">-&gt;</span>) a) ((,) a) <span class="kw">where</span>
  pair p f <span class="fu">=</span> uncurry (p <span class="fu">.</span> f)

<span class="kw">instance</span> <span class="dt">Pairing</span> ((,) a) ((<span class="ot">-&gt;</span>) a) <span class="kw">where</span>
  pair p f g <span class="fu">=</span> pair (flip p) g f</code></pre></td></tr></table></div>
<p>And finally we can pair <code>Cofree</code> and <code>Free</code> as well as <code>Product</code> and <code>Coproduct</code>, thus providing all the necessary tools for tying the knots. Note that in this case no intepretation takes place before pairing hit a <code>Pure</code> value, which actually means that interpretation first need to build all the “spine” for program to be interpreted then unwind it and applying interpretation step to each instruction. This precludes evaluating infinite “scripts”.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Pairing</span> f g <span class="ot">=&gt;</span> <span class="dt">Pairing</span> (<span class="dt">Cofree</span> f) (<span class="dt">Free</span> g) <span class="kw">where</span>
  pair p (a <span class="fu">:&lt;</span> _ ) (<span class="dt">Pure</span> x)  <span class="fu">=</span> p a x
  pair p (_ <span class="fu">:&lt;</span> fs) (<span class="dt">Free</span> gs) <span class="fu">=</span> pair (pair p) fs gs

<span class="kw">instance</span> (<span class="dt">Pairing</span> g f, <span class="dt">Pairing</span> k h) <span class="ot">=&gt;</span> <span class="dt">Pairing</span> (<span class="dt">Product</span> g k) (<span class="dt">Coproduct</span> f h) <span class="kw">where</span>
  pair p (<span class="dt">Product</span> (g,_))  (<span class="dt">Coproduct</span> (<span class="dt">Left</span> f)) <span class="fu">=</span> pair p g f
  pair p (<span class="dt">Product</span> (_,k)) (<span class="dt">Coproduct</span> (<span class="dt">Right</span> h)) <span class="fu">=</span> pair p k h</code></pre></td></tr></table></div>
<p>We finally tie the appropriate “leaf” functors together in a straightforward way.</p>
<div class="sourceCode"><table class="sourceCode haskell numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
</pre></td><td class="sourceCode"><pre><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Pairing</span> <span class="dt">CoLogging</span> <span class="dt">Logging</span> <span class="kw">where</span>
  pair f (<span class="dt">CoLogging</span> l) (<span class="dt">Logging</span> m k) <span class="fu">=</span> f (l m) k

<span class="kw">instance</span> <span class="dt">Pairing</span> <span class="dt">CoPersist</span> <span class="dt">Persist</span> <span class="kw">where</span>
  pair f (<span class="dt">CoPersist</span> s) (<span class="dt">Store</span> v k) <span class="fu">=</span> f (s v) k

<span class="kw">type</span> <span class="dt">Effect</span> <span class="fu">=</span> <span class="dt">Coproduct</span> <span class="dt">Logging</span> <span class="dt">Persist</span></code></pre></td></tr></table></div>
<p>We are now ready to define and interpret programs mixing logging and persistence:</p>
<blockquote>
<p>let prog = store “bar” &gt;&gt; logI “foo” &gt;&gt; store “quux” &gt;&gt; logI “baz” :: Free Effect () λ&gt; pair const interpretEffect ((return &lt;$&gt; prog) :: Free Effect (IO ()) ) “storing bar” “foo” “storing quux” “baz” λ&gt;</p>
</blockquote>
<h1 id="conclusion">Conclusion</h1>
<p>As is often the case when dealing with “complex” or rather unfamiliar category theoretic constructions, I am fascinated by the elegance of the solution but I can’t help asking “What’s the point?” There is always a simpler solution which does not require all this machinery and solves the problem at hand. But in this case I am really excited about the possibilities it opens in terms of engineering and architecting our system, because it gives us a clear and rather easy way to:</p>
<ul>
<li>Define in isolation fragments of DSL matching our APIs and business logic,</li>
<li>Define one or more interpreter for each of these fragments,</li>
<li>Combine them in arbitrary (but consistent for pairing) ways.</li>
</ul>
<p>This code is in <a href="https://gist.github.com/abailly/84a54ace82a67c3c8aab">gist</a>.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>GHC 7.8.3 in our case<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>In private conversation by email David Laing told me follow-up talks will deal with free/cofree duality with effects thus taking care of evaluating monadic scripts and interpreters.<a href="#fnref2">↩</a></p></li>
</ol>
</div>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Ten &quot;Good&quot; Reasons Not to Do TDD</title>
    <link href="http://abailly.github.io/posts/no-tdd.html" />
    <id>http://abailly.github.io/posts/no-tdd.html</id>
    <published>2014-01-31T00:00:00Z</published>
    <updated>2014-01-31T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Ten &quot;Good&quot; Reasons Not to Do TDD</h1>
<div class="info">Posted on January 31, 2014</div>

<p>When trying to introduce <em>Test-Driven Development</em> in a team or company, it is normal to encounter resistance: Change is always hard, whatever it may be, for <em>everybody</em>. It is a transgression of the current norm and rules that most people would not accept readily.</p>
<p>Here is a small compendium of ten “good” reasons I have been given for not doing TDD while introducing that technique to new teams.</p>
<h2 id="it-is-going-to-slow-us-down">“It Is going to slow us down!”</h2>
<p>If we deliver code faster, we have more times to discover bugs and fix them using real testing conditions, eg. in production.</p>
<h2 id="it-takes-a-lot-of-time-to-master">“It takes a lot of time to master!”</h2>
<p>We would rather employ youngsters having just graduated that will put 12+ hours of work per day and ship code faster than take the time to train people on TDD</p>
<h2 id="managers-and-business-people-keep-setting-tight-deadlines">“Managers and Business people keep setting tight deadlines”</h2>
<p>We cannot or do not know how to say “no” to our customers, so we keep promising features and given we work hard and fast, we can deliver and fix bugs later. Anyway, it has always worked that way so the customer does not even expect first versions to be correct so everybody knows and expect there will be bugs (and more overtime to fix them after delivery…). Besides, our contracts fix scope, deadline and price with high penalty in case of failure to deliver so we would rather ship it as planned.</p>
<h2 id="we-already-tried-writing-unit-tests-and-it-became-a-maintenance-nightmare">“We already tried writing unit tests and it became a maintenance nightmare”</h2>
<p>Given we already have QA team that takes care of testing, and the complexity of the code, it is better to invest in large, complex but well-known functional or system-level tests than doubling the codebase with unit tests. And by the way, when I write unit tests for my code, it happens to be 3-4 times bigger than the code I am testing so what’s the point?</p>
<h2 id="we-have-too-much-legacy-code-it-would-be-a-drop-in-the-ocean">“We have too much legacy code, it would be a drop in the ocean”</h2>
<p>Let’s concentrate on shipping new features and fixing bugs touching existing code in the least invasively possible way, given we do not know if touching anything won’t break our software in possibly horrible ways</p>
<h2 id="i-do-not-want-to-be-told-how-i-have-to-code">“I do not want to be told how I have to code”</h2>
<p>I have enough experience to find my way in the code so I can change it quickly enough without the need of TDD. Besides I have my own set of techniques and tools that I have polished over the years so why bother changing?</p>
<h2 id="our-test-suite-takes-too-long-to-run-and-is-broken-half-of-the-time">“Our test suite takes too long to run and is broken half of the time”</h2>
<p>Given the aforementioned reasons, we do not have the time to fix it properly so let’s move on and find other ways to deal with bugs.</p>
<h2 id="our-code-does-not-lend-itself-to-tdd-because-we-do-much-guiembeddedmobilelegacy-pick-one-code">“Our code does not lend itself to TDD because we do much (GUI/Embedded/Mobile/Legacy Pick one) code”</h2>
<p>We are special here so we cannot do something that’s been invented for startupers or simple web apps.</p>
<h2 id="all-these-unit-tests-do-not-guarantee-functional-relevance">“All these unit tests do not guarantee functional relevance”</h2>
<p>So why bother writing them given we could invest the time in functional-level tests?</p>
<h2 id="whats-the-point-of-writing-tests-for-code-that-will-never-change-they-wont-catch-any-regression">“What’s the point of writing tests for code that will never change? They won’t catch any regression”</h2>
<p>OK, it might be changed but surely not in the near future so given I know what I am doing, I would rather get rid of those tests</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>Comprendre les catamorphismes</title>
    <link href="http://abailly.github.io/posts/cata.html" />
    <id>http://abailly.github.io/posts/cata.html</id>
    <published>2014-01-11T00:00:00Z</published>
    <updated>2014-01-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Comprendre les catamorphismes</h1>
<div class="info">Posted on January 11, 2014</div>

<h1 id="bananes-lentilles-enveloppes-et-barbelés">Bananes, lentilles, enveloppes et barbelés</h1>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.125">Functional Programming with bananas, lenses, envelopes and barbed wires</a> est un article célèbre qui explore différentes formes (ou <em>patterns</em>) de récursion. C’est à dire que l’on cherche à exprimer la récursion non pas comme une caractéristique du langage mais comme une <em>fonction d’ordre supérieur</em>, ou un combinateur comme un autre, comme tel donc susceptible d’être généralisé, réutilisé, composé. Depuis ma découverte de cet article j’ai été fasciné par ses possibilités sans avoir jamais pris le temps de les comprendre vraiment. Cet article est une tentative d’explication de ce <em>qu’est</em> un catamorphisme, l’une des formes de récursions classifiées dans l’article sus-cité.</p>
<h2 id="types-de-données-récursifs">Types de données récursifs</h2>
<p>Quand on définit une structure (un type de données), il est fréquent de définir des types qui soient <em>récursifs</em>, c’est à dire qui utilisent des données de leur propre type. L’exemple le plus typique en est l’ensemble des entiers naturels, définissable en Java comme suit:</p>
<div class="sourceCode"><table class="sourceCode java numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="sourceCode"><pre><code class="sourceCode java"><span class="kw">public</span> <span class="kw">class</span> Natural {

  <span class="kw">public</span> <span class="dt">static</span> <span class="dt">final</span> Natural Zero = <span class="kw">new</span> <span class="fu">Natural</span>();
  
  <span class="kw">public</span> <span class="dt">static</span> <span class="dt">final</span> Natural <span class="fu">succ</span>(Natural natural) {
   <span class="kw">return</span> <span class="kw">new</span> <span class="fu">Natural</span>(natural);
  }
  
  <span class="kw">private</span> <span class="fu">Natural</span>() {}
  
  <span class="kw">private</span> <span class="fu">Natural</span>(Natural pred) {
    <span class="kw">this</span>.<span class="fu">pred</span> = pred;
  }
}</code></pre></td></tr></table></div>
<p>Un entier est ici construit à l’aide de la méthode <code>succ</code> et de la constante <code>Zero</code>:</p>
<ul>
<li>soit 0 ;</li>
<li>soit le successeur d’un autre entier.</li>
</ul>
<p>La question que l’on peut se poser, si l’on s’intéresse à ce genre de choses, c’est : comment peut-on caractériser algébriquement l’ensemble des entiers ainsi défini, si ce n’est de manière tautologique ? Il peut nous apparaître très naturel d’utiliser un type dans sa propre définition mais c’est parce que nous sommes habitués à raisonner récursivement.</p>
<h3 id="point-fixe">Point Fixe</h3>
<p>Pour répondre à la question posée, on peut reformuler de manière “compacte” le problème en cherchant à définir le type <code>Natural</code> comme la solution d’une équation algébrique (+ joue ici le rôle de <code>OU</code>):</p>
<pre><code>Natural = Zero  + Succ (Natural),</code></pre>
<p>équation dont la solution est problématique puisque la variable apparaît des deux côtés de l’équation !</p>
<p>Si l’on substitue naïvement la définition de <code>Natural</code> en partie droite, alors on obtient quelque chose comme</p>
<pre><code>Natural = Zero + Succ (Zero + Succ ( Zero + Succ (Zero +...</code></pre>
<p>ce qui peut se réécrire en</p>
<pre><code>Natural = Zero + Succ (Zero) + Succ (Succ (Zero)) +...</code></pre>
<p><code>Natural</code> apparait bien comme un ensemble infini d’éléments qui sont soit <code>Zero</code> soit de la forme <span class="math inline"><em>S</em><em>u</em><em>c</em><em>c</em><sup><em>n</em></sup><em>Z</em><em>e</em><em>r</em><em>o</em></span> pour tout <span class="math inline"><em>n</em></span> entier.</p>
<p>Du point de vue mathématique, la solution d’une équtation de la forme <span class="math inline"><em>x</em> = <em>f</em>(<em>x</em>)</span> est appelée un <em>point fixe</em>, ce qui est bien la forme de l’équation de Natural. On peut donc dire que <code>Natural</code> est le point fixe de l’équation <span class="math inline"><em>X</em> = <em>Z</em><em>e</em><em>r</em><em>o</em> + <em>S</em><em>u</em><em>c</em><em>c</em>(<em>X</em>)</span>. Nous disons <em>le</em> point fixe, mais ce n’est pas tout à fait exact : comme on ne considére que des nombres finis (même si l’ensemble lui-même est de taille infinie), il s’agit là du <em>plus petit point fixe</em>. Il existe en effet des ensembles qui sont des points fixes de cette équation mais dont la cardinalité est plus grande que N car ils contiennent des nombres infinis (en quantité infinie…).</p>
<p>Ce type de définition étant très courant, il a paru utile de généraliser cette notion de <em>plus petit point fixe</em>, d’où l’introduction l’opérateur <em>μ</em>. Pour toute fonction f, μf est le plus petit point fixe de f, plus formellement: <br /><span class="math display"><em>μ</em><em>f</em> = <em>x</em> ∈ <em>d</em><em>o</em><em>m</em>(<em>f</em>), <em>x</em> = <em>f</em>(<em>x</em>)<em>e</em><em>t</em>∀<em>x</em>′ ∈ <em>d</em><em>o</em><em>m</em>(<em>f</em>), <em>x</em>′ = <em>f</em>(<em>x</em>′) ⇒ <em>x</em>′ ≥ <em>x</em></span><br /></p>
<p>Or ici la définition de Natural ne semble pas être une fonction. En fait, pour qu’une définition de type soit une fonction, il faut qu’elle soit une fonction sur des types, prenant en argument des types et retournant des types, en d’autres termes un foncteur. Mais c’est exactement ce que dit la forme <span class="math inline"><em>Z</em><em>e</em><em>r</em><em>o</em> + <em>S</em><em>u</em><em>c</em><em>c</em>(<em>X</em>)</span> où X désigne un type quelconque, et donc on peut légitimement définir <code>Natural  = μ(Zero + Succ(x))</code> comme un ensemble d’éléments point fixe d’un foncteur.</p>
<h3 id="définition-explicite">Définition explicite</h3>
<p>Toute cette mécanique est rendu implicite dans tous les langages, même les plus plus sophistiqués comme Haskell, Scala ou Caml. Pour définir un type de données récursif, nul besoin d’utiliser l’opérateur μ, on se contente d’utiliser les possibilités syntaxiques du langage qui autorise l’utilisation du nom d’un type dans sa définition. Mais pour pouvoir généraliser les mécanismes de récursions sous forme de FOS, il est nécessaire de déconstruire cette vision et d’introduire explicitement la récursion.</p>
<p>C’est ce que l’on va faire, en Haskell tout d’abord.</p>
<p>On introduit d’abord l’opérateur <code>Mu</code> comme un nouveau type de données prenant en paramètre un foncteur <code>f</code>. <code>Mu</code> a un seul constructeur, <code>In</code> qui empaquette le foncteur <code>f</code> dans une boucle récursive, ce qui nous donne 2 fonctions permettant de naviguer dans la “pile” de récursion:</p>
<ul>
<li><code>In : f (Mu f) -&gt; Mu f</code> (le constructeur, vu comme une fonction),</li>
<li><code>out : Mu f -&gt; f (Mu f)</code> (l’accesseur de l’unique champ de la structure encapsulée par In).</li>
</ul>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- newtypes in Haskell are cheaps, they do not add any runtime overhead and serve</span>
<span class="co">-- only for the compiler to distinguish types</span>
<span class="kw">newtype</span> <span class="dt">Mu</span> f <span class="fu">=</span> <span class="dt">In</span> {<span class="ot"> out ::</span> (f (<span class="dt">Mu</span> f)) }</code></pre></div>
<p>Essayons maintenant de définir les entiers comme ci-dessus au moyen de <code>Mu</code> en évitant la récursion explicite et en définissant <code>Natural</code> comme un foncteur:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- le foncteur engendrant les entiers naturels</span>
<span class="kw">data</span> <span class="dt">Natf</span> x <span class="fu">=</span> <span class="dt">Zero</span>  <span class="fu">|</span> <span class="dt">Succ</span> x 

<span class="co">-- le type (un simple alias) Natural comme point fixe d&#39;un foncteur</span>
<span class="kw">type</span> <span class="dt">Natural</span> <span class="fu">=</span> <span class="dt">Mu</span> <span class="dt">Natf</span></code></pre></div>
<p>Voici quelques objets de type <code>Natural</code> que l’on peut construire en utilisant directement les constructeurs de <code>Natf</code> sans se préoccuper de <code>Mu</code> pour l’instant:</p>
<pre><code>*Main&gt; let zero = Zero
*Main&gt; let un = Succ Zero
*Main&gt; :t un
un :: Natf (Natf x)
*Main&gt; let deux = Succ un
*Main&gt; :t deux
deux :: Natf (Natf (Natf x))</code></pre>
<p>On peut constater que chaque “nombre” a un type différent, ce qui n’est pas très pratique. En utilisan Mu, on uniformise le type d’où la naissance de Natural, un ensemble contenant des objets de type homogène:</p>
<pre><code>*Main&gt; let zero = In Zero
*Main&gt; :t zero
zero :: Mu Natf
*Main&gt; let un = In (Succ zero)
*Main&gt; :t un
un :: Mu Natf
*Main&gt; let deux = In (Succ un)
*Main&gt; :t deux
deux :: Mu Natf</code></pre>
<p>Tous les nombres ont bien ici le type <code>Mu Natf</code> et l’on peut sans problème les combiner, par exemple pour définir l’addition:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">add ::</span> <span class="dt">Natural</span> <span class="ot">-&gt;</span> <span class="dt">Natural</span> <span class="ot">-&gt;</span> <span class="dt">Natural</span>
add (<span class="dt">In</span> <span class="dt">Zero</span>) x <span class="fu">=</span> x
add x (<span class="dt">In</span> <span class="dt">Zero</span>) <span class="fu">=</span> x
add (<span class="dt">In</span> (<span class="dt">Succ</span> x)) (<span class="dt">In</span> (<span class="dt">Succ</span> x&#39;)) <span class="fu">=</span> <span class="dt">In</span> (<span class="dt">Succ</span> (<span class="dt">In</span> (<span class="dt">Succ</span> (add x x&#39;))))</code></pre></div>
<h3 id="foncteur-et-f-algèbre">Foncteur et F-Algèbre</h3>
<p>Evidemment, c’est théoriquement très intéressant mais ce qu’on veut c’est manipuler des “vrais” nombres, pas de longues chaînes de constructeurs, sauf dans les cas où l’on s’intéresse à la récursion explicite, évidemment. On voudrait donc pouvoir <em>transformer</em> des objets de notre type Natural en un type plus commun, par exemple Int. Pour ce faire, notre type de base Natf manque d’un ingrédient: la <em>fonctorialité</em> (ou propriété d’être un foncteur). On a vu que ce qui définissait un foncteur, c’était le fait de posséder une fonction <code>fmap</code> possédant quelques bonnes propriétés de compositionnalité. Dans le cas de Natf, cette définition est simple:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">instance</span> <span class="dt">Functor</span> <span class="dt">Natf</span> <span class="kw">where</span>
  fmap f (<span class="dt">Zero</span>) <span class="fu">=</span> <span class="dt">Zero</span>
  fmap f (<span class="dt">Succ</span> x) <span class="fu">=</span> <span class="dt">Succ</span> (f x)</code></pre></div>
<p>Dès que l’on a un foncteur <code>f</code>, alors pour tout type <code>a</code> on peut définir (entre autres myriades de choses) des fonctions de types <code>h :: f a -&gt; a</code> qui “déconstruisent” des éléments de <code>a</code> “transformés” par <code>f</code> en éléments de <code>a</code>: c’est comme si on enlevait une couche d’une pelure d’oignon. Ce type de fonction est suffisamment courant pour avoir été nommé, on les appelle des <em>f-algèbres</em>. Par exemple, on peut écrire une f-algèbre qui permet de transformer des objets de type <code>Natf Int</code> en objets de type <code>Int</code> (nos gentils entiers habituels):</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">intalgebra ::</span> <span class="dt">Natf</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>
intalgebra <span class="dt">Zero</span>     <span class="fu">=</span> <span class="dv">0</span>
intalgebra (<span class="dt">Succ</span> x) <span class="fu">=</span> <span class="dv">1</span> <span class="fu">+</span> x</code></pre></div>
<p>Cette fonction est très simple et non récursive, elle décrit simplement une correspondance univoque entre des opérations du type de départ (les constructeurs de <code>Natf</code>) et des opérations du type d’arrivée (les fonctions <code>plus</code> et la constante <code>0</code>). Ce serait encore plus explicite si l’on pouvait écrire ceci:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="co">-- does not compile</span>
<span class="ot">intalgebra ::</span> <span class="dt">Natf</span> <span class="dt">Int</span> <span class="ot">-&gt;</span> <span class="dt">Int</span>
intalgebra <span class="dt">Zero</span> <span class="fu">=</span> <span class="dv">0</span>
intalgebra <span class="dt">Succ</span> <span class="fu">=</span> (<span class="dv">1</span><span class="fu">+</span>)</code></pre></div>
<p>Mais une fois que l’on a cette fonction, on n’est guère avancé car de toute évidence, elle ne peut s’appliquer aux nombres de type <code>Natural</code>. C’est ici qu’entre un jeu notre premier “récurseur” d’ordre supérieur: le <strong>catamorphisme</strong> (roulement de tambour) !</p>
<h2 id="catamorphismes">Catamorphismes</h2>
<p>Un <em>catamorphisme</em> est donc une <em>fonction d’ordre supérieure</em> permettant de produire une valeur d’un type arbitraire en “repliant” une structure, un type algébrique, récursivement, par application d’un opérateur quelconque sur une valeur initiale.</p>
<p>Le catamorphisme “canonique” est l’opérateur <code>foldr</code> sur les listes:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">foldr<span class="ot"> ::</span> (a <span class="ot">-&gt;</span> b <span class="ot">-&gt;</span>  b) <span class="ot">-&gt;</span> b <span class="ot">-&gt;</span> [a] <span class="ot">-&gt;</span> b
foldr op x []     <span class="fu">=</span> x
foldr op x (y<span class="fu">:</span>ys) <span class="fu">=</span> y <span class="ot">`op`</span> (foldr op x ys)</code></pre></div>
<p>Pour tout opérateur binaire ⊙ et toute valeur x, h = foldr ⊙ x, est un catamorphisme pour les listes de type <code>[a] -&gt; b</code>. Le parcours de la liste est imbriqué avec l’application de l’opérateur dans l’appel récursif à <code>foldr</code>. Par ailleurs, on a vu ci-dessus que la récursion pouvait être rendue explicite au travers de la structure du type de données, par l’opérateur <code>Mu</code>, qui produit un <em>point fixe</em> d’un foncteur quelconque. On aimerait donc pouvoir distinguer, séparer, dans foldr et d’autres opérations du même type qui transforment un type de données récursif en une valeur quleconque, deux entités distinctes:</p>
<ul>
<li>le traitement de chaque instance possible d’un foncteur, autrement dit une f-algèbre quelconque ;</li>
<li>et la récursion.</li>
</ul>
<p>Ces deux contraintes peuvent s’exprimer dans le système de type, ce qui nous donne la signature suivante pour <code>cata</code>:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">cata ::</span> <span class="dt">Functor</span> f <span class="ot">=&gt;</span> (f a <span class="ot">-&gt;</span> a) <span class="ot">-&gt;</span> (<span class="dt">Mu</span> f <span class="ot">-&gt;</span> a)</code></pre></div>
<p><code>cata</code> est donc une fonction qui, à partir d’une f-algèbre, produit une fonction transformation un point fixe du foncteur <code>f</code> en une valeur. Sa définition est la suivante et l’on voit bien que la récursion y est explicite:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">cata h <span class="fu">=</span> h <span class="fu">.</span> fmap (cata h) <span class="fu">.</span> out</code></pre></div>
<p>On est désormais équipé pour appliquer notre fonction <code>intalgebra</code> définie ci-dessus pour transformer les nombres algébriques en entiers “sympathiques”:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">toInt<span class="ot"> ::</span> <span class="dt">Natural</span> <span class="ot">-&gt;</span> <span class="dt">Int</span> 
toInt <span class="fu">=</span> cata intalgebra</code></pre></div>
<p>et l’on peut utiliser <code>toint</code> pour obtenir de “vrais” entiers:</p>
<pre><code>*Main&gt; toint (In Zero)
0
*Main&gt; toint (In (Succ (In (Succ (In Zero)))))
2
*Main&gt; </code></pre>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>
<entry>
    <title>On &quot;The Dream Team Nightmare&quot;,  by Portia Tung</title>
    <link href="http://abailly.github.io/posts/dtn.html" />
    <id>http://abailly.github.io/posts/dtn.html</id>
    <published>2014-01-09T00:00:00Z</published>
    <updated>2014-01-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>On &quot;The Dream Team Nightmare&quot;,  by Portia Tung</h1>
<div class="info">Posted on January  9, 2014</div>

<p>The first “agile” conference I attended was <a href="http://spaconference.org/spa2008">SPA 2008</a> which took place in a nice hotel in the english countryside. And one of the first session I attended at this conference was a session about <a href="http://www.spaconference.org/spa2008/sessions/session148.html">Real options</a>, initially planned to be run by Chris Matts but actually lead by Pascal Van Cauwenberghe and Portia Tung. I vividly recall that, although the session was far from being perfect, it was fun, intriguing and I learnt quite a few new things.  Since then, I have had the opportunity to attend several of Portia’s session, mainly at [XP Day Benelux[(http://xpday.be/) (which by the way is the best conference I ever attended), and they always have been great moments, perfectly balanced between learning and fun, and perfectly organized[^1].  # The Dream Team Nightmare  <a href="http://pragprog.com/book/ptdream/the-dream-team-nightmare">The Dream Team Nightmare</a> is Portia Tung’s new book published by Pragmatic Books, which offers you a journey beyond the basics of agile coaching practices, techniques and tools. You take the role of Jim Hopper, an experienced agile coach which has been appointed by Love Inc. to help one of the company’s development team, the <em>Dream Team</em>.  This team has been struggling with agile software development practice for couple of years and is facing severe issues: Development time increases, relations with business people are difficult and conflicting, quality is soaring… After initial enthusiasm for agile adoption, it seems to have been lagging behind other teams, to the point where they are considering abandoning agile altogether. You have been given a week to provide the management of the company an assessment of the situation and proposals to improve the team’s productivity and quality.  # What I Loved  The first thing I loved with this book is its form. Being an adventure book means that you are somehow in control of the destiny of Jim, the main character: You have to make decisions at crucial points, which can have beneficial or detrimental effects on the outcome of the story. Each step of the story is written in a lively manner, with a special attention to the description of the characters and the dialogues.  Day by day, one follows the progress of the coach and its team, and how they apply a lot of varying coaching techniques and tools to interact with people and start solving their problems. Without the hassle of a text book, one is then introduced to things like setting a kanban board for a meeting or a team, various meeting facilitation techniques for meetings, perfection game and decider from Core protocols, story writing, measurements and feedback evaluations, system thinking with reality and future trees…  The book covers a lot of the classical dysfunctions one find in software development (and probably other engineering) teams: Lack of trust between team members, and across team boundaries, isolation of teams from other teams’ experiments and feedback, silos, business-technical divide, fear of change and failure, lack of feedback, point less measurements and estimating. I especially liked how kanban boards are used systematically to set goals and track progress, even for meetings; the emphasis on concrete and multidimensional measurements for progress; and the <em>option thinking</em> toolbox which is used extensively in the book to build a release plan that is both realistic, flexible and business-oriented.  It is not the same thing to <em>read</em> a formal description of a tool or technique, and to live it through the eyes of an involved person in a concrete situation. <em>The Dream Team Nightmare</em> succeeds in being both pedagogical and fun, which is a rare endeavour. And I already started using some of the techniques from the book in my daily work!  [^1]: The quality of Portia’s sessions props deserves a special mention!</p>


<div id="disqus_thread"></div>
<script>
  (function() {  // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
  
    s.src = '//arnaudsblog.disqus.com/embed.js';
  
    s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


]]></summary>
</entry>

</feed>
