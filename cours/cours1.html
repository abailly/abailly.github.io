<!doctype html>
<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
  <meta charset="utf-8">

  <title>Arnaud Bailly - Le test de logiciels</title>
  <meta name="description" content="We craft code">
  <meta name="author" content="Arnaud Bailly, Thomas Queste">

  <link rel="stylesheet" type="text/css" href="/css/style.css?v=3">
  <link rel="stylesheet" type="text/css" href="/css/default.css">
  <link rel="stylesheet" type="text/css" href="/css/syntax.css">
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Lato">
  <script src="/js/modernizr-2.0.6.min.js"></script>
</head>
<body>
  <div id="container">
    <header>
      <div id="company-title">
        <a href="/"><img id="company-logo" src="/images/logo.png" width="259" height="75" title="igitur.io" /></a>
      </div>
      <div>
        <nav class="clearfix">
        <ul id="menu">
          <li>
          <a href="http://drcode.io">Dr.Code</a>
          </li>
          <li>
          <a href="/about.html">About</a>
          </li>
        </ul>
        </nav>
      </div>
    </header>
    <div id="main" role="main">
<h1>Le test de logiciels</h1>

<section id="références-pour-ces-notes" class="slide level2">
<h1>Références pour ces notes:</h1>
<h3 id="livres">Livres</h3>
<ul>
<li class="fragment"><em>The Art of software testing</em>, G.J. Myers, <em>Wiley</em>, 2004 (2nde édition) 1979 (1ère édition).</li>
<li class="fragment"><em>Testing object-oriented systems</em>, R.V. Binder, <em>Addison Wesley</em>, 2000.</li>
<li class="fragment"><em>A practical guide to testing OO software</em>, J.D. McGregor, D.A. Sykes, <em>Addison Wesley</em>, 2001.</li>
<li class="fragment"><em>Le test des logiciels</em>, Xanthakis et al., Hermés, 1998</li>
<li class="fragment"><em>Sytematic Black-box Testing</em>, Boris Beizer, Prentice-Hall, 1993</li>
<li class="fragment"><em>Lessons learned in Software Testing</em>, Cem Kaner, James Bach and Brett Pettichord, ?, 200?</li>
<li class="fragment"><em>Un processus pour les Systèmes d’Informations</em>, Pezziardi et al., Octo Technology, 2006</li>
<li class="fragment"><em>Le test de logiciels</em>, ???, Vuibert, 2003</li>
<li class="fragment"><em>Practical Model-based Testing</em>, M.Utting et B.Legeard, Addison-Wesley, 2007</li>
<li class="fragment"><em>Agile Testing</em>, Addison-Wesley, 2009</li>
</ul>
<h3 id="sites">Sites</h3>
<ul>
<li class="fragment">cours de Yves Le Traon: <a href="http://www.irisa.fr/triskell/perso_pro/yletraon/cours/Maitrise-ADT/">Le test des logiciels</a></li>
<li class="fragment">site de Brian Marick</li>
<li class="fragment">site de <a href="http://www.satisfice.com">James Bach</a></li>
</ul>
<h3 id="listes-de-diffusion">Listes de diffusion</h3>
<ul>
<li class="fragment">software testing</li>
<li class="fragment">agile testing</li>
<li class="fragment">test driven devlopment</li>
</ul>
</section>
<section id="objectif" class="slide level2">
<h1>Objectif:</h1>
<ul>
<li class="fragment">détecter des erreurs dans un programme;</li>
<li class="fragment"><p>célèbre définition de Myers:</p>
<p><em>Testing is the process of executing a program with the intent of finding errors.</em></p></li>
</ul>
<p>Participe à la validation des programmes:</p>
<ul>
<li class="fragment">valider un programme = vérifier qu’il est conforme à sa spécification;</li>
<li class="fragment">autres moyens de validation: vérification et preuve;</li>
<li class="fragment">test = moyen de validation principal:</li>
<li class="fragment">moins coûteux que la vérification ou la preuve;</li>
<li class="fragment">facile à comprendre;</li>
<li class="fragment"><p>retour à l’utilisateur immédiat et (plus ou moins) compréhensible; . Néanmoins ne peut garantir que le programme est exempt d’erreurs:</p></li>
<li class="fragment">n’apporte pas de certitude;</li>
<li class="fragment">ne fait qu’augmenter la confiance qu’on porte au programme;</li>
<li class="fragment"><p>esprit différent de la vérification (quand une proprieté est prouvée, elle est prouvée !).</p></li>
</ul>
<p>Pourtant très coûteux !</p>
<ul>
<li class="fragment">avec la maintenance: 80% du coût total d’un projet (on parle ici du <em>test de recette</em> ou <em>test système</em> ;</li>
<li class="fragment">un exemple classique adapté de [Myers,Binder]: le <strong>Triangle</strong></li>
</ul>
<h3 id="lexemple-du-triangle">L’exemple du Triangle</h3>
<p><a href="http://www.testobsessed.com/exercises/triangle.html">Une version en Ajax du problème du triangle</a></p>
<p>Version initiale:</p>
<ol type="1">
<li class="fragment">L’utilisateur rentre <em>trois nombres</em> sensés représenter les longueurs des côtés d’un triangle.</li>
<li class="fragment">Le programme répond en indiquant le type du triangle: scalene, isocèle, équilatéral, rectangle ou <strong>erreur</strong></li>
</ol>
<p>Version objet (Binder):</p>
<ol type="1">
<li class="fragment">La classe =Triangle= est construite avec trois longueurs</li>
<li class="fragment">Elle dispose de méthodes: =isIsocele()=, =isRectangle()=, =isScalene()= et =isEquilateral()=</li>
</ol>
<p><strong>Problème</strong>: Donner les cas de test permettant de vérifier et valider le bon fonctionnement de l’application Triangle.</p>
<h3 id="terminologie">Terminologie</h3>
<p>Distinguer <em>panne</em> et <em>erreur</em> :</p>
<ul>
<li class="fragment">une <strong>panne</strong> (<em>fault</em>) est l’observation d’un comportement incorrect du programme testé</li>
<li class="fragment">un <strong>défaut</strong> (<em>defect</em>) est la cause d’une panne. On notera qu’un même défaut peut être à l’origine de plusieurs pannes, et réciproquement qu’une panne peut-êrte causée par la conjonction de plusieurs défauts (ou même par plusieurs défauts indépendamment les uns des autres)</li>
<li class="fragment">une <strong>erreur</strong> (<em>error</em>) est l’action (ou l’inaction) humaine ayant causé l’introduction du défaut dans le logiciel. Une erreur est souvent appelée <strong>bug</strong> mais cela peut induire un subtil effet de déresponsabilisation du programmeur, comme si des leprechauns malins introduisaient des erreurs dans le programme derrière son dos.</li>
</ul>
<p>Tester révèle des pannes, déboguer enlève les erreurs à l’origine des pannes et en introduit d’autres, d’où l’importance de tester la <em>non-régression</em> donc de disposer d’un mode d’exécution automatisé des tests.</p>
</section>
<section id="un-état-desprit" class="slide level2">
<h1>Un état d’esprit</h1>
<p>Quelques évidences, pour la plupart issues du [Myers].</p>
<p>Concernant la forme des cas de test:</p>
<ul>
<li class="fragment">inclure dans un cas de test des entrées pour le programme mais aussi le résultat attendu (sortie calculée, émission d’une exception, impression d’un message, etc);</li>
<li class="fragment">toujours déterminer le résultat attendu par rapport à la spécification du programme (pas au code);</li>
<li class="fragment">stocker les cas de tests pour pouvoir les exécuter à nouveau;</li>
<li class="fragment">soigner la traçabilité des tests.</li>
</ul>
<p>Concernant le contenu des cas de test:</p>
<ul>
<li class="fragment">vérifier que le programme se comporte bien dans les cas attendus comme dans les cas invalides. Par exemple, dans le cas du triangle:</li>
<li class="fragment">spontanément on vérifiera les cas “équilatéral”, “isocèle”, “quelconque”;</li>
<li class="fragment">tendance à oublier le cas invalide “pas un triangle”;</li>
<li class="fragment">mettre en pratique le fait que la probabilité qu’une portion de code contienne des erreurs est proportionnelle au nombre d’erreur déjà trouvées dans cette portion.</li>
</ul>
<p>Concernant le processus de test:</p>
<ul>
<li class="fragment">ne jamais tester ses propres programmes (<strong>difficile</strong>) ;</li>
<li class="fragment">examiner très attentivement les rapports de test, les stocker aussi;</li>
<li class="fragment">ne jamais partir du principe qu’un test ne trouvera pas d’erreurs.</li>
</ul>
<p>Enfin: concevoir des cas de tests est (pourvu que le concepteur soit dans le bon état d’esprit) une activité difficile mais créative et intéressante !</p>
</section>
<section id="différentes-approches" class="slide level2">
<h1>Différentes approches</h1>
<p>L’exécution sur une machine n’est pas la seule manière de tester un programme.</p>
<h3 id="test-statique">Test statique</h3>
<p>Test «par l’humain», sans machine, par lecture du code:</p>
<p>cf. <em>Handbook of Inspection and Reviews</em>, Gerald Weinberg,</p>
<h4 id="principes">Principes</h4>
<ul>
<li class="fragment">réunions de 4 personnes environ ou plus dont le programmeur et le concepteur, un programmeur expérimenté, un testeur expérimenté, un modérateur;</li>
<li class="fragment">le but n’est pas de mettre le programmeur sur la sellette mais de trouver des erreurs;</li>
<li class="fragment">efficace:</li>
<li class="fragment">plus de 50% des fautes sont détectées à ce stade;</li>
<li class="fragment">pas forcément des fautes «faciles»;</li>
<li class="fragment">complémentaire du test par exécution.</li>
<li class="fragment">oblige à écrire du code clair, bien documenté et structuré;</li>
</ul>
<h4 id="inspection">Inspection</h4>
<p>lecture du code accompagnée d’une liste des points à vérifier, par ex:</p>
<ul>
<li class="fragment">présence de variables avec des noms très proches;</li>
<li class="fragment">expressions booléennes correctes;</li>
<li class="fragment">priorité des opérateurs bien comprise;</li>
<li class="fragment">évaluation paresseuse des opérateurs bien comprise;</li>
<li class="fragment">terminaison des boucles;</li>
<li class="fragment">pb de surcharge/redéfinition de méthodes;</li>
</ul>
<h4 id="revue-de-code">revue de code</h4>
<p>plus complexe :</p>
<ul>
<li class="fragment">les participants viennent avec des cas de test simples;</li>
<li class="fragment">le code est «exécuté» manuellement</li>
</ul>
<h3 id="test-dynamique">Test dynamique</h3>
<p>Test par l’exécution du système = cas qui nous intéresse.</p>
<p>Schématisation du test dynamique. Il comporte:</p>
<ul>
<li class="fragment">un testeur (humain);</li>
<li class="fragment">pour lancer les tests (fournir les entrées, etc): un <strong>pilote</strong> ou <strong>driver</strong> de test (logiciel);</li>
<li class="fragment">le problème de l’<strong>oracle</strong>: comment décider si les résultats produits par le test sont bien ceux attendus ? Oracle = capacité de répondre à cette question (toujours basé sur la spécification);</li>
<li class="fragment">problème du <strong>critère d’arrêt</strong>: comment savoir si on a «suffisamment» testé ? mesures de <strong>couverture</strong>.</li>
</ul>
<h3 id="adéquation-des-tests">Adéquation des tests</h3>
<p>Tester complètement (exhaustivement) un logiciel est impossible:</p>
<ul>
<li class="fragment">le nombre de combinaison d’entrées pour les tests est ingérable;</li>
<li class="fragment">même s’il était gérable: de toute manière trop coûteux;</li>
<li class="fragment">nécessité de trouver un sous-ensemble de l’ensemble des cas de test possibles qui ont la plus forte probabilité de trouver un maximum d’erreur;</li>
<li class="fragment">notion d’adéquation du test d’un logiciel: l’avoir testé suffisamment pour être raisonnablement sûr qu’il se comporte comme il est censé le faire.</li>
</ul>
<p>L’adéquation peut se mesurer en termes de couverture, qui se mesure par exemple:</p>
<ol type="1">
<li class="fragment">en termes de la proportion de la spécification qui est testée;</li>
<li class="fragment">en termes de la proportion du code (de l’implantation) qui est sensibilisée par une suite de tests.</li>
<li class="fragment">en termes de la proportion des domaines de valeurs des données en entrée/sortie</li>
</ol>
<p>Correspond à deux approches de base pour le test:</p>
<ol type="1">
<li class="fragment">test basé sur ce que le logiciel est censé faire: la spécification sert à concevoir l’oracle et les cas de test;</li>
<li class="fragment">test basé sur ce que fait réellement l’implantation du logiciel: la spécification sert à concevoir l’oracle, le code sert à concevoir les cas de test.</li>
</ol>
<h3 id="test-fonctionnel">Test fonctionnel</h3>
<p>Aussi appelé <em>test en boîte noire</em>, ou test basé sur la spécification.</p>
<ul>
<li class="fragment">aucune connaissance de l’implantation;</li>
<li class="fragment">repose exclusivement sur la spécification;</li>
<li class="fragment">avantage: permet d’écrire les tests avant le codage;</li>
<li class="fragment">inconvénient: l’efficacité du test repose sur la qualité de la spécification (complète et compréhensible pour le concepteur des tests).</li>
</ul>
<p>Le Modèle de base est la <strong>fonction</strong> caractérisant une relation entre des <em>entrées</em> et des <em>sorties</em>.</p>
<figure>
<img src="figures/modele-test-fonction.png" />
</figure>
<p>Tester, c’est <em>sensibiliser</em> le Composant sous Test (<em>Component Under Test</em> d’où CUT), c’est à dire lui fournir des input, et comparer les output <em>réels</em> aux output <em>attendus</em> au moyen d’un <strong>oracle</strong>.</p>
<h3 id="test-structurel">Test structurel</h3>
<p>Aussi appelé <em>test en boîte blanche</em> (plus exactement <em>boîte de verre</em> !) ou test basé sur l’implantation:</p>
<ul>
<li class="fragment">connaissance totale de l’implantation;</li>
<li class="fragment">avantages:
<ul>
<li class="fragment">possibilité de fixer finement la valeur des entrées pour sensibiliser des chemins particuliers du code;</li>
<li class="fragment">critères de couvertures divers et précis.</li>
</ul></li>
<li class="fragment">inconvénient: conception des tests uniquement pour le code déjà écrit.</li>
</ul>
<p>En pratique :: Combinaison des deux approches, voir la section consacrée aux <strong>critères de tests</strong>.</p>
</section>
<section id="triangle-magique" class="slide level2">
<h1>Triangle magique</h1>
<p>Le code, les specs et les tests se vérifient l’un l’autre. Une erreur dans les tests peut avoir trois interprétations différentes :</p>
<ul>
<li class="fragment">les tests sont incorrects : c’est le cas le plus défavorable puisqu’il induit une confiance infondée dans le logiciel produit. Pour éviter ce cas, les tests doivent être le plus simple possible ;</li>
<li class="fragment">le code est incorrect : cas le plus fréquent;</li>
<li class="fragment">les specs sont “incorrectes”, p.ex. elles spécifient des comportements impossibles (non exécutables), elles sont incohérentes et/ou contradictoires, elles sont incomplètes.</li>
</ul>
<figure>
<img src="figures/triangle-magique-test.png" />
</figure>
<h3 id="tests-comme-spécification">Tests comme spécification</h3>
<p>Lors de la mise en oeuvre du développement dirigé par les tests, ceux-ci peuvent être considérés comme une expression formalisée (exécutable) des spécifications, d’où le raccourci: les tests <strong>sont</strong> la spécification.</p>
<p>Problème: les tests (unitaires) sont écrits par le développeur, donc ils ne peuvent être qu’<strong>une</strong> vision partiale des spécifications du logiciel. Nécessaire de compléter les tests par de la documentation orientée client.</p>
<p>En fait, l’écriture des tests permet de <em>mesurer</em> la compréhension de la spécification par le <em>testeur</em>. Ce n’est pas la spécification elle-même qui est généralement inaccessible (dans l’empyrée des Idées).</p>
</section>
<section><section id="le-test-dans-le-cycle-de-développement" class="titleslide slide level1"><h1>Le test dans le cycle de développement</h1></section><section id="cycle-en-v" class="slide level2">
<h1>Cycle en V</h1>
<p>Modèle de développement normalisé par la RFA, nouvelle norme V-modell XT (2004). Le principe est d’associer une activité de vérification (test) à chaque phase du cycle de développement du logiciel.</p>
<p>Schématiquement :</p>
<pre><code>    Exigences   ---------
       \                 \
        \                 ---------- Recette 
      Spéc.                          /
    fonctionnelles-------           /
         \               \         /
          \                ------ Test système
       Architecture ---         /
          \            \       /
           \            -----  Test intégration
        Conception  --        /
           \          \      /
            \           --- Test unitaire
             \              / 
             +------+      /
             | Code |_____/
             +------+</code></pre>
<p>Voir <a href="http://www.testing.com/writings/new-models.pdf">B.Marick</a> pour une critique du modèle en V</p>
<p>Ce modèle offre une classification commode des différentes granularités auxquelles s’applique le test. <strong>Attention</strong> à la rigidité du modèle de développement.</p>
<h3 id="test-unitaire">Test unitaire</h3>
<ul>
<li class="fragment">test d’une unité logicielle, d’un «module»;</li>
<li class="fragment">pour détecter des fautes dans son comportement individuel;</li>
<li class="fragment">on ne teste pas les comportements dépendants d’autres unités;</li>
<li class="fragment">avant de tester le mur, tester ses briques;</li>
<li class="fragment">notion d’unité: dépend du paradigme de programmation utilisé: fonction, procédure, sous-programme, classe, composant, etc.</li>
</ul>
<h3 id="test-dintégration">Test d’intégration</h3>
<ul>
<li class="fragment">vérifier qu’un ensemble d’unités coopérent correctement;</li>
<li class="fragment">pour détecter des erreurs dans leur inter-opérabilité, la mauvaise utilisation d’une interface (surtout si interface floue);</li>
<li class="fragment">basé sur l’architecture de conception;</li>
<li class="fragment">plusieurs approches pour l’intégration:</li>
<li class="fragment">non-incrémentale ou big-bang: les modules sont testés unitairement chacun de leur côté; puis on les assemble et on teste le tout d’un coup;</li>
<li class="fragment">incrémentale: on assemble un module déjà testé avec un module pas encore testé, puis on teste leur combinaison. Encore deux approches: bottom-up et top-down.</li>
<li class="fragment">pour simuler les modules non encore testés ou non disponibles: «bouchons» ou stubs.</li>
</ul>
<h3 id="test-système">Test système</h3>
<p>Sur une application complètement intégrée ds son environnement. - test de montée en charge; - stress de l’application; - …</p>
<p>Et aussi…</p>
<ul>
<li class="fragment">test de <em>régression</em> (ou <em>non-régression</em>) : nouveau test du système après une modification pour vérifier qu’elle n’a pas apporté d’autres fautes. En pratique, les tests fonctionnels d’une version =n= sont des tests de non-régression pour la version =n+1= ;</li>
<li class="fragment"><em>smoke test</em>: tests “primitifs” pour vérifier la bonne marche d’un système, le nom vient de l’époque des constructeurs de hardware: si on branche et que çane fait pas de <em>fumée</em>, c’est que le test est réussi.</li>
</ul>
<h3 id="test-de-recette">Test de recette</h3>
<p>Ou test d’<em>acceptation</em>, (ou <em>User Acceptance Testing</em>, ou simplement recette) : effectué avec l’utilisateur final pour valider le système produit par rapport aux exigences, pour obtenir son approbation avant la livraison.</p>
</section><section id="le-modèle-w" class="slide level2">
<h1>Le modèle W</h1>
<p><a href="http://www.gerrardconsulting.com/default.asp?page=services/wmodel.html">Modèle W</a></p>
<p>Raffinement du modèle V pour mettre en avant les différentes activités de test <strong>et</strong> de vérification des artefacts produits pour le logiciel aux différentes étapes du cycle de développement.</p>
<p>Le V principal est dupliqué par un autre V représentant les différentes activités de V&amp;V ayant lieu au cours du développement:</p>
<p>La branche gauche du W lie à chaque activité de <em>conception</em> des activités d’analyse ou de “test statique”:</p>
<ul>
<li class="fragment"><strong>exigences</strong>: animation des exigences, inspection des scénarios, analyse des modèles métiers</li>
<li class="fragment"><strong>spécifications</strong>: revues</li>
<li class="fragment"><strong>architecture</strong>: prototypage, inspection de code</li>
<li class="fragment"><strong>conception/codage</strong>: analyse statique, revues de code</li>
</ul>
<p>La branche droite du W lie à chaque activité de construction d’une partie du logiciel final (unité, composant, sous-système, système) une activité de “test dynamique”:</p>
<ul>
<li class="fragment">codage/conception: test unitaire</li>
<li class="fragment">architecture/intégration continue: test d’intégration</li>
<li class="fragment">spécifications/construction système: tests systèmes</li>
<li class="fragment">exigences/déploiement: tests d’acceptation</li>
</ul>
</section><section id="le-modèle-agile" class="slide level2">
<h1>Le modèle Agile</h1>
<p>Les méthodes <a href="http://www.agilemanifesto.org">Agiles</a> (<a href="http://www.extremprogramming.org">Extreme Programming</a> essentiellement) utilisent le test comme moteur du processus de développement afin de:</p>
<ul>
<li class="fragment">réduire les <em>déchets</em> (le travail ne contribuant pas directement à ajouter de la valeur au produit final)</li>
<li class="fragment">améliorer la qualité du logiciel produit</li>
<li class="fragment">maximiser l’adéquation entre les besoins <em>réels</em> du client (ie. pas nécessairement les besoins exprimés formellement) et le logiciel produit. On suppose que les besoins exprimés sont toujours partiels, partiaux et qu’ils changent.</li>
</ul>
<p>Ce qui implique de:</p>
<ul>
<li class="fragment">réduire les cycles de développement;</li>
<li class="fragment"><a href="http://www.extremeprogramming.org">eXtreme programming</a>: on écrit les tests puis on code (mais il est formellement déconseillé d’utiliser les tests comme spécification !) ;</li>
<li class="fragment">[McGregor Sykes] <em>test early, test often, test enough</em>:</li>
<li class="fragment">tester dès la phase d’analyse;</li>
<li class="fragment">processus de développement itératif (<em>analyse a little, design a little, code a little, test what you can</em>): tester à chaque incrément;</li>
<li class="fragment">soigneusement peser sur ce quoi doit se concentrer l’effort de test (risk analysis), hiérarchisation des tests d’où la méthode des tests basés sur les risques (James Bach).</li>
<li class="fragment">exécuter les tests en permanence sur la base de code réelle: <em>intégration continue</em> (voir aussi <em>test en continu</em>), tous les tests sont toujours exécutés sur tous le code en permanence</li>
<li class="fragment">donc, les tests doivent être <strong>exécutables</strong> (ou automatisés) pour diminuer leur coût: seul subsiste le coût de conception (et d’écriture initiale) des tests.</li>
</ul>
<p>Résultat: <em>Développement Dirigé par les Tests</em> (<em>Test Driven Development</em>) ou <strong>TDD</strong></p>
<h3 id="tests-unitaires-et-tdd">Tests unitaires et TDD</h3>
<p>Technique de développement/conception (les deux sont synonymes en XP)</p>
<p>Principe:</p>
<ol type="1">
<li class="fragment">Ecrire un test</li>
<li class="fragment">S’assurer qu’il <em>échoue</em></li>
<li class="fragment">Ecrire le code <em>minimal</em> permettant de <em>réussir</em> le test</li>
<li class="fragment">S’assurer qu’il <em>réussit</em></li>
<li class="fragment">Réusiner (<em>refactor</em>) le code pour supprimer les doublons et améliorer sa testabilité</li>
</ol>
<p>Mantra:</p>
<ul>
<li class="fragment"><strong>Red</strong> : la barre de test unitaire est rouge</li>
<li class="fragment"><strong>Green</strong> : la barre de test est verte</li>
<li class="fragment"><strong>Refactor</strong> : le code est amélioré</li>
</ul>
<p>Intérêt:</p>
<ul>
<li class="fragment">maintien en parallèle des tests et du code, donc on a à disposition en permanence un ensemble fiable de tests de non-régression</li>
<li class="fragment">seul le code testé est produit, ergo seul le code utile est écrit</li>
</ul>
<h3 id="autres-tests">Autres tests</h3>
<p>Ce même principe est appliqué à tous les types de tests:</p>
<ul>
<li class="fragment">on définit pour chaque niveau de granularité adéquat des tests permettant de <strong>valider</strong> de manière exécutable et formelle que le produit (l’incrément, le logiciel, le composant)</li>
<li class="fragment">différents outils/langages sont utilisés pour définir de manière adéquate les différents tests: tests systèmes, tests d’acceptation, tests fonctionnels d’IHM…</li>
</ul>
</section><section id="comparaisons" class="slide level2">
<h1>Comparaisons</h1>
<p><em>Attention, cette comparaison est biaisée en faveur des modèles Agiles</em></p>
<blockquote>
<p>Le coût de correction d’une erreur croît de manière exponentielle en fonction de l’interval de temps séparant la <em>production de l’erreur</em> de sa <em>manifestation</em> sous forme d’une panne B.Boehm, référence ?? - cf. Leprechauns of Software Engineering, L.Bossavit</p>
</blockquote>
<p>Plus les tests sont réalisés/exécutés tôt, plus les erreurs qu’ils sont susceptibles de détecter seront révélées tôt, donc moins elles coûteront cher.</p>
<p>Réduire les cycles de développement: analyse-conception-réalisation-test pour détecter au plus tôt les erreurs, omissions, incompréhensions, et réagir au changement dans les meilleurs délais.</p>
</section></section>
<section><section id="le-test-dynamique" class="titleslide slide level1"><h1>Le test dynamique</h1></section><section id="terminologie-1" class="slide level2">
<h1>Terminologie</h1>
<p>quoi teste-t-on ? :: une implantation du système: <strong>IUT</strong> = <em>Implementation Under Test</em> ou encore <strong>SUT</strong> = <em>System Under Test</em>;</p>
<p>que teste-t-on ? :: une propriété/caractéristique à vérifier: l’objectif de test;</p>
<p>donnée de test :: valeurs spécifiques pour les entrées du programme et pour la simulation de l’environnement (peuvent servir pour plusieurs cas de test);</p>
<p>jeu de test :: ensemble de données de test;</p>
<p>cas de test :: test élémentaire associé à une donnée de test pour un objectif de test donné. Il contient souvent:</p>
<ul>
<li class="fragment">un préambule qui mène l’IUT dans une configuration particulière à la donnée de test;</li>
<li class="fragment">un corps de test qui permet de vérifier l’objectif de test;</li>
<li class="fragment">un postambule qui ramène par ex l’IUT ds un état permettant d’enchaîner un autre test;</li>
<li class="fragment">le résultat attendu;</li>
<li class="fragment">le résultat attendu inclut les sorties, le post-état de l’IUT, les exceptions levées, les messages générés;</li>
</ul>
<p>suite de test :: un ensemble de cas de test rassemblés suivant un critère donné (ex: tests de toutes les méthodes d’une classe);</p>
<p>critère d’arrêt :: critère permettant d’évaluer si la confiance apportée par les tests effectués est suffisante; stratégie de test ou critère de sélection: algorithme pour créer des cas de test;</p>
<p>critère d’adéquation :: détermine a posteriori si un cas de test est intéressant, cf test par mutation;</p>
<ul>
<li class="fragment">un test réussit (passes) si les résultats obtenus sont les résultats attendue, sinon il échoue (fails);</li>
<li class="fragment">en cas d’échec, l’IUT contient une faute (un bout de code incorrect), causée par une erreur humaine.</li>
</ul>
</section></section>
<section><section id="automatisation-des-tests" class="titleslide slide level1"><h1>Automatisation des tests</h1></section><section id="objectifs" class="slide level2">
<h1>Objectifs</h1>
<h3 id="amélioration-de-la-qualité">Amélioration de la qualité</h3>
<p>Les tests sont des spécifications exécutables:</p>
<ul>
<li class="fragment">applicable surtout au TDD: un outil pour comprendre et détailler le fonctionnement de l’application</li>
<li class="fragment"><strong>attention</strong>: ce n’est vrai que si les tests fournissent une bonne <em>couverture</em> du comportement attendu (ie. de la spécification), ce qui suppose des tests manuels et une compréhensions du problème</li>
</ul>
<p>Les tests automatisés <em>ne détectent pas de pannes</em>, ils servent à les <em>prévenir</em> ! Par contre, ils permettent <em>éventuellement</em> de localiser plus rapidement les défauts à l’origine des pannes, en étant précis et localisés.</p>
<h3 id="compréhension-du-sut">Compréhension du SUT</h3>
<p>Les tests <em>documentent</em> le code, ce qu’il est sensé faire.</p>
<p>Ils permettent de limiter les risques, en les identifiant au plus tôt et en les levant.</p>
<p>Ils constituent un filet de sécurité pour les développeurs:</p>
<ul>
<li class="fragment">on peut toucher au code sans crainte: si on fait une bêtise, on la voit tout de suite parce qu’un test échoue</li>
<li class="fragment">dans le code légataire, on n’a pas cette sécurité (stratégie de refactoring de code légataire: écrire des jeux de test)</li>
<li class="fragment">couplage avec le contrôle de sources: permet de toujours revenir en arrière, éventuellement d’identifier la modification du code ayant introduit une erreur (eg. voir <a href="http://www.selenic.com/mercurial/wiki/index.cgi/BisectExtension">bisect</a>)</li>
</ul>
<p>Les tests <em>ne doivent pas</em> augmenter les risques: ils doivent être simples, immediats, et tester <em>effectivement</em> le code (attention à l’abus de <em>doubles</em>).</p>
<h3 id="facilité-dexécution">Facilité d’exécution</h3>
<p>Les tests doivent pouvoir être exécuté très fréquemment:</p>
<ul>
<li class="fragment">l’exécution doit être totalement automatisés</li>
<li class="fragment">chaque tests doit être <em>auto-vérifiants</em>: le tests doit encapsuler son oracle</li>
<li class="fragment">tous les tests doivent être reproductibles: pas d’effets de bord, pas de comportement non-déterministe dans le résultat du test</li>
</ul>
<h3 id="facilité-décriture">Facilité d’écriture</h3>
<p>Les tests doivent être simples à lire et à écrire, et éviter la duplication, le recouvrement dans les comportements qu’ils testent.</p>
<ul>
<li class="fragment">simplicité: pas de flôt de contrôle complexe dans les tests, <em>une seule vérification par test</em>, chaque test est un cas identifié et un seul</li>
<li class="fragment">expressivité: limiter/encapsuler le <em>boilerplate code</em>, définir des bibliothèques spécifiques, pseudo-DSL permettant de comprendre immédiatement l’objectif d’un test (tension entre DRY/factorisation et nécessité d’autonomie de chaque cas de test)</li>
<li class="fragment">séparation des préoccupations:
<ul>
<li class="fragment">séparer le code de test du code de production</li>
<li class="fragment">séparer les responsabilités de chaque test</li>
</ul></li>
</ul>
<h3 id="limiter-la-maintenance">Limiter la maintenance</h3>
<p>Les tests doivent être robustes:</p>
<ul>
<li class="fragment">le nombre de tests affectés par un changement doit être réduit</li>
<li class="fragment">les tests ne doivent pas dépendre de leur environnement (cf. autonomie): système de fichiers, si possible OS, réseau…</li>
</ul>
<!-- -*- coding: utf-8-dos; -*- -->
</section></section>

    </div>
    <footer>
       <a href="https://fr.linkedin.com/in/arnaudbailly"> <img src="/images/linkedin.png" width="28" /></a>  <a href="https://twitter.com/dr_c0d3"> <img width="32" src="/images/twitter.png" /></a>  <a href="/atom.xml"><img src="/images/feed-icon.svg" width="24px" /></a>  <a href="http://jaspervdj.be/hakyll"><img src="/images/lambda.png" width="24px" /></a>
    </footer>
    
  </div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-42631907-2', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>
