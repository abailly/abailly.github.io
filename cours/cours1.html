<!doctype html>
<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if IE 7]>    <html class="no-js lt-ie9 lt-ie8" lang="en"> <![endif]-->
<!--[if IE 8]>    <html class="no-js lt-ie9" lang="en"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
  <meta charset="utf-8">

  <title>Arnaud Bailly - Le test de logiciels</title>
  <meta name="description" content="We craft code">
  <meta name="author" content="Arnaud Bailly, Thomas Queste">

  <link rel="stylesheet" type="text/css" href="/css/style.css?v=3">
  <link rel="stylesheet" type="text/css" href="/css/default.css">
  <link rel="stylesheet" type="text/css" href="/css/syntax.css">
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Lato">

  <script src="http://foldlabs.com/js/modernizr-2.0.6.min.js"></script>
</head>
<body>
  <div id="container">
    <header>
      <div id="company-title">
        <a href="http://blog.foldlabs.com"><img id="company-logo" src="http://foldlabs.com/img/foldlabs-logo.jpeg" width="259" height="75" title="FoldLabs.com" /></a>
      </div>
      <div>
        <nav class="clearfix">
        <ul id="menu">
          <li>
          <a href="/cours">Training</a>
          </li>
        </ul>
        </nav>
      </div>
    </header>
    <div id="main" role="main">
<h1>Le test de logiciels</h1>

<h2 id="références-pour-ces-notes">Références pour ces notes:</h2>
<h3 id="livres">Livres</h3>
<ul>
<li><em>The Art of software testing</em>, G.J. Myers, <em>Wiley</em>, 2004 (2nde édition) 1979 (1ère édition).</li>
<li><em>Testing object-oriented systems</em>, R.V. Binder, <em>Addison Wesley</em>, 2000.</li>
<li><em>A practical guide to testing OO software</em>, J.D. McGregor, D.A. Sykes, <em>Addison Wesley</em>, 2001.</li>
<li><em>Le test des logiciels</em>, Xanthakis et al., Hermés, 1998</li>
<li><em>Sytematic Black-box Testing</em>, Boris Beizer, Prentice-Hall, 1993</li>
<li><em>Lessons learned in Software Testing</em>, Cem Kaner, James Bach and Brett Pettichord, ?, 200?</li>
<li><em>Un processus pour les Systèmes d’Informations</em>, Pezziardi et al., Octo Technology, 2006</li>
<li><em>Le test de logiciels</em>, ???, Vuibert, 2003</li>
<li><em>Practical Model-based Testing</em>, M.Utting et B.Legeard, Addison-Wesley, 2007</li>
<li><em>Agile Testing</em>, Addison-Wesley, 2009</li>
</ul>
<h3 id="sites">Sites</h3>
<ul>
<li>cours de Yves Le Traon: <a href="http://www.irisa.fr/triskell/perso_pro/yletraon/cours/Maitrise-ADT/">Le test des logiciels</a></li>
<li>site de Brian Marick</li>
<li>site de <a href="http://www.satisfice.com">James Bach</a></li>
</ul>
<h3 id="listes-de-diffusion">Listes de diffusion</h3>
<ul>
<li>software testing</li>
<li>agile testing</li>
<li>test driven devlopment</li>
</ul>
<h2 id="objectif">Objectif:</h2>
<ul>
<li>détecter des erreurs dans un programme;</li>
<li><p>célèbre définition de Myers:</p>
<p><em>Testing is the process of executing a program with the intent of finding errors.</em></p></li>
</ul>
<p>Participe à la validation des programmes:</p>
<ul>
<li>valider un programme = vérifier qu’il est conforme à sa spécification;</li>
<li>autres moyens de validation: vérification et preuve;</li>
<li>test = moyen de validation principal:</li>
<li>moins coûteux que la vérification ou la preuve;</li>
<li>facile à comprendre;</li>
<li><p>retour à l’utilisateur immédiat et (plus ou moins) compréhensible; . Néanmoins ne peut garantir que le programme est exempt d’erreurs:</p></li>
<li>n’apporte pas de certitude;</li>
<li>ne fait qu’augmenter la confiance qu’on porte au programme;</li>
<li><p>esprit différent de la vérification (quand une proprieté est prouvée, elle est prouvée !).</p></li>
</ul>
<p>Pourtant très coûteux !</p>
<ul>
<li>avec la maintenance: 80% du coût total d’un projet (on parle ici du <em>test de recette</em> ou <em>test système</em> ;</li>
<li>un exemple classique adapté de [Myers,Binder]: le <strong>Triangle</strong></li>
</ul>
<h3 id="lexemple-du-triangle">L’exemple du Triangle</h3>
<p><a href="http://www.testobsessed.com/exercises/triangle.html">Une version en Ajax du problème du triangle</a></p>
<p>Version initiale:</p>
<ol style="list-style-type: decimal">
<li>L’utilisateur rentre <em>trois nombres</em> sensés représenter les longueurs des côtés d’un triangle.</li>
<li>Le programme répond en indiquant le type du triangle: scalene, isocèle, équilatéral, rectangle ou <strong>erreur</strong></li>
</ol>
<p>Version objet (Binder):</p>
<ol style="list-style-type: decimal">
<li>La classe =Triangle= est construite avec trois longueurs</li>
<li>Elle dispose de méthodes: =isIsocele()=, =isRectangle()=, =isScalene()= et =isEquilateral()=</li>
</ol>
<p><strong>Problème</strong>: Donner les cas de test permettant de vérifier et valider le bon fonctionnement de l’application Triangle.</p>
<h3 id="terminologie">Terminologie</h3>
<p>Distinguer <em>panne</em> et <em>erreur</em> :</p>
<ul>
<li>une <strong>panne</strong> (<em>fault</em>) est l’observation d’un comportement incorrect du programme testé</li>
<li>un <strong>défaut</strong> (<em>defect</em>) est la cause d’une panne. On notera qu’un même défaut peut être à l’origine de plusieurs pannes, et réciproquement qu’une panne peut-êrte causée par la conjonction de plusieurs défauts (ou même par plusieurs défauts indépendamment les uns des autres)</li>
<li>une <strong>erreur</strong> (<em>error</em>) est l’action (ou l’inaction) humaine ayant causé l’introduction du défaut dans le logiciel. Une erreur est souvent appelée <strong>bug</strong> mais cela peut induire un subtil effet de déresponsabilisation du programmeur, comme si des leprechauns malins introduisaient des erreurs dans le programme derrière son dos.</li>
</ul>
<p>Tester révèle des pannes, déboguer enlève les erreurs à l’origine des pannes et en introduit d’autres, d’où l’importance de tester la <em>non-régression</em> donc de disposer d’un mode d’exécution automatisé des tests.</p>
<h2 id="un-état-desprit">Un état d’esprit</h2>
<p>Quelques évidences, pour la plupart issues du [Myers].</p>
<p>Concernant la forme des cas de test:</p>
<ul>
<li>inclure dans un cas de test des entrées pour le programme mais aussi le résultat attendu (sortie calculée, émission d’une exception, impression d’un message, etc);</li>
<li>toujours déterminer le résultat attendu par rapport à la spécification du programme (pas au code);</li>
<li>stocker les cas de tests pour pouvoir les exécuter à nouveau;</li>
<li>soigner la traçabilité des tests.</li>
</ul>
<p>Concernant le contenu des cas de test:</p>
<ul>
<li>vérifier que le programme se comporte bien dans les cas attendus comme dans les cas invalides. Par exemple, dans le cas du triangle:</li>
<li>spontanément on vérifiera les cas “équilatéral”, “isocèle”, “quelconque”;</li>
<li>tendance à oublier le cas invalide “pas un triangle”;</li>
<li>mettre en pratique le fait que la probabilité qu’une portion de code contienne des erreurs est proportionnelle au nombre d’erreur déjà trouvées dans cette portion.</li>
</ul>
<p>Concernant le processus de test:</p>
<ul>
<li>ne jamais tester ses propres programmes (<strong>difficile</strong>) ;</li>
<li>examiner très attentivement les rapports de test, les stocker aussi;</li>
<li>ne jamais partir du principe qu’un test ne trouvera pas d’erreurs.</li>
</ul>
<p>Enfin: concevoir des cas de tests est (pourvu que le concepteur soit dans le bon état d’esprit) une activité difficile mais créative et intéressante !</p>
<h2 id="différentes-approches">Différentes approches</h2>
<p>L’exécution sur une machine n’est pas la seule manière de tester un programme.</p>
<h3 id="test-statique">Test statique</h3>
<p>Test «par l’humain», sans machine, par lecture du code:</p>
<p>cf. <em>Handbook of Inspection and Reviews</em>, Gerald Weinberg,</p>
<h4 id="principes">Principes</h4>
<ul>
<li>réunions de 4 personnes environ ou plus dont le programmeur et le concepteur, un programmeur expérimenté, un testeur expérimenté, un modérateur;</li>
<li>le but n’est pas de mettre le programmeur sur la sellette mais de trouver des erreurs;</li>
<li>efficace:</li>
<li>plus de 50% des fautes sont détectées à ce stade;</li>
<li>pas forcément des fautes «faciles»;</li>
<li>complémentaire du test par exécution.</li>
<li>oblige à écrire du code clair, bien documenté et structuré;</li>
</ul>
<h4 id="inspection">Inspection</h4>
<p>lecture du code accompagnée d’une liste des points à vérifier, par ex:</p>
<ul>
<li>présence de variables avec des noms très proches;</li>
<li>expressions booléennes correctes;</li>
<li>priorité des opérateurs bien comprise;</li>
<li>évaluation paresseuse des opérateurs bien comprise;</li>
<li>terminaison des boucles;</li>
<li>pb de surcharge/redéfinition de méthodes;</li>
</ul>
<h4 id="revue-de-code">revue de code</h4>
<p>plus complexe :</p>
<ul>
<li>les participants viennent avec des cas de test simples;</li>
<li>le code est «exécuté» manuellement</li>
</ul>
<h3 id="test-dynamique">Test dynamique</h3>
<p>Test par l’exécution du système = cas qui nous intéresse.</p>
<p>Schématisation du test dynamique. Il comporte:</p>
<ul>
<li>un testeur (humain);</li>
<li>pour lancer les tests (fournir les entrées, etc): un <strong>pilote</strong> ou <strong>driver</strong> de test (logiciel);</li>
<li>le problème de l’<strong>oracle</strong>: comment décider si les résultats produits par le test sont bien ceux attendus ? Oracle = capacité de répondre à cette question (toujours basé sur la spécification);</li>
<li>problème du <strong>critère d’arrêt</strong>: comment savoir si on a «suffisamment» testé ? mesures de <strong>couverture</strong>.</li>
</ul>
<h3 id="adéquation-des-tests">Adéquation des tests</h3>
<p>Tester complètement (exhaustivement) un logiciel est impossible:</p>
<ul>
<li>le nombre de combinaison d’entrées pour les tests est ingérable;</li>
<li>même s’il était gérable: de toute manière trop coûteux;</li>
<li>nécessité de trouver un sous-ensemble de l’ensemble des cas de test possibles qui ont la plus forte probabilité de trouver un maximum d’erreur;</li>
<li>notion d’adéquation du test d’un logiciel: l’avoir testé suffisamment pour être raisonnablement sûr qu’il se comporte comme il est censé le faire.</li>
</ul>
<p>L’adéquation peut se mesurer en termes de couverture, qui se mesure par exemple:</p>
<ol style="list-style-type: decimal">
<li>en termes de la proportion de la spécification qui est testée;</li>
<li>en termes de la proportion du code (de l’implantation) qui est sensibilisée par une suite de tests.</li>
<li>en termes de la proportion des domaines de valeurs des données en entrée/sortie</li>
</ol>
<p>Correspond à deux approches de base pour le test:</p>
<ol style="list-style-type: decimal">
<li>test basé sur ce que le logiciel est censé faire: la spécification sert à concevoir l’oracle et les cas de test;</li>
<li>test basé sur ce que fait réellement l’implantation du logiciel: la spécification sert à concevoir l’oracle, le code sert à concevoir les cas de test.</li>
</ol>
<h3 id="test-fonctionnel">Test fonctionnel</h3>
<p>Aussi appelé <em>test en boîte noire</em>, ou test basé sur la spécification.</p>
<ul>
<li>aucune connaissance de l’implantation;</li>
<li>repose exclusivement sur la spécification;</li>
<li>avantage: permet d’écrire les tests avant le codage;</li>
<li>inconvénient: l’efficacité du test repose sur la qualité de la spécification (complète et compréhensible pour le concepteur des tests).</li>
</ul>
<p>Le Modèle de base est la <strong>fonction</strong> caractérisant une relation entre des <em>entrées</em> et des <em>sorties</em>.</p>
<div class="figure">
<img src="figures/modele-test-fonction.png" alt />

</div>
<p>Tester, c’est <em>sensibiliser</em> le Composant sous Test (<em>Component Under Test</em> d’où CUT), c’est à dire lui fournir des input, et comparer les output <em>réels</em> aux output <em>attendus</em> au moyen d’un <strong>oracle</strong>.</p>
<h3 id="test-structurel">Test structurel</h3>
<p>Aussi appelé <em>test en boîte blanche</em> (plus exactement <em>boîte de verre</em> !) ou test basé sur l’implantation:</p>
<ul>
<li>connaissance totale de l’implantation;</li>
<li>avantages:
<ul>
<li>possibilité de fixer finement la valeur des entrées pour sensibiliser des chemins particuliers du code;</li>
<li>critères de couvertures divers et précis.</li>
</ul></li>
<li>inconvénient: conception des tests uniquement pour le code déjà écrit.</li>
</ul>
<p>En pratique :: Combinaison des deux approches, voir la section consacrée aux <strong>critères de tests</strong>.</p>
<h2 id="triangle-magique">Triangle magique</h2>
<p>Le code, les specs et les tests se vérifient l’un l’autre. Une erreur dans les tests peut avoir trois interprétations différentes :</p>
<ul>
<li>les tests sont incorrects : c’est le cas le plus défavorable puisqu’il induit une confiance infondée dans le logiciel produit. Pour éviter ce cas, les tests doivent être le plus simple possible ;</li>
<li>le code est incorrect : cas le plus fréquent;</li>
<li>les specs sont “incorrectes”, p.ex. elles spécifient des comportements impossibles (non exécutables), elles sont incohérentes et/ou contradictoires, elles sont incomplètes.</li>
</ul>
<div class="figure">
<img src="figures/triangle-magique-test.png" alt />

</div>
<h3 id="tests-comme-spécification">Tests comme spécification</h3>
<p>Lors de la mise en oeuvre du développement dirigé par les tests, ceux-ci peuvent être considérés comme une expression formalisée (exécutable) des spécifications, d’où le raccourci: les tests <strong>sont</strong> la spécification.</p>
<p>Problème: les tests (unitaires) sont écrits par le développeur, donc ils ne peuvent être qu’<strong>une</strong> vision partiale des spécifications du logiciel. Nécessaire de compléter les tests par de la documentation orientée client.</p>
<p>En fait, l’écriture des tests permet de <em>mesurer</em> la compréhension de la spécification par le <em>testeur</em>. Ce n’est pas la spécification elle-même qui est généralement inaccessible (dans l’empyrée des Idées).</p>
<h1 id="le-test-dans-le-cycle-de-développement">Le test dans le cycle de développement</h1>
<h2 id="cycle-en-v">Cycle en V</h2>
<p>Modèle de développement normalisé par la RFA, nouvelle norme V-modell XT (2004). Le principe est d’associer une activité de vérification (test) à chaque phase du cycle de développement du logiciel.</p>
<p>Schématiquement :</p>
<pre><code>    Exigences   ---------
       \                 \
        \                 ---------- Recette 
      Spéc.                          /
    fonctionnelles-------           /
         \               \         /
          \                ------ Test système
       Architecture ---         /
          \            \       /
           \            -----  Test intégration
        Conception  --        /
           \          \      /
            \           --- Test unitaire
             \              / 
             +------+      /
             | Code |_____/
             +------+</code></pre>
<p>Voir <a href="http://www.testing.com/writings/new-models.pdf">B.Marick</a> pour une critique du modèle en V</p>
<p>Ce modèle offre une classification commode des différentes granularités auxquelles s’applique le test. <strong>Attention</strong> à la rigidité du modèle de développement.</p>
<h3 id="test-unitaire">Test unitaire</h3>
<ul>
<li>test d’une unité logicielle, d’un «module»;</li>
<li>pour détecter des fautes dans son comportement individuel;</li>
<li>on ne teste pas les comportements dépendants d’autres unités;</li>
<li>avant de tester le mur, tester ses briques;</li>
<li>notion d’unité: dépend du paradigme de programmation utilisé: fonction, procédure, sous-programme, classe, composant, etc.</li>
</ul>
<h3 id="test-dintégration">Test d’intégration</h3>
<ul>
<li>vérifier qu’un ensemble d’unités coopérent correctement;</li>
<li>pour détecter des erreurs dans leur inter-opérabilité, la mauvaise utilisation d’une interface (surtout si interface floue);</li>
<li>basé sur l’architecture de conception;</li>
<li>plusieurs approches pour l’intégration:</li>
<li>non-incrémentale ou big-bang: les modules sont testés unitairement chacun de leur côté; puis on les assemble et on teste le tout d’un coup;</li>
<li>incrémentale: on assemble un module déjà testé avec un module pas encore testé, puis on teste leur combinaison. Encore deux approches: bottom-up et top-down.</li>
<li>pour simuler les modules non encore testés ou non disponibles: «bouchons» ou stubs.</li>
</ul>
<h3 id="test-système">Test système</h3>
<p>Sur une application complètement intégrée ds son environnement. - test de montée en charge; - stress de l’application; - …</p>
<p>Et aussi…</p>
<ul>
<li>test de <em>régression</em> (ou <em>non-régression</em>) : nouveau test du système après une modification pour vérifier qu’elle n’a pas apporté d’autres fautes. En pratique, les tests fonctionnels d’une version =n= sont des tests de non-régression pour la version =n+1= ;</li>
<li><em>smoke test</em>: tests “primitifs” pour vérifier la bonne marche d’un système, le nom vient de l’époque des constructeurs de hardware: si on branche et que çane fait pas de <em>fumée</em>, c’est que le test est réussi.</li>
</ul>
<h3 id="test-de-recette">Test de recette</h3>
<p>Ou test d’<em>acceptation</em>, (ou <em>User Acceptance Testing</em>, ou simplement recette) : effectué avec l’utilisateur final pour valider le système produit par rapport aux exigences, pour obtenir son approbation avant la livraison.</p>
<h2 id="le-modèle-w">Le modèle W</h2>
<p><a href="http://www.gerrardconsulting.com/default.asp?page=services/wmodel.html">Modèle W</a></p>
<p>Raffinement du modèle V pour mettre en avant les différentes activités de test <strong>et</strong> de vérification des artefacts produits pour le logiciel aux différentes étapes du cycle de développement.</p>
<p>Le V principal est dupliqué par un autre V représentant les différentes activités de V&amp;V ayant lieu au cours du développement:</p>
<p>La branche gauche du W lie à chaque activité de <em>conception</em> des activités d’analyse ou de “test statique”:</p>
<ul>
<li><strong>exigences</strong>: animation des exigences, inspection des scénarios, analyse des modèles métiers</li>
<li><strong>spécifications</strong>: revues</li>
<li><strong>architecture</strong>: prototypage, inspection de code</li>
<li><strong>conception/codage</strong>: analyse statique, revues de code</li>
</ul>
<p>La branche droite du W lie à chaque activité de construction d’une partie du logiciel final (unité, composant, sous-système, système) une activité de “test dynamique”:</p>
<ul>
<li>codage/conception: test unitaire</li>
<li>architecture/intégration continue: test d’intégration</li>
<li>spécifications/construction système: tests systèmes</li>
<li>exigences/déploiement: tests d’acceptation</li>
</ul>
<h2 id="le-modèle-agile">Le modèle Agile</h2>
<p>Les méthodes <a href="http://www.agilemanifesto.org">Agiles</a> (<a href="http://www.extremprogramming.org">Extreme Programming</a> essentiellement) utilisent le test comme moteur du processus de développement afin de:</p>
<ul>
<li>réduire les <em>déchets</em> (le travail ne contribuant pas directement à ajouter de la valeur au produit final)</li>
<li>améliorer la qualité du logiciel produit</li>
<li>maximiser l’adéquation entre les besoins <em>réels</em> du client (ie. pas nécessairement les besoins exprimés formellement) et le logiciel produit. On suppose que les besoins exprimés sont toujours partiels, partiaux et qu’ils changent.</li>
</ul>
<p>Ce qui implique de:</p>
<ul>
<li>réduire les cycles de développement;</li>
<li><a href="http://www.extremeprogramming.org">eXtreme programming</a>: on écrit les tests puis on code (mais il est formellement déconseillé d’utiliser les tests comme spécification !) ;</li>
<li>[McGregor Sykes] <em>test early, test often, test enough</em>:</li>
<li>tester dès la phase d’analyse;</li>
<li>processus de développement itératif (<em>analyse a little, design a little, code a little, test what you can</em>): tester à chaque incrément;</li>
<li>soigneusement peser sur ce quoi doit se concentrer l’effort de test (risk analysis), hiérarchisation des tests d’où la méthode des tests basés sur les risques (James Bach).</li>
<li>exécuter les tests en permanence sur la base de code réelle: <em>intégration continue</em> (voir aussi <em>test en continu</em>), tous les tests sont toujours exécutés sur tous le code en permanence</li>
<li>donc, les tests doivent être <strong>exécutables</strong> (ou automatisés) pour diminuer leur coût: seul subsiste le coût de conception (et d’écriture initiale) des tests.</li>
</ul>
<p>Résultat: <em>Développement Dirigé par les Tests</em> (<em>Test Driven Development</em>) ou <strong>TDD</strong></p>
<h3 id="tests-unitaires-et-tdd">Tests unitaires et TDD</h3>
<p>Technique de développement/conception (les deux sont synonymes en XP)</p>
<p>Principe:</p>
<ol style="list-style-type: decimal">
<li>Ecrire un test</li>
<li>S’assurer qu’il <em>échoue</em></li>
<li>Ecrire le code <em>minimal</em> permettant de <em>réussir</em> le test</li>
<li>S’assurer qu’il <em>réussit</em></li>
<li>Réusiner (<em>refactor</em>) le code pour supprimer les doublons et améliorer sa testabilité</li>
</ol>
<p>Mantra:</p>
<ul>
<li><strong>Red</strong> : la barre de test unitaire est rouge</li>
<li><strong>Green</strong> : la barre de test est verte</li>
<li><strong>Refactor</strong> : le code est amélioré</li>
</ul>
<p>Intérêt:</p>
<ul>
<li>maintien en parallèle des tests et du code, donc on a à disposition en permanence un ensemble fiable de tests de non-régression</li>
<li>seul le code testé est produit, ergo seul le code utile est écrit</li>
</ul>
<h3 id="autres-tests">Autres tests</h3>
<p>Ce même principe est appliqué à tous les types de tests:</p>
<ul>
<li>on définit pour chaque niveau de granularité adéquat des tests permettant de <strong>valider</strong> de manière exécutable et formelle que le produit (l’incrément, le logiciel, le composant)</li>
<li>différents outils/langages sont utilisés pour définir de manière adéquate les différents tests: tests systèmes, tests d’acceptation, tests fonctionnels d’IHM…</li>
</ul>
<h2 id="comparaisons">Comparaisons</h2>
<p><em>Attention, cette comparaison est biaisée en faveur des modèles Agiles</em></p>
<blockquote>
<p>Le coût de correction d’une erreur croît de manière exponentielle en fonction de l’interval de temps séparant la <em>production de l’erreur</em> de sa <em>manifestation</em> sous forme d’une panne B.Boehm, référence ?? - cf. Leprechauns of Software Engineering, L.Bossavit</p>
</blockquote>
<p>Plus les tests sont réalisés/exécutés tôt, plus les erreurs qu’ils sont susceptibles de détecter seront révélées tôt, donc moins elles coûteront cher.</p>
<p>Réduire les cycles de développement: analyse-conception-réalisation-test pour détecter au plus tôt les erreurs, omissions, incompréhensions, et réagir au changement dans les meilleurs délais.</p>
<h1 id="le-test-dynamique">Le test dynamique</h1>
<p>Définitions officielles: IEEE (Standard Glossary of Software Engineering Terminology).</p>
<p>Qu’est-ce qu’effectuer un test (dynamique) ?</p>
<ul>
<li>déterminer un objectif de test: la propriété à tester;</li>
<li>choisir une donnée de test: au sens large des valeurs pour les entrées qui permettent d’amener le programme (l’IUT) dans un état propice à la vérification de l’objectif (positionnement de ses variables d’états);</li>
<li>écrire un cas de test: un programme qui amène l’IUT dans cet état propice et effectue le test;</li>
<li>stocker le cas de test ainsi que le résultat attendu: les deux doivent être conservés pour pouvoir rejouer les tests;</li>
<li>exécuter ce cas de test;</li>
<li>observer et enregistrer les résultats;</li>
<li>les comparer avec les résultats attendus</li>
</ul>
<p>Qu’est-ce que tester dynamiquement ?</p>
<ul>
<li>Exécuter sur l’IUT une suite de tests;</li>
<li>Corriger les erreurs révélées par les tests;</li>
<li>Relancer la suite de tests sur la nouvelle version de l’IUT;</li>
<li>Évaluer le critère d’arrêt/de couverture;</li>
<li>Compléter la suite de test si besoin;</li>
<li>On obtient une version de référence (baseline version);</li>
<li>Relancer cette suite lors des tests de régression, et dès que besoin de comparaison avec la version de référence.</li>
</ul>
<p>besoin d’automatisation du test.</p>
<h2 id="terminologie-1">Terminologie</h2>
<p>quoi teste-t-on ? :: une implantation du système: <strong>IUT</strong> = <em>Implementation Under Test</em> ou encore <strong>SUT</strong> = <em>System Under Test</em>;</p>
<p>que teste-t-on ? :: une propriété/caractéristique à vérifier: l’objectif de test;</p>
<p>donnée de test :: valeurs spécifiques pour les entrées du programme et pour la simulation de l’environnement (peuvent servir pour plusieurs cas de test);</p>
<p>jeu de test :: ensemble de données de test;</p>
<p>cas de test :: test élémentaire associé à une donnée de test pour un objectif de test donné. Il contient souvent:</p>
<ul>
<li>un préambule qui mène l’IUT dans une configuration particulière à la donnée de test;</li>
<li>un corps de test qui permet de vérifier l’objectif de test;</li>
<li>un postambule qui ramène par ex l’IUT ds un état permettant d’enchaîner un autre test;</li>
<li>le résultat attendu;</li>
<li>le résultat attendu inclut les sorties, le post-état de l’IUT, les exceptions levées, les messages générés;</li>
</ul>
<p>suite de test :: un ensemble de cas de test rassemblés suivant un critère donné (ex: tests de toutes les méthodes d’une classe);</p>
<p>critère d’arrêt :: critère permettant d’évaluer si la confiance apportée par les tests effectués est suffisante; stratégie de test ou critère de sélection: algorithme pour créer des cas de test;</p>
<p>critère d’adéquation :: détermine a posteriori si un cas de test est intéressant, cf test par mutation;</p>
<ul>
<li>un test réussit (passes) si les résultats obtenus sont les résultats attendue, sinon il échoue (fails);</li>
<li>en cas d’échec, l’IUT contient une faute (un bout de code incorrect), causée par une erreur humaine.</li>
</ul>
<h1 id="automatisation-des-tests">Automatisation des tests</h1>
<p>Source: <em>xUnit Patterns</em>, Gerald Meszaros, Addison-Wesley, 2007, pp.19-30</p>
<p>Motivation économique: le coût initial d’apprentissage, puis les coûts de construction et maintenance des tests sont justifiés par des gains lors du développement.</p>
<h2 id="objectifs">Objectifs</h2>
<h3 id="amélioration-de-la-qualité">Amélioration de la qualité</h3>
<p>Les tests sont des spécifications exécutables:</p>
<ul>
<li>applicable surtout au TDD: un outil pour comprendre et détailler le fonctionnement de l’application</li>
<li><strong>attention</strong>: ce n’est vrai que si les tests fournissent une bonne <em>couverture</em> du comportement attendu (ie. de la spécification), ce qui suppose des tests manuels et une compréhensions du problème</li>
</ul>
<p>Les tests automatisés <em>ne détectent pas de pannes</em>, ils servent à les <em>prévenir</em> ! Par contre, ils permettent <em>éventuellement</em> de localiser plus rapidement les défauts à l’origine des pannes, en étant précis et localisés.</p>
<h3 id="compréhension-du-sut">Compréhension du SUT</h3>
<p>Les tests <em>documentent</em> le code, ce qu’il est sensé faire.</p>
<p>Ils permettent de limiter les risques, en les identifiant au plus tôt et en les levant.</p>
<p>Ils constituent un filet de sécurité pour les développeurs:</p>
<ul>
<li>on peut toucher au code sans crainte: si on fait une bêtise, on la voit tout de suite parce qu’un test échoue</li>
<li>dans le code légataire, on n’a pas cette sécurité (stratégie de refactoring de code légataire: écrire des jeux de test)</li>
<li>couplage avec le contrôle de sources: permet de toujours revenir en arrière, éventuellement d’identifier la modification du code ayant introduit une erreur (eg. voir <a href="http://www.selenic.com/mercurial/wiki/index.cgi/BisectExtension">bisect</a>)</li>
</ul>
<p>Les tests <em>ne doivent pas</em> augmenter les risques: ils doivent être simples, immediats, et tester <em>effectivement</em> le code (attention à l’abus de <em>doubles</em>).</p>
<h3 id="facilité-dexécution">Facilité d’exécution</h3>
<p>Les tests doivent pouvoir être exécuté très fréquemment:</p>
<ul>
<li>l’exécution doit être totalement automatisés</li>
<li>chaque tests doit être <em>auto-vérifiants</em>: le tests doit encapsuler son oracle</li>
<li>tous les tests doivent être reproductibles: pas d’effets de bord, pas de comportement non-déterministe dans le résultat du test</li>
</ul>
<h3 id="facilité-décriture">Facilité d’écriture</h3>
<p>Les tests doivent être simples à lire et à écrire, et éviter la duplication, le recouvrement dans les comportements qu’ils testent.</p>
<ul>
<li>simplicité: pas de flôt de contrôle complexe dans les tests, <em>une seule vérification par test</em>, chaque test est un cas identifié et un seul</li>
<li>expressivité: limiter/encapsuler le <em>boilerplate code</em>, définir des bibliothèques spécifiques, pseudo-DSL permettant de comprendre immédiatement l’objectif d’un test (tension entre DRY/factorisation et nécessité d’autonomie de chaque cas de test)</li>
<li>séparation des préoccupations:
<ul>
<li>séparer le code de test du code de production</li>
<li>séparer les responsabilités de chaque test</li>
</ul></li>
</ul>
<h3 id="limiter-la-maintenance">Limiter la maintenance</h3>
<p>Les tests doivent être robustes:</p>
<ul>
<li>le nombre de tests affectés par un changement doit être réduit</li>
<li>les tests ne doivent pas dépendre de leur environnement (cf. autonomie): système de fichiers, si possible OS, réseau…</li>
</ul>
<!-- -*- coding: utf-8-dos; -*- -->

    </div>
    <footer>
      - Brewed since 2011 - <a href="http://blog.foldlabs.com/atom.xml"><img src="http://blog.foldlabs.com/images/feed-icon.svg" width="15px" /></a> - Generated with <a href="http://jaspervdj.be/hakyll">Hakyll</a>  - 
    </footer>
  </div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-26916078-2', 'foldlabs.com');
  ga('send', 'pageview');

</script>
</body>
</html>
